# Do-it-yourself with Python  {#doItYourselfWithPython}

Most of the methods presented in this book are available in both R and Python and can be used in a uniform way. But each of these languages also has many other tools for Explanatory Model Analysis.  

In this book, we introduce various methods for instance-level and dataset-level exploration and explanation of predictive models. In each chapter, there is a section with code snippets for R and Python that shows how to use a particular method. In this chapter, we provide a short description of steps that are needed to set-up the Python environment with the required libraries.

## What to install?

The Python interpreter [@python3] is needed. It is always a good idea to use the newest version. At least Python in version 3.6 is recommended. It can be downloaded from the Python website [https://python.org/](https://python.org/).
A popular environment for simple python installation and configuration is Anaconda, which can be downloaded from  website [https://www.anaconda.com/](https://www.anaconda.com/).

There are many editors available for Python to edit the code in a convenient way. In the data science community a very popular solution is The Jupyter Notebook. It is a web application that allows you to create and share documents that contain live code, visualizations and descriptions. The Jupyter Notebook can be installed from the website [https://jupyter.org/](https://jupyter.org/).

Once Python and the editor are available, the required packages should be installed.
The most important one is the `dalex` package currently in version `0.2.0`.
The  package can be installed with `pip` by executing the following instruction from the command line:

```
pip install dalex -U
```

Installation of `dalex` will automatically take care about other required libraries.

## How to work with `dalex`? {#infoDALEXpy}

There are many libraries in Python that can be used to construct a predictive model. 
Among the most popular, one needs to name algorithm-specific libraries, like `catboost` [@catbooost], `xgboost` [@xgboost], `keras` [@chollet2015keras] or libraries with multiple ML algorithms like scikit-learn [@scikitlearn].

While it is great to have such a large choice of tools for constructing models, the disadvantage is that different  packages have different interfaces and different arguments. Moreover, model-objects created with different packages  may have different internal structures. The main goal of the `dalex` package is to create a level of abstraction around a model that makes it easier to explore and explain the model.

Constructor `Explainer()` is THE method for model wrapping. There is only one argument that is required by the function; it is `model`, which is used to specify the model-object with the fitted form of the model. However, the function takes also additional arguments that extend its functionalities. They will be discussed in Section \@ref(ExplainersTitanicPythonCode). If these additional arguments are not provided by the user, the dalex library will try to extract them from the model. It is a good idea to specify them directly to avoid surprises. 

As soon as the model is wrapped by the `Explainer` object, all further functionalities will be performed on this object. They will be presented in subsections *Code snippets for Python*.

## Code snippets for Python

```{r python_setup, include=FALSE, eval=FALSE}
library(reticulate)
use_python("/Library/Frameworks/Python.framework/Versions/3.6/bin/python3")
```

A detailed description of the model exploration will be presented in the next chapters. In general, however, the way of working with the `dalex` library can be described in following steps: 

1. Import the `dalex` library.

```{python, eval=FALSE, highlight=TRUE}
import dalex as dx 
```

2. Create an Explainer / a wrapper around the model.

```{python, eval=FALSE, highlight=TRUE}
exp = dx.Explainer(model, X, y)
```

3. Calculate predictions for the model

```{python, eval=FALSE, highlight=TRUE}
exp.predict(henry)
```

4. Calculate specific explanations.

```{python, eval=FALSE, highlight=TRUE}
obs_bd = exp.predict_parts(obs, type='break_down')
```

5. Print calculated explanations.

```{python, eval=FALSE, highlight=TRUE}
obs_bd.result
```

5. Plot calculated explanations.

```{python, eval=FALSE, highlight=TRUE}
obs_bd.plot()
```

