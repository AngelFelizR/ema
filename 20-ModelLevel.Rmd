# Model level explanations {-}


# Introduction

Model level explainers help to understand how the model works in general, for an observed population. This is the main difference from the model level explainers that were focused on the model as a whole and on model population for whole population. Model level explainers work in the context of a population or subpopulation of observations.

Think about following use-cases

* One wants to know which variables are important in the model. Think about model for heart accident in which features come from additional medical examinations. Knowing which examinations are not important one can reduce model by removing unnecessary variables.
* One wants to understand how a selected variable affects the model response. Think about a model for prediction of apartment prices. You know that apartment location is an important factor, but which locations are better and how much a given location is worth? Model explainers help to understand how values of a selected variable affect the model response.
* One wants to know if there are any unusual observations that do not fit to the model. Observations with unusually large residuals. Think about a model for survival after some very risky treatment. You would like to know if for some patients the model predictions are extremely incorrect.


## Approaches to model explanations

Model level explanations are focused on four main aspects of a model. 

* Model performance. Here the question is how good is the model, is it good enough (better than some predefined threshold), is a model A better than model B?
* Model residuals. Is there any unusual pattern related to residuals, are they biased, are they correlated with some additional variable?
* Variable importance. How important are variables, which are the most important and which are not important at all?
* Variable effects. What is the relation between a variable and model response, can the variable be transformed to create a better model?



## A bit of philosophy: Three Laws for Model Level Explanations

In the spirit of three laws introduces in the chapter \@ref(three-single-laws) here we propose three laws for model level explanations.

* **Variable importance.** For every model we shall be able to understand which variables are important and which are not.
* **Model audit.** For every model we shall be able to verify basic check like if residuals are correlated with variables and if there are unusual observations.
* **Second opinion.**  For every model we shall be able to compare it against other models to verify if they capture different stories about the data.


# Variable Importance

## Example: Price prediction

[@R-e1071]
[@R-factorMerger]

In this chapter we show examples for three predictive models trained on `apartments` dataset from the `DALEX` package. Random Forest model (elastic but biased), Support Vector Machines model (large variance on boundaries) and Linear Model (stable but not very elastic). 
Presented examples are for regression (prediction of square meter price), but the CP profiles may be used in the same way for classification.


```{r, warning=FALSE, message=FALSE}
library("DALEX")
# Linear model trained on apartments data
model_lm <- lm(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)

library("randomForest")
set.seed(59)
# Random Forest model trained on apartments data
model_rf <- randomForest(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)

library("e1071")
# Support Vector Machinesr model trained on apartments data
model_svm <- svm(m2.price ~ construction.year + surface + floor + 
                         no.rooms + district, data = apartments)
```

For these models we use `DALEX` explainers created with `explain()` function. There exapliners  wrap models, predict functions and validation data.

```{r, warning=FALSE, message=FALSE}
explainer_lm <- explain(model_lm, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
explainer_rf <- explain(model_rf, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
explainer_svm <- explain(model_svm, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
```

Examples presented in this chapter are generated with the `ceterisParibus` package in version `r installed.packages()["ceterisParibus","Version"]`.

```{r, warning=FALSE, message=FALSE}
library("ceterisParibus")
```


Feature selection

[@Strobl2007] 
[@Strobl2008] 
- variable importance

[@2018arXiv180101489F]

Beware Default Random Forest Importances

Terence Parr, Kerem Turgutlu, Christopher Csiszar, and Jeremy Howard
March 26, 2018.

http://explained.ai/rf-importance/index.html


# Marginal Response

Feature extraction

## Partial Dependency Plots {#partialDependence}

[@demsar2018]

[@RJ2017016]
[@MAGIX]

Accumulated Local Effects (ALE) Plots
[@R-ALEPlot]



Interactions - extraction

## Merging Path Plots

[@R-factorMerger]

```{r, warning=FALSE, message=FALSE}
library(factorMerger)
```

# Performance Diagnostic {#modelComparisons}

Model selection

# Residual Diagnostic {#modelAuditing}

Model validation

[@R-auditor]

```{r, warning=FALSE, message=FALSE}
library(auditor)
```


# Other topics


[@R-randomForestExplainer]
[@R-ICEbox]
[@R-ALEPlot]

[@R-modelDown]

