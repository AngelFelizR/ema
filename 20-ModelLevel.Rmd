# Model level explanations {-}

# Introduction

## A bit of philosophy

Rights:

1. audit model residuals
2. variable importance
3. partial dependency plot

## Example: Price prediction

[@R-DALEX]

[@R-e1071]

[@R-factorMerger]

```{r, warning=FALSE, message=FALSE}
library("factorMerger")
```

In this chapter we show examples for three predictive models trained on `apartments` dataset from the `DALEX` package. Random Forest model (elastic but biased), Support Vector Machines model (large variance on boundaries) and Linear Model (stable but not very elastic). 
Presented examples are for regression (prediction of square meter price), but the CP profiles may be used in the same way for classification.


```{r, warning=FALSE, message=FALSE}
library("DALEX")
# Linear model trained on apartments data
model_lm <- lm(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)

library("randomForest")
set.seed(59)
# Random Forest model trained on apartments data
model_rf <- randomForest(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)

library("e1071")
# Support Vector Machinesr model trained on apartments data
model_svm <- svm(m2.price ~ construction.year + surface + floor + 
                         no.rooms + district, data = apartments)
```

For these models we use `DALEX` explainers created with `explain()` function. There exapliners  wrap models, predict functions and validation data.

```{r, warning=FALSE, message=FALSE}
explainer_lm <- explain(model_lm, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
explainer_rf <- explain(model_rf, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
explainer_svm <- explain(model_svm, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
```

Examples presented in this chapter are generated with the `ceterisParibus` package in version `r installed.packages()["ceterisParibus","Version"]`.

```{r, warning=FALSE, message=FALSE}
library("ceterisParibus")
```




# Variable Importance

Feature selection

[@Strobl2007] 
[@Strobl2008] 
- variable importance

[@2018arXiv180101489F]

Beware Default Random Forest Importances

Terence Parr, Kerem Turgutlu, Christopher Csiszar, and Jeremy Howard
March 26, 2018.

http://explained.ai/rf-importance/index.html


# Marginal Response

Feature extraction

## Partial Dependency Plots

Accumulated Local Effects (ALE) Plots

[@RJ2017016]
[@R-ALEPlot]

```{r, warning=FALSE, message=FALSE}
library(ALEPlot)
```


[@MAGIX]

Interactions - extraction

## Merging Path Plots

[@R-factorMerger]

```{r, warning=FALSE, message=FALSE}
library(factorMerger)
```

# Performance Diagnostic

Model selection

# Residual Diagnostic

Model validation

[@R-auditor]

```{r, warning=FALSE, message=FALSE}
library(auditor)
```


# Other topics


[@R-randomForestExplainer]
[@R-ICEbox]
[@R-ALEPlot]

```{r, warning=FALSE, message=FALSE}
library(randomForestExplainer)
library(ICEbox)
library(ALEPlot)
```


[@R-modelDown]

```{r, warning=FALSE, message=FALSE}
library(modelDown)
```
