# Part III: Dataset Level {-}

```{r UMEPpiramideDataset, echo=FALSE, out.width = '99%', fig.align='center'}
knitr::include_graphics("figure/UMEPpiramideDataset.png")
```

# Introduction to Dataset-level Exploration {#modelLevelExploration}

In Part II, we focused on instance-level explainers, which help to understand how a model yields a prediction for a single observation (instance). 

In Part III, we concentrate on dataset-level explainers, which help to understand how model's predictions perform overall, for an entire set of observations. Assuming that the observations form a representative sample from a general population, model-level explainers can provide an information about the quality of predictions for the population.

The following examples illustrate situations in which model-level explainers may be useful:

* We may want to learn which variables are "important" in the model. For instance, we may be interested in predicting the risk of heart attack by using explanatory variables that are derived from results of some medical examinations. If some of the variables do not influence model's predictions, we could simplify the model by removing the variables.
* We may want to understand how a selected variable influences model's predictions. For instance, we may be interested in predicting prices of apartments. Apartment's location is an important factor, but we may want to know which locations lead to higher prices? 
* We may want to discover whether there are any observations, for which the model yields wrong predictions. For instance, for a model predicting the probability of survival after a risky treatment, we might know whether there are patients for whom the model predictions are extremely wrong. Identifying such a group of patients might point to, for instance, an incorrect form of a explanatory variable, or even a missed variable. 
* We may be interested in an overall "performance" of the model. For instance, we may want to copmare two models in terms of, for instance, the average accuracy of their predictions.

<!---
Model-level explainers focus on four main aspects of a model:
* Variable's importance: which explanatory variables are ''important'', and which are not?
* Variable's effect: how does a variable influence average model's predictions? 
* Model's performance: how ''good'' is the model? Is one model ''better'' than another?
* Model's fit: which observations are misfitted by the model, where residual are the largest? 
---->

In all cases, measures capturing a particular aspect of the model have to be defined. We will discuss them in subsequent chapters. In particular, in Chapter \@ref(modelPerformance), we discuss measures that are useful for the evaluation of the overall predictive model performance. In Chapter \@ref(featureImportance), we focus on methods that allow evaluation of a variable's effect on model's predictions. Chapter \@ref(partialDependenceProfiles) and Chapter \@ref(accumulatedLocalProfiles) focus on exploration of the effect of selected variables on model's predictions. Chapter \@ref(residualDiagnostic) presents an overview of the classical residual-diagnostics tools. Finally, in Chapter \@ref(UseCaseFIFA), we present an example of an analysis that illustrates the use of the dataset-level explainers introduced in the previous chapters. 

