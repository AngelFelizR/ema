# Variable attribution for linear models {#variableAttributionMethods}

## Introduction  

In this chapter we introduce the concept and the intuitions underlying ,,variable attribution,'' i.e., the decomposition of the difference between the single-instance and the average model predictions among the different explanatory variables. We can think about the following examples:

* Assume that we are interested in predicting the risk of heart attack based on person's age, sex, and smoking habits. A patient may want to know which factors have the highest impact on the his/her risk score.
* Consider a model for prediction of apartment prices. An investor may want to know how much of the predicted price may be attributed to, for instance, the location of an apartment.
* Consider a model for credit scoring. A customer may want to know if factors like gender, age, or number of children influence model predictions.

In each of those cases we want to attribute a part of the model prediction to a single explanatory variable. This can be done directly for linear models. Hence, in this chapter We focus on those models. The method can be easily extended to generalized linear models. Model-agnostic approaches will be presented in Chapters \@ref(breakDown) and \@ref(shapley).

## Intuition  

Assume a linear model with $p$ explanatory variables collected in the vector $x = (x_1, x_2, \ldots, x_p)$ and   coefficients $\beta = (\beta_0, \beta_1, .., \beta_p)$, where $\beta_0$ is the intercept. The prediction is given by the following linear combination:  

$$
f(x) = \beta_0 + x_1 \beta_1 + \ldots + x_p \beta_p.
$$

We are interested in the contribution of variable $x_i$ on model prediction $f(x^*)$ for a single observation described by $x^*$. In this case, the contribution is related to $x^*_i\beta_i$, as variable $x_i$ occurs only in this term. As it will become clear in the sequel, it is easier to interpret the variable's contribution if $x_i$ is is centered by subtracting a constant $\hat x_i$ (usually, the mean of $x_i$). This leads the following, intuitive formula for the variable attribution:
$$
v(f, x^*, i) = \beta_i (x_i^* - \hat x_i).
$$

## Method

We want to calculate $v(f, x^*, i)$, which is the contribution of variable $x_i$ on prediction of model $f()$ in point $x^*$. 

Geneal approach for calculation of variable attributions would be to measure how much the expected model response would change after conditioning on $x_i = x_i^*$.

$$
v(f, x^*, i) = E[f(x) | x_i = x_i^*] - E[f(x)]
$$

For linear models, if coordinates of $x$ are independent, this is equivalent of

$$
v(f, x^*, i) = f(x^*) - E[f(x)|x_{-i} = x^*_{-i}] = \beta_i x^*_i  - E \beta_i X_i.
$$
Expected value can be estimated as averages, and this leads to  
$$
v(f, x^*, i) = \beta_i x^*_i - \beta_i \bar x_i = \beta_i (x^*_i - \bar x_i)
$$

The logic behind the attribution is the following. 
Contribution of variable $x_i$ is the difference between model response for value $x_i^*$ minus the average model response.

Note that the linear model ma be rewritten in a following way

$$
f(x) = baseline + (x_1 - \bar x_1) \beta_1 + ... + (x_p - \bar x_p) \beta_p
$$

where
$$
baseline = \mu + \bar x_1 \beta_1 + ... + \bar x_p \beta_p.
$$

Here $baseline$ is an average model response and variable contributions show how prediction for particular $x^*$ is different from the average response. 

** NOTE for careful readers **

There is a gap between expected value of $X_i$ and average calculated on some dataset $\bar x_i$. The latter depends on the data used for calculation of averages. For the sake of simplicity we do not emphasize these differences. To live with this just assume that we have access to a very large validation data that allows us to calculate $\bar x_i$ very accurately.

Also we assumed that coordinated of $x$ are independent, which may not be the case. We will return to this problem later, during the discussion related to interactions.

## Example: Wine quality

It may be a surprise, that the attribution for variable $x_i$ is not the $\beta_i x_i$. To understand this, consider following example. 

```{r attribution1, echo=FALSE, fig.cap="(fig:attribution1)Relation between wine quality and concentration of alcohol assessed with linear model", out.width = '50%', fig.align='center'}
knitr::include_graphics("figure/attribution_1.png")
```


Figure \@ref(fig:attribution1) shows the relation between alcohol and wine quality, based on the wine dataset [@wine2009]. The corresponding linear model is

$$
quality(alcohol) = 2.5820 + 0.3135 * alcohol
$$

The weakest wine in this dataset has 8\% of alcohol, average alcohol concentration is 10.51, so the contribution of alcohol to the model prediction is $0.3135  *(8-10.51) = -0.786885$. It means that low value of alcohol for this wine (8\%) lower the prediction of quality by $-0.786885$.

Note, that it would be confusing to use $x_i\beta_i$ as alcohol contribution on quality would be $0.3135*8 = 2.508$. This would not reflect the intuition that for positive relation, the smaller is the alcohol concentration the lower should be the quality of wine.


## Pros and Cons

Here we summarise pros and cons of this approach.

**Pros**

- Presented variable attribution for linear model is not an approximation, it is directly linked with the structure of a model.
- It is easier to understand attributions that are not linked with scale nor location of $x_i$ as the standard $\beta_i$ are.

**Cons**

- It works only for linear models. 
- This do not reduce model complexity. Just present model coefficients in a different way.


## Code snippets

Variable attributions for linear models may be directly extracted from the `predict()` function for linear models. 

In this section we will present an example for logistic regression based on the `HR` dataset. See the Section \@ref(HRdataset) for more details.

First we build a logistic regression model for binary variable `status == "fired"`. Here are fitted model coefficients.

```{r, warning=FALSE, message=FALSE}
library("DALEX")
model_fired <- glm(status == "fired" ~ ., data = HR, family = "binomial")
coef(model_fired)
```

We want to calculate variable attributions for a particular point. Here we define this point.

```{r, warning=FALSE, message=FALSE}
new_observation <- data.frame(gender = factor("male", levels = c("male", "female")),
                      age = 57.7,
                      hours = 42.3,
                      evaluation = 2,
                      salary = 2)
```

For linear and generalized linear models we may specify argument `type = "terms"` that extracts variable contributions.

```{r, warning=FALSE, message=FALSE}
predict(model_fired, new_observation, type = "terms")
```

Below we show how to do this with the `DALEX` package. Additionaly we may easily plot contributions.

```{r, warning=FALSE, message=FALSE}
library("DALEX")

explainer_fired <- explain(model_fired,
                 data = HR,
                 y = HR$status == "fired",
                 label = "fired")

attribution <- single_prediction(explainer_fired, new_observation)
attribution
plot(attribution)
```

