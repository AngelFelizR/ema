---
output:
  pdf_document: default
  html_document: default
---
# Ceteris-paribus Profiles and What-If Analysis {#ceterisParibus}

## Introduction {#CPIntro}

*Ceteris paribus* is a Latin phrase meaning "other things held constant" or "all else unchanged." In this chapter, we introduce a technique for model exploration based on the Ceteris paribus principle. In particular, we examine the influence of each explanatory variable, assuming that effects of all other variables are unchanged. The main goal is to understand how changes in a single explanatory variable affects model predictions. 

Explanation tools (explainers) presented in this chapter are linked to the second law introduced in Section \@ref(three-single-laws), i.e. the law of "Prediction's speculation." This is why the tools are also known as *What-If model analysis* or *Individual Conditional Expectations* [@ICEbox]. It turns out that it is easier to understand how a black-box model is working if we can explore the model by investigating the influence of explanatory variables separately, changing one at a time. 


## Intuition {#CPIntuition}

Panel A of Figure \@ref(fig:modelResponseCurveLine) presents response (prediction) surface for the `titanic_lmr_v6` model for two explanatory variables, *age* and *class*, from the *titanic* dataset (see Section \@ref(TitanicDataset)). We are interested in the change of the model prediction induced by each of the variables. Toward this end, we may want to explore the curvature of the response surface around a single point with *age* equal to 47 and *class* equal to "1st," indicated in the plot. Ceteris-paribus (CP) profiles are one-dimensional profiles that examine the curvature across each dimension, i.e., for each variable. Panel B of Figure \@ref(fig:modelResponseCurveLine) presents the profiles corresponding to *age* and *class*. Note that, in the CP profile for *age*, the point of interest is indicated by the black dot. In essence, a CP profile shows a conditional expectation of the dependent variable (response) for the particular explanatory variable.  


```{r modelResponseCurveLine, echo=FALSE, fig.cap="(fig:modelResponseCurveLine) A) Model response (prediction) surface. Ceteris-paribus (CP) profiles marked with black curves help to understand the curvature of the surface while changing only a single explanatory variable. B) CP profiles for individual variables, age (continuous) and class (categorical).", out.width = '70%', fig.align='center'}
knitr::include_graphics("figure/profile_age_class.png")
```

CP technique is similar to the LIME method (see Chapter \@ref(LIME)). LIME and CP profiles examine the curvature of a model response-surface. The difference between these two methods lies in the fact that LIME approximates the black-box model of interest locally with a simpler white-box model. Usually, the LIME model is sparse, i.e., contains fewer variables, and thus we have got to graphically investigate a smaller number of dimensions. On the other hand, the CP profiles present conditional predictions for every variable and, in most cases, are easier to interpret. 

## Method {#CPMethod}

In this section we introduce more formally one-dimensional CP profiles. 

In predictive modeling, we are interested a distribution of a dependent variable $Y$ given vector $x^*$ that contains the values of explanatory variables. In the ideal world we would like to know the conditional distribution of $Y$ given $x^*$, $Y | x^*$. In practical applications we usually do not predict the entire distribution, but just some of its characteristics like the expected (mean) value, a quantile, or variance. Without loss of generality we will assume that we model the expected value $E_Y(Y | x^*)$.

Assume that we have got model $f()$, for which $f(x^*)$ is an approximation of $E_Y(Y | x^*)$, i.e., $E_Y(Y | x^*) \approx f(x^*)$. Note that we do not assume that it is a "good" model, nor that the approximation is precise. We simply assume that we have got a model that is used to estimate the expected value and that to form predictions of the dependent variable. Our interest lies in the evaluation of the quality of the predictions. If the model offers a "good" approximation of the expected value, it should be reflected in its satisfactory predictive performance. 

<<<<<<< HEAD
We will use subscript $x^*_i$ to refer to the vector corresponding to the $i$-th observation in a dataset. We will use superscript $x^{*j}$ to refer to the $j$-th element of $x^*$, i.e., the $j$-th variable. Additionally, let $x^{*-j}$ denote a vector resultinig from removing the $j$-th element from vector $x^{*}$. Moreover, let $x^{*|j}=z$ denote a vector in which the $j$-th element is equal to $z$ (a scalar). 
=======
We will use subscript $x^*_i$ to refer to the vector corresponding to the $i$-th observation in a dataset. We will use superscript $x^{*j}$ to refer to the $j$-th element of $x^*$, i.e., the $j$-th variable. Additionally, let $x^{*-j}$ denote a vector resulting from removing the $j$-th element from vector $x^{*}$. Moreover, let $x^{*|j}=z$ denote a vector in which the $j$-th element is equal to $z$ (a scalar). 
>>>>>>> 898a606cf7f177f6aeecac8c3b804ff1082ee50e

We define a one-dimensional CP profile for the model $f()$, $j$-th explanatory variable, and point $x^*$ as follows:

$$
CP^{f, j, x^*}(z) \equiv f(x^{*|j} = z).
$$
That is, CP profile is a function that provides the dependence of the approximated expected value (prediction) of the model for $Y$ on the value of $j$-th explanatory variable $z$. Note that $z$ is taken to go through the range of values typical for the variable, while values of all other explanatory variables are kept fixed at the values given by $x^*$. 

## Example: Titanic data {#CPExample}

For continuous explanatory variables, a natural way to represent the CP function is to use a profile plot similar to the ones presented in Figure \@ref(fig:profileAgeRf). In the figure, the dot on the curves marks an instance prediction, i.e., prediction $f(x^*)$ for a single observation $x^*$. The curve itself shows how the prediction would change if the value of a particular explanatory variable changed. 

Figure \@ref(fig:profileAgeRf) presents CP profiles for the *age* variable in the logistic regression and random forest models for the Titanic dataset (see Section \@ref(HFDataset)). It is worth observing that the profile for the logistic regression model is smooth, while for the random forest model it shows more variability. For this instance (observation), the prediction for both models would increase substantially if the value of the explanatory variable became lower than 20.

```{r profileAgeRf, echo=FALSE, fig.cap="(fig:profileAgeRf) Ceteris-paribus profiles for variable `age` for the logistic regression (`titanic_lmr_v6`) and random forest (`titanic_rf_v6` ) models that predict the probability of surviving based on the Titanic data", out.width = '70%', fig.align='center'}
knitr::include_graphics("figure/profile_age_rf.png")
```

For a categorical explanatory variable, a natural way to represent the CP function is to use a barplot similar to  the ones presented in Figure \@ref(fig:profileAgeRf2). The barplots in Figure \@ref(fig:profileAgeRf) present CP profiles for the *class* variable in the logistic regression and random forest models for the Titanic dataset (see Section \@ref(HFDataset)). For this instance (observation), the predicted probability for the logistic regression model would decrease substantially if the value of *class* changed to "2nd". On the other hand, for the random forest model, the largest change would be marked if *class* changed to "restaurant staff".

```{r profileAgeRf2, echo=FALSE, fig.cap="(fig:profileAgeRf2) Ceteris-paribus profiles for variable `class` for the logistic regression (`titanic_lmr_v6`) and random forest (`titanic_rf_v6` ) models that predict the probability of surviving based on the Titanic data", out.width = '70%', fig.align='center'}
knitr::include_graphics("figure/profile_class_rf.png")
```

Usually, black-box models contain a large number of explanatory variables. However, CP profiles are legible even for tiny subplots, created with techniques like sparklines or small multiples [@Tufte1986]. In this way we can display a large number of profiles at the same time keeping profiles for consecutive variables in separate panels, as shown in Figure \@ref(fig:profileV4Rf) for the random forest model for the Titanic dataset. It helps if these panels are ordered so that the most important profiles are listed first. We discuss a method to assess the importance of CP profiles in the next chapter.

```{r profileV4Rf, echo=FALSE, fig.cap="(fig:profileV4Rf) Ceteris-paribus profiles for all continuous explanatory variables for the random forest (`titanic_rf_v6`) model for the `titanic` dataset", out.width = '70%', fig.align='center'}
knitr::include_graphics("figure/profile_v4_rf3.png")
```


## Pros and cons {#CPProsCons}

One-dimensional CP profiles, as presented in this chapter, offer a uniform, easy to communicate and extendable approach to model exploration. Their graphical representation is easy to understand and explain. It is possible to show profiles for many variables or models in a single plot.

There are several issues related to the use of the CP profiles. If explanatory variables are correlated, then changing one variable implies a change in the other. In such case, the application of the *Ceteris paribus* principle may lead to unrealistic settings, as it is not possible to keep one variable fixed while varying the other one. Special cases are interactions, which require the use of two-dimensional CP profiles that are more complex than one-dimensional ones. Also, in case of a model with hundreds or thousands of variables, the number of plots to inspect may be daunting. Finally, while barplots allow visualization of CP profiles for factors (categorical explanatory variables), their use becomes less trivial in case of factors with many nominal (unordered) categories (like, for example, a ZIP-code). 

## Code snippets for R {#CPR}

In this section we present key features of the R package `ingredients` [@ingredientsRPackage] which is a part of `DrWhy.AI` universe and covers all methods presented in this chapter. More details and examples can be found at https://modeloriented.github.io/ingredients/.

Note that there are also other R packages that offer similar functionality, like `condvis` [@JSSv081i05], `pdp` [@pdpRPackage], `ICEbox` [@ICEboxRPackage], `ALEPlot` [@ALEPlotRPackage], `iml` [@imlRPackage].

In this section, we use two classification models developed in the chapter \@ref(TitanicDataset), namely logistic regression [@rms] model `titanic_lmr_v6` and the random forest [@R-randomForest] model `titanic_rf_v6`. They are trained to predict probability of survival from sinking of Titanic. Instance level explanations are calculated for a single observation `henry` - 47 years old passenger that travels 1st class.

`DALEX` explainers for both models and the Henry data are retrieved via `archivist` hooks as listed in Chapter \@ref(ListOfModelsTitanic). 

```{r, warning=FALSE, message=FALSE, eval=FALSE}
library("rms")
explain_lmr_v6 <- archivist::aread("pbiecek/models/2b9b6")

library("randomForest")
explain_rf_v6 <- archivist::aread("pbiecek/models/9b971")

library("DALEX")
henry <- archivist::aread("pbiecek/models/a6538")
henry
```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
library("rms")
library("randomForest")
library("DALEX")
load("models/explain_lmr_v6.rda")
load("models/explain_rf_v6.rda")
load("models/henry.rda")
henry
```

### Basic usage for the `ceteris_paribus` function

The easiest way to create and plot Ceteris Paribus profiles is to call `ceteris_paribus()` function and then the generic `plot()` function. By default profiles for all variables are being calculated and all numeric features are being plotted. One can limit the number of variables that should be considered with the `variables` argument. 

To obtain CP profiles, we use the `ceteris_paribus()` function. It requires the explainer-object and the instance data frame as arguments. 

As a result, the function yields an object od the class `ceteris_paribus_explainer`. It is a data frame with model predictions.

```{r, warning=FALSE, message=FALSE}
library("ingredients")
cp_titanic_lmr <- ceteris_paribus(explain_lmr_v6, henry)
cp_titanic_lmr
```

To obtain a graphical representation of CP profiles, the generic `plot()` function can be applied to the data frame returned by the `ceteris_paribus()` function. It returns a `ggplot2` object that can be processed further if needed. In examples below we use `ggplot2` functions like `ggtitle()` or `ylim()` to modify plot's title or range of OY axis.

The resulting plot can be enriched with additional data by applying functions `ingredients::show_rugs()` (adds rugs for the selected points), `ingredients::show_observations` (adds dots that shows observations), or `ingredients::show_aggreagated_profiles` (see Chapter  \@ref(variableEngeneering)). All these functions can take additional arguments to modify size, color or linetype.

Below we show an R snippet that can be used to replicate plots presented in the left panel of Figure \@ref(fig:profileAgeRf).

```{r titanicCeterisProfile01, warning=FALSE, message=FALSE,  fig.width=7, fig.height=4, fig.cap="Ceteris-paribus profiles for `age` and `fare` variables and the `titanic_lmr_v6` model.", out.width = '70%', fig.align='center'}
library("ggplot2")
plot(cp_titanic_lmr, variables = c("age", "fare")) +
  show_observations(cp_titanic_lmr, variables = c("age", "fare")) +
  ggtitle("Ceteris Paribus Profiles", "For the logistic regression model and titanic dataset")
```

By default all numerical variables are plotted. For categorical variables we use bar plots instead of line plots. Default `ggplot2` plots cannot handle facets with different geoms, and for this reason we need to plot categorical variables separately.

To plot CP profiles for categorical variables we need to add the `only_numerical = FALSE` argument to the `plot()` function.

Here we recreate plot from Figure \@ref(fig:profileAgeRf2).

```{r titanicCeterisProfile01B, warning=FALSE, message=FALSE, fig.width=7, fig.height=4, fig.cap="Ceteris-paribus profiles for `class` and `embarked` variables and the `titanic_lmr_v6` model.", out.width = '70%', fig.align='center'}
plot(cp_titanic_lmr, variables = c("class", "embarked"), only_numerical = FALSE) +
  ggtitle("Ceteris Paribus Profiles", "For the logistic regression model and titanic dataset")
```


### Advanced usage for the `ceteris_paribus` function

The `ceteris_paribus()` is a very flexible function. To better understand how it can be used let's scan it's arguments.

* `x`, `data`, `predict_function`, `label` - information about a model. If `x` is created with the `DALEX::explain` function then other arguments are extracted from `x`, this is how we use this function in this chapter. Otherwise we need to specify directly model, validation data, predict function and the model label.
* `new_observation` - instances, one or more, for which we want to calculate CP profiles. It should be a data frame with same variables as in the validation data.
* `y` - observed labels for `new_observation`. We will show how to make use of this argument in the chapter  \@ref(cPLocDiagIntro), 
* `variables` - names of variables for which Ceteris Paribus profiles shall be calculated. By default they will be calculated for all variables, which may be time consuming.
* `variable_splits` - it's a list which specifies for what values Ceteris Paribus shall be calculated. By default these are all values for categorical variables. For continuous variables they are uniformly placed values and one can specify how many with the `grid_points` argument (default is 101).

In the example below we replicate plot \@ref(fig:profileV4Rf) for `henry` and the random forest model `titanic_rf_v6`.

The argument `variable_splits` specifies for which variables (here `age` and `fare`) CP profiles are to be calculated and in which points they shall be evaluated. 

```{r, warning=FALSE, message=FALSE}
cp_titanic_rf <- ceteris_paribus(explain_rf_v6, henry,
              variable_splits = list(age = seq(0, 70, 0.1),
                                     fare = seq(0, 100, 0.1)))
```

Random Forest model is especially interesting case for such investigations, as the CP profiles are piece-wise constant. Moreover, as we see below, some profiles are quite unstable.

```{r titanicCeterisProfile01C, warning=FALSE, message=FALSE, fig.width=7, fig.height=4, fig.cap="Ceteris-paribus profiles for `class` and `embarked` variables and the `titanic_rf_v6` model. Blue dot stands for `henry`.", out.width = '70%', fig.align='center'}
plot(cp_titanic_rf) + 
  show_observations(cp_titanic_rf, variables = c("age", "fare"), size = 5) + 
  ylim(0, 1) +
  ggtitle("Ceteris Paribus Profiles", "For the random forest model and titanic dataset")
```

There are few functions that one can use. The generic `plot` creates a `ggplot2` object with a single `geom_line` layer. Function `show_observations` adds `geom_point` layer, `show_rugs` adds `geom_rugs` while `show_profiles` adds another `geom_line`. All these functions take as the first argument an object created with `ceteris_paribus` function. They can be combined freely combined to superpose profiles for different models or observations.

In the example below we create profiles for two passengers, `henry` and `johny_d`. Their profiles are plot in a single chart \@ref(fig:titanicCeterisProfile01D). We add `scale_color_manual` function to add names of passengers to the plot, control colors and positions.


```{r, warning=FALSE, message=FALSE, eval=FALSE}
johny_d <- archivist::aread("pbiecek/models/e3596")
cp_titanic_rf2 <- ceteris_paribus(explain_rf_v6, rbind(henry, johny_d))
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
load("models/johny_d.rda")
variable_splits = list(age = seq(0, 70, 0.1), fare = seq(0, 100, 0.1))

cp_titanic_rf2 <- ceteris_paribus(explain_rf_v6, 
              rbind(henry, johny_d), variable_splits = variable_splits)
```


```{r titanicCeterisProfile01D, warning=FALSE, message=FALSE, fig.width=7, fig.height=4, fig.cap="Ceteris-paribus profiles for the `titanic_rf_v6` model. Profiles for different passangers are color-coded.", out.width = '70%', fig.align='center'}
plot(cp_titanic_rf2, color = "_ids_") + 
  show_observations(cp_titanic_rf2, size = 5, variables = c("age", "fare")) + 
  show_rugs(cp_titanic_rf2, sides = "bl", variables = c("age", "fare")) + 
  scale_color_manual(name = "Passenger:", breaks = 1:2, values = c("#4378bf", "#8bdcbe"), labels = c("henry" , "johny_d")) + 
  ggtitle("Ceteris Paribus Profiles", "For the random forest model and titanic dataset")
```

### Champion-challenger analysis

One of the most interesting use cases for explainers is contrastive comparison of two or larger number of models.

Let's see how to do this. First we calculate profiles for two models. We can do this for larger number of models, here we limit to two models for larger clarity.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
cp_titanic_rf <- ceteris_paribus(explain_rf_v6, henry, variable_splits = variable_splits)
cp_titanic_lmr <- ceteris_paribus(explain_lmr_v6, henry, variable_splits = variable_splits)
```
```{r, warning=FALSE, message=FALSE, eval=FALSE}
cp_titanic_rf <- ceteris_paribus(explain_rf_v6, henry)
cp_titanic_lmr <- ceteris_paribus(explain_lmr_v6, henry)
```

Every `plot` and `show_*` function can take a collection of explainers as arguments. Profiles for different models will be plot in a single chart. Here models are color-coded as we set argument `color = "_label_"`. Here `_label_` is the name of a column in CP explainer that contains information about model label.

Figure \@ref(fig:titanicCeterisProfile01E) shows differences between CP profiles for both considered models.

```{r titanicCeterisProfile01E, warning=FALSE, message=FALSE, fig.width=7, fig.height=4, fig.cap="Champion-challenger comparison of `titanic_lmr_v6` and `titanic_rf_v6` models. Profiles for different models are color-coded.", out.width = '70%', fig.align='center'}
plot(cp_titanic_rf, cp_titanic_lmr, color = "_label_") +
  show_observations(cp_titanic_rf, cp_titanic_lmr, color = "black", variables = c("age", "fare"), size = 5) +
  scale_color_discrete(name = "Selected models:") + ylim(0,1) + 
  ggtitle("Ceteris Paribus Profiles for Henry")
```

