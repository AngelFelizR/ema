# Feature Importance {#variableImportance}

Methods presented in this chapter are useful for estimation of feature importance. There is many possible applications of such methods, for example:
  
* feature importance may be used for filtering. Features that were not important may be removed from the data before next iteration of model fitting. Removal of the noise shall lead to a better model. 
* identification of the most important features may be used as a validation of a model against domain knowledge. Just to make sure that it's not like a single random feature dominates model predictions.
* identification of the most important features may increase the domain knowledge.
* comparison of feature importance between different models helps to understand how different models handle particular features.


There are many methods for feature importance. In general we may divide them into two groups, methods that are model specific and methods that are model agnostic.

Methods like random forest, extreme gradient boosting, linear models and many others have their own ways to assess feature importance. But in this chapter we will focus on methods that are model agnostic. The may reason for that is 

* first, be able to apply this method to any predictive model, 
* second, (which is maybe even more important) to be able to compare methods between models of different structure.

Model agnostic methods cannot assume anything about the model structure and we do not want to refit a model. The method that is presented below is described in details in the [@variableImportancePermutations]. 
The main idea is to measure how much the model fit will decrease if a selected feature or group of features will be cancelled out. Here cancellation means perturbations like resampling from empirical distribution of just permutation.

The method can be used to measure importance of single features, pairs or larger subsets. For the simplicity below we describe algorithm for single features, but it is straight forward to use it for larger subsets of features.

## The Algorithm for Model Agnostic Variable Importance Assessment

Let $\mathcal L(M(X), y)$ be a loss function that calculates goodness of fit of a model predictions calculated for data $X$ and target $y$. 

1. Let $\mathcal F$ be a set of features, for each feature $f \in \mathcal F$ do steps 2-5
2. Create a new data $X^{-f}$ with feature $f$ resampled.
3. Calculate model predictions for the new data $X^{f*}$, they will be denoted as $M(X^{-f})$.
4. Calculate loss function for models predictions on perturbed data 
$$
L^{-f} = \mathcal L(M(X^{-f}), y)
$$
5. Feature importance may be calculated as difference or ration of the original loss and loss on perturbed data, i.e. $fip(f) = L^f - L$ or $fip(f) = L^f/L$. 

Note that ranking of feature importance will be the same for the difference and the ratio since the loss $L$ is the same.

As we will see below, on diagnostic plot it may be more useful to present loss functions for perturbed data rather than direct feature importance.

## Example: Price prediction

Let's create a regression model for prediction of apartment prices.

```{r, warning=FALSE, message=FALSE}
library("DALEX")
library("randomForest")
set.seed(59)
model_rf <- randomForest(m2.price ~ construction.year + surface + floor + 
                           no.rooms + district, data = apartments)
```

A popular loss function for regression model is the root mean square loss
$$
  L(x, y) = \sqrt{\frac1n \sum_{i=1}^n (x_i - y_i)^2}
$$
  
  ```{r, warning=FALSE, message=FALSE}
loss_root_mean_square(
  predict(model_rf, apartments), 
  apartments$m2.price
)
```

Let's calculate feature importances

```{r, warning=FALSE, message=FALSE}
explainer_rf <- explain(model_rf, 
            data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
vip <- variable_importance(explainer_rf, 
            loss_function = loss_root_mean_square)
vip
```

On a diagnostic plot is useful to present feature importance as an interval that start in a loss and ends in a loss of perturbed data.

```{r, warning=FALSE, message=FALSE}
plot(vip)
```

## More models

Much more can be read from feature importance plots if we compare models of a different structure.
Let's train three predictive models trained on `apartments` dataset from the `DALEX` package. Random Forest model [@R-randomForest] (elastic but biased), Support Vector Machines model [@R-e1071] (large variance on boundaries) and Linear Model (stable but not very elastic). 
Presented examples are for regression (prediction of square meter price), but the CP profiles may be used in the same way for classification.

Let's fit these three models. 

```{r, warning=FALSE, message=FALSE}
library("DALEX")
model_lm <- lm(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)

library("randomForest")
set.seed(59)
model_rf <- randomForest(m2.price ~ construction.year + surface + floor + 
                      no.rooms + district, data = apartments)

library("e1071")
model_svm <- svm(m2.price ~ construction.year + surface + floor + 
                         no.rooms + district, data = apartments)
```

For these models we use `DALEX` explainers created with `explain()` function. These explainers wrap models, predict functions and validation data.

```{r, warning=FALSE, message=FALSE}
explainer_lm <- explain(model_lm, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
vip_lm <- variable_importance(explainer_lm, 
            loss_function = loss_root_mean_square)
vip_lm

explainer_rf <- explain(model_rf, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
vip_rf <- variable_importance(explainer_rf, 
            loss_function = loss_root_mean_square)
vip_rf

explainer_svm <- explain(model_svm, 
                       data = apartmentsTest[,2:6], y = apartmentsTest$m2.price)
vip_svm <- variable_importance(explainer_svm, 
            loss_function = loss_root_mean_square)
vip_svm
```

Let's plot feature importance for all three models on a single plot.

Intervals start in a different values, thus we can read that loss for SVM model is the lowest.

When we compare other features it looks like in all models the `district` is the most important feature followed by `surface` and `floor`. 

```{r, warning=FALSE, message=FALSE}
plot(vip_rf, vip_svm, vip_lm)
```

There is interesting difference between linear model and others in the way how important is the `construction.year`. For linear model this variable is not importance, while for remaining two models there is some importance.

In the next chapter we will see how this is possible.



