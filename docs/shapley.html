<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>8 Shapley Additive Explanations (SHAP) for Average Attributions | Explanatory Model Analysis</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="8 Shapley Additive Explanations (SHAP) for Average Attributions | Explanatory Model Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="figure/front4.png" />
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="8 Shapley Additive Explanations (SHAP) for Average Attributions | Explanatory Model Analysis" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="twitter:image" content="figure/front4.png" />

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-12-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="iBreakDown.html"/>
<link rel="next" href="LIME.html"/>
<script src="libs/header-attrs-2.4/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain, and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.1</b> The aim of the book</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.2</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#teminology"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#glassblack"><i class="fa fa-check"></i><b>1.4</b> Black-box models and glass-box models</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#agnosticspecific"><i class="fa fa-check"></i><b>1.5</b> Model-agnostic and model-specific approach</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.6</b> The structure of the book</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#whatisinthebook"><i class="fa fa-check"></i><b>1.7</b> What is included in this book and what is not</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.8</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> Model-development process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#dataunderstanding"><i class="fa fa-check"></i><b>2.4</b> Data understanding</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#fitting"><i class="fa fa-check"></i><b>2.5</b> Model assembly (fitting)</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#validation"><i class="fa fa-check"></i><b>2.6</b> Model audit</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="do-it-yourself.html"><a href="do-it-yourself.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself</a>
<ul>
<li class="chapter" data-level="3.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#doItYourselfWithR"><i class="fa fa-check"></i><b>3.1</b> Do-it-yourself with R</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#what-to-install"><i class="fa fa-check"></i><b>3.1.1</b> What to install?</a></li>
<li class="chapter" data-level="3.1.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#infoDALEX"><i class="fa fa-check"></i><b>3.1.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.1.3" data-path="do-it-yourself.html"><a href="do-it-yourself.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.1.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#doItYourselfWithPython"><i class="fa fa-check"></i><b>3.2</b> Do-it-yourself with Python</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#what-to-install-1"><i class="fa fa-check"></i><b>3.2.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#infoDALEXpy"><i class="fa fa-check"></i><b>3.2.2</b> How to work with <code>dalex</code>?</a></li>
<li class="chapter" data-level="3.2.3" data-path="do-it-yourself.html"><a href="do-it-yourself.html#code-snippets-for-python"><i class="fa fa-check"></i><b>3.2.3</b> Code snippets for Python</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>4</b> Datasets and Models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>4.1</b> Sinking of the RMS Titanic</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>4.1.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-rms-titanic-snippets-for-r"><i class="fa fa-check"></i><b>4.2</b> Models for RMS Titanic, snippets for R</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>4.2.1</b> Logistic regression model</a></li>
<li class="chapter" data-level="4.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>4.2.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>4.2.3</b> Gradient boosting model</a></li>
<li class="chapter" data-level="4.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>4.2.4</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>4.2.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>4.2.6</b> Models’ explainers</a></li>
<li class="chapter" data-level="4.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>4.2.7</b> List of model-objects</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-rms-titanic-snippets-for-python"><i class="fa fa-check"></i><b>4.3</b> Models for RMS Titanic, snippets for Python</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-lr"><i class="fa fa-check"></i><b>4.3.1</b> Logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-rf"><i class="fa fa-check"></i><b>4.3.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.3.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-gbm"><i class="fa fa-check"></i><b>4.3.3</b> Gradient boosting model</a></li>
<li class="chapter" data-level="4.3.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-svm"><i class="fa fa-check"></i><b>4.3.4</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.3.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic-python"><i class="fa fa-check"></i><b>4.3.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.3.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicPythonCode"><i class="fa fa-check"></i><b>4.3.6</b> Models’ explainers</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>4.4</b> Apartment prices</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>4.4.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-apartment-prices-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Models for apartment prices, snippets for R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>4.5.1</b> Linear regression model</a></li>
<li class="chapter" data-level="4.5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>4.5.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.5.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>4.5.3</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.5.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>4.5.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.5.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>4.5.5</b> Models’ explainers</a></li>
<li class="chapter" data-level="4.5.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>4.5.6</b> List of model-objects</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-apartment-prices-snippets-for-python"><i class="fa fa-check"></i><b>4.6</b> Models for apartment prices, snippets for Python</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-lr"><i class="fa fa-check"></i><b>4.6.1</b> Linear regression model</a></li>
<li class="chapter" data-level="4.6.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-rf"><i class="fa fa-check"></i><b>4.6.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.6.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-svm"><i class="fa fa-check"></i><b>4.6.3</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.6.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-apartments-python"><i class="fa fa-check"></i><b>4.6.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.6.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsPythonCode"><i class="fa fa-check"></i><b>4.6.5</b> Models’ explainers</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Instance Level</b></span></li>
<li class="chapter" data-level="5" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>5</b> Introduction to Instance-level Exploration</a></li>
<li class="chapter" data-level="6" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>6</b> Break-down Plots for Additive Attributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="breakDown.html"><a href="breakDown.html#BDIntroduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>6.3</b> Method</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="breakDown.html"><a href="breakDown.html#BDMethodLin"><i class="fa fa-check"></i><b>6.3.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="6.3.2" data-path="breakDown.html"><a href="breakDown.html#BDMethodGen"><i class="fa fa-check"></i><b>6.3.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>6.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="6.5" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>6.5</b> Pros and cons</a></li>
<li class="chapter" data-level="6.6" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>6.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>6.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="6.6.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>6.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="breakDown.html"><a href="breakDown.html#BDPython"><i class="fa fa-check"></i><b>6.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Interactions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a></li>
<li class="chapter" data-level="7.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a></li>
<li class="chapter" data-level="7.6" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDPythonCode"><i class="fa fa-check"></i><b>7.6</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>8</b> Shapley Additive Explanations (SHAP) for Average Attributions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
<li class="chapter" data-level="8.6" data-path="shapley.html"><a href="shapley.html#SHAPPythonCode"><i class="fa fa-check"></i><b>8.6</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>9</b> Local Interpretable Model-agnostic Explanations (LIME)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>9.2</b> Intuition</a></li>
<li class="chapter" data-level="9.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>9.3</b> Method</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="LIME.html"><a href="LIME.html#LIMErepr"><i class="fa fa-check"></i><b>9.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="9.3.2" data-path="LIME.html"><a href="LIME.html#LIMEsample"><i class="fa fa-check"></i><b>9.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="9.3.3" data-path="LIME.html"><a href="LIME.html#LIMEglas"><i class="fa fa-check"></i><b>9.3.3</b> Fitting the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>9.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>9.5</b> Pros and cons</a></li>
<li class="chapter" data-level="9.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>9.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="LIME.html"><a href="LIME.html#LIMERcodelime"><i class="fa fa-check"></i><b>9.6.1</b> The <code>lime</code> package</a></li>
<li class="chapter" data-level="9.6.2" data-path="LIME.html"><a href="LIME.html#LIMERcodelocMod"><i class="fa fa-check"></i><b>9.6.2</b> The <code>localModel</code> package</a></li>
<li class="chapter" data-level="9.6.3" data-path="LIME.html"><a href="LIME.html#LIMERcodeiml"><i class="fa fa-check"></i><b>9.6.3</b> The <code>iml</code> package</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="LIME.html"><a href="LIME.html#LIMEPythoncode"><i class="fa fa-check"></i><b>9.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>10</b> Ceteris-paribus Profiles</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a></li>
<li class="chapter" data-level="10.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-predict_profile-function"><i class="fa fa-check"></i><b>10.6.1</b> Basic use of the <code>predict_profile()</code> function</a></li>
<li class="chapter" data-level="10.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-predict_profile-function"><i class="fa fa-check"></i><b>10.6.2</b> Advanced use of the <code>predict_profile()</code> function</a></li>
<li class="chapter" data-level="10.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#comparison-of-models-champion-challenger"><i class="fa fa-check"></i><b>10.6.3</b> Comparison of models (champion-challenger)</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPPython"><i class="fa fa-check"></i><b>10.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Oscillations</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-predict_parts-function-1"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-predict_parts-function-1"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscPython"><i class="fa fa-check"></i><b>11.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>12</b> Local-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="12.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagneighbours"><i class="fa fa-check"></i><b>12.3.1</b> Nearest neighbours</a></li>
<li class="chapter" data-level="12.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>12.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="12.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>12.3.3</b> Local-stability plot</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="12.7" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagPython"><i class="fa fa-check"></i><b>12.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>13</b> Summary of Instance-level Exploration</a>
<ul>
<li class="chapter" data-level="13.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#summaryInstanceLevelIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>13.2</b> Number of explanatory variables in the model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-a-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.2</b> Medium to a large number of explanatory variables</a></li>
<li class="chapter" data-level="13.2.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>13.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="13.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>13.4</b> Models with interactions</a></li>
<li class="chapter" data-level="13.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>13.5</b> Sparse explanations</a></li>
<li class="chapter" data-level="13.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>13.6</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="13.7" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#comparison-of-models-champion-challenger-analysis"><i class="fa fa-check"></i><b>13.7</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="part"><span><b>III Dataset Level</b></span></li>
<li class="chapter" data-level="14" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>14</b> Introduction to Dataset-level Exploration</a></li>
<li class="chapter" data-level="15" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>15</b> Model-performance Measures</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>15.2</b> Intuition</a></li>
<li class="chapter" data-level="15.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>15.3</b> Method</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>15.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="15.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>15.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="15.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>15.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="15.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>15.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>15.4</b> Example</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>15.4.1</b> Apartment prices</a></li>
<li class="chapter" data-level="15.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>15.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>15.5</b> Pros and cons</a></li>
<li class="chapter" data-level="15.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>15.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="15.7" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformancePython"><i class="fa fa-check"></i><b>15.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>16</b> Variable-importance Measures</a>
<ul>
<li class="chapter" data-level="16.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a></li>
<li class="chapter" data-level="16.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>16.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="16.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="16.7" data-path="featureImportance.html"><a href="featureImportance.html#featureImportancePython"><i class="fa fa-check"></i><b>16.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>17</b> Partial-dependence Profiles</a>
<ul>
<li class="chapter" data-level="17.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPs"><i class="fa fa-check"></i><b>17.3.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clusteredPDPs"><i class="fa fa-check"></i><b>17.3.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#groupedPDPs"><i class="fa fa-check"></i><b>17.3.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastivePDPs"><i class="fa fa-check"></i><b>17.3.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>17.4</b> Example: apartment-prices data</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPPython"><i class="fa fa-check"></i><b>17.7</b> Code snippets for Python</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-2"><i class="fa fa-check"></i><b>17.7.1</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.7.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-2"><i class="fa fa-check"></i><b>17.7.2</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>18</b> Local-dependence and Accumulated-local Profiles</a>
<ul>
<li class="chapter" data-level="18.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#local-dependence-profile"><i class="fa fa-check"></i><b>18.3.1</b> Local-dependence profile</a></li>
<li class="chapter" data-level="18.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>18.3.2</b> Accumulated-local profile</a></li>
<li class="chapter" data-level="18.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#dependence-profiles-for-a-model-with-interaction-and-correlated-explanatory-variables-an-example"><i class="fa fa-check"></i><b>18.3.3</b> Dependence profiles for a model with interaction and correlated explanatory variables: an example</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: apartment-prices data</a></li>
<li class="chapter" data-level="18.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="18.7" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPPython"><i class="fa fa-check"></i><b>18.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>19</b> Residual-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="19.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntroResidualDiagnostic"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntuitionResidualDiagnostic"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#MethodResidualDiagnostic"><i class="fa fa-check"></i><b>19.3</b> Method</a></li>
<li class="chapter" data-level="19.4" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ExampleResidualDiagnostic"><i class="fa fa-check"></i><b>19.4</b> Example: apartment-prices data</a></li>
<li class="chapter" data-level="19.5" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ProsConsResidualDiagnostic"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#RcodeResidualDiagnostic"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="19.7" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#PythoncodeResidualDiagnostic"><i class="fa fa-check"></i><b>19.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html"><i class="fa fa-check"></i><b>20</b> Summary of Dataset-level Exploration</a>
<ul>
<li class="chapter" data-level="20.1" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#summaryModelLevelIntro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#exploration-on-trainingtesting-data"><i class="fa fa-check"></i><b>20.2</b> Exploration on training/testing data</a></li>
<li class="chapter" data-level="20.3" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#correlated-explanatory-variables-1"><i class="fa fa-check"></i><b>20.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="20.4" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#comparison-of-models-champion-challenger-analysis-1"><i class="fa fa-check"></i><b>20.4</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="part"><span><b>IV Use-cases</b></span></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a>
<ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAintro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAdataprep"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r"><i class="fa fa-check"></i><b>21.2.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.2.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-1"><i class="fa fa-check"></i><b>21.2.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAdataunderst"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelassembly"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>21.4.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.4.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-2"><i class="fa fa-check"></i><b>21.4.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelaudit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>21.5.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.5.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-3"><i class="fa fa-check"></i><b>21.5.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelunderst"><i class="fa fa-check"></i><b>21.6</b> Model understanding (dataset-level explanations)</a>
<ul>
<li class="chapter" data-level="21.6.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>21.6.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.6.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-4"><i class="fa fa-check"></i><b>21.6.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAinstanceunderst"><i class="fa fa-check"></i><b>21.7</b> Instance-level explanations</a>
<ul>
<li class="chapter" data-level="21.7.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFALewy"><i class="fa fa-check"></i><b>21.7.1</b> Robert Lewandowski</a></li>
<li class="chapter" data-level="21.7.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>21.7.2</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.7.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-5"><i class="fa fa-check"></i><b>21.7.3</b> Code snippets for Python</a></li>
<li class="chapter" data-level="21.7.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFACR7"><i class="fa fa-check"></i><b>21.7.4</b> CR7</a></li>
<li class="chapter" data-level="21.7.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFASzczesny"><i class="fa fa-check"></i><b>21.7.5</b> Wojciech Szczęsny</a></li>
<li class="chapter" data-level="21.7.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAMessi"><i class="fa fa-check"></i><b>21.7.6</b> Lionel Messi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>22</b> Reproducibility</a>
<ul>
<li class="chapter" data-level="22.1" data-path="reproducibility.html"><a href="reproducibility.html#package-versions-for-r"><i class="fa fa-check"></i><b>22.1</b> Package versions for R</a></li>
<li class="chapter" data-level="22.2" data-path="reproducibility.html"><a href="reproducibility.html#package-versions-for-python"><i class="fa fa-check"></i><b>22.2</b> Package versions for Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Explanatory Model Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="shapley" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Shapley Additive Explanations (SHAP) for Average Attributions</h1>
<p>In Chapter <a href="breakDown.html#breakDown">6</a>, we introduced break-down (BD) plots, a procedure for calculation of attribution of an explanatory variable for a model’s prediction. We also indicated that, in the presence of interactions, the computed value of the attribution depends on the order of explanatory covariates that are used in calculations. One solution to the problem, presented in Chapter <a href="breakDown.html#breakDown">6</a>, is to find an ordering in which the most important variables are placed at the beginning. Another solution, described in Chapter <a href="iBreakDown.html#iBreakDown">7</a>, is to identify interactions and explicitly present their contributions to the predictions.</p>
<p>In this chapter, we introduce yet another approach to address the ordering issue. It is based on the idea of averaging the value of a variable’s attribution over all (or a large number of) possible orderings. The idea is closely linked to “Shapley values” developed originally for cooperative games <span class="citation">(Shapley <a href="#ref-shapleybook1952" role="doc-biblioref">1953</a>)</span>. The approach was first translated to the machine-learning domain by <span class="citation">Štrumbelj and Kononenko (<a href="#ref-imeJLMR" role="doc-biblioref">2010</a>)</span> and <span class="citation">Štrumbelj and Kononenko (<a href="#ref-Strumbelj2014" role="doc-biblioref">2014</a>)</span>. It has been widely adopted after the publication of the paper by <span class="citation">Lundberg and Lee (<a href="#ref-SHAP" role="doc-biblioref">2017</a>)</span> and Python’s library for SHapley Additive exPlanations, SHAP <span class="citation">(Lundberg <a href="#ref-shapPackage" role="doc-biblioref">2019</a>)</span>. The authors of SHAP introduced an efficient algorithm for tree-based models <span class="citation">(Lundberg, Erion, and Lee <a href="#ref-TreeSHAP" role="doc-biblioref">2018</a>)</span>. They also showed that Shapley values could be presented as a unification of a collection of different commonly used techniques for model explanations <span class="citation">(Lundberg and Lee <a href="#ref-SHAP" role="doc-biblioref">2017</a>)</span>.</p>
<div id="SHAPIntuition" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Intuition</h2>
<p>Figure <a href="shapley.html#fig:shap10orderings">8.1</a> presents BD plots for 10 random orderings (indicated by the order of the rows in each plot) of explanatory variables for the prediction for Johnny D (see Section <a href="dataSetsIntro.html#predictions-titanic">4.2.5</a>) for the random forest model <code>titanic_rf</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>) for the Titanic dataset. The plots show clear differences in the contributions of various variables for different orderings. The most remarkable differences can be observed for variables <em>fare</em> and <em>class</em>, with contributions changing the sign depending on the ordering.</p>

<div class="figure" style="text-align: center"><span id="fig:shap10orderings"></span>
<img src="figure/shap_10_replicates.png" alt="Break-down plots for 10 random orderings of explanatory variables for the prediction for Johnny D for the random forest model titanic_rf for the Titanic dataset. Each panel presents a single ordering, indicated by the order of the rows in the plot." width="100%" />
<p class="caption">
Figure 8.1: Break-down plots for 10 random orderings of explanatory variables for the prediction for Johnny D for the random forest model <code>titanic_rf</code> for the Titanic dataset. Each panel presents a single ordering, indicated by the order of the rows in the plot.
</p>
</div>
<p>To remove the influence of the ordering of the variables, we can compute the mean value of the attributions.
Figure <a href="shapley.html#fig:shapOrdering">8.2</a> presents the averages, calculated over the ten orderings presented in Figure <a href="shapley.html#fig:shap10orderings">8.1</a>. Red and green bars present, respectively, the negative and positive averages Violet box plots summarize the distribution of the attributions for each explanatory variable across the different orderings. The plot indicates that the most important variables, from the point of view of the prediction for Johnny D, are <em>age</em>, <em>class</em>, and <em>gender</em>.</p>

<div class="figure" style="text-align: center"><span id="fig:shapOrdering"></span>
<img src="figure/shap_ordering.png" alt="Average attributions for 10 random orderings. Red and green bars present the means. Box plots summarize the distribution of contributions for each explanatory variable across the orderings." width="80%" />
<p class="caption">
Figure 8.2: Average attributions for 10 random orderings. Red and green bars present the means. Box plots summarize the distribution of contributions for each explanatory variable across the orderings.
</p>
</div>
</div>
<div id="SHAPMethod" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Method</h2>
<p>SHapley Additive exPlanations (SHAP) are based on “Shapley values” developed by <span class="citation">Shapley (<a href="#ref-shapleybook1952" role="doc-biblioref">1953</a>)</span> in the cooperative game theory. Note that the terminology may be confusing at first glance. Shapley values are introduced for cooperative games. SHAP is an acronym for a method designed for predictive models. To avoid confusion, we will use the term “Shapley values”.</p>
<p>Shapley values are a solution to the following problem. A coalition of players cooperates and obtains a certain overall gain from the cooperation. Players are not identical, and different players may have different importance. Cooperation is beneficial, because it may bring more benefit than individual actions. The problem to solve is how to distribute the generated surplus among the players. Shapley values offer one possible fair answer to this question <span class="citation">(Shapley <a href="#ref-shapleybook1952" role="doc-biblioref">1953</a>)</span>.</p>
<p>Let’s translate this problem to the context of a model’s predictions. Explanatory variables are the players, while model <span class="math inline">\(f()\)</span> plays the role of the coalition. The payoff from the coalition is the model’s prediction. The problem to solve is how to distribute the model’s prediction across particular variables?</p>
<p>The idea of using Shapley values for evaluation of local variable-importance was introduced by <span class="citation">Štrumbelj and Kononenko (<a href="#ref-imeJLMR" role="doc-biblioref">2010</a>)</span>. We will define the values using the notation introduced in Section <a href="breakDown.html#BDMethodGen">6.3.2</a>.</p>
<p>Let us consider a permutation <span class="math inline">\(J\)</span> of the set of indices <span class="math inline">\(\{1,2,\ldots,p\}\)</span> corresponding to an ordering of <span class="math inline">\(p\)</span> explanatory variables included in the model <span class="math inline">\(f()\)</span>. Denote by <span class="math inline">\(\pi(J,j)\)</span> the set of the indices of the variables that are positioned in <span class="math inline">\(J\)</span> before the <span class="math inline">\(j\)</span>-th variable. Note that, if the <span class="math inline">\(j\)</span>-th variable is placed as the first, then <span class="math inline">\(\pi(J,j) = \emptyset\)</span>. Consider the model’s prediction <span class="math inline">\(f(\underline{x}_*)\)</span> for a particular instance of interest <span class="math inline">\(\underline{x}_*\)</span>. The Shapley value is defined as follows:</p>
<p><span class="math display" id="eq:SHAP">\[\begin{equation}
\varphi(\underline{x}_*,j) = \frac{1}{p!} \sum_{J} \Delta^{j|\pi(J,j)}(\underline{x}_*),  
\tag{8.1}
\end{equation}\]</span></p>
<p>where the sum is taken over all <span class="math inline">\(p!\)</span> possible permutations (orderings of explanatory variables) and the variable-importance measure <span class="math inline">\(\Delta^{j|J}(\underline{x}_*)\)</span> was defined in equation <a href="breakDown.html#eq:lcondJBD">(6.7)</a> in Section <a href="breakDown.html#BDMethodGen">6.3.2</a>. Essentially, <span class="math inline">\(\varphi(\underline{x}_*,j)\)</span> is the average of the variable-importance measures across all possible orderings of explanatory variables.</p>
<p>It is worth noting that the value of <span class="math inline">\(\Delta^{j|\pi(J,j)}(\underline{x}_*)\)</span> is constant for all permutations <span class="math inline">\(J\)</span> that share the same subset <span class="math inline">\(\pi(J,j)\)</span>. It follows that equation <a href="shapley.html#eq:SHAP">(8.1)</a> can be expressed in an alternative form:</p>
<p><span class="math display" id="eq:SHAP1">\[\begin{eqnarray}
\varphi(\underline{x}_*,j) &amp;=&amp; \frac 1{p!}\sum_{s=0}^{p-1} \sum_{
\substack{
S \subseteq \{1,\ldots,p\}\setminus \{j\} \\ |S|=s
}}  \left\{s!(p-1-s)! \Delta^{j|S}(\underline{x}_*)\right\}\nonumber\\
&amp;=&amp;
\frac 1{p}\sum_{s=0}^{p-1} \sum_{
\substack{
S \subseteq \{1,\ldots,p\}\setminus \{j\} \\ |S|=s
}}  \left\{{{p-1}\choose{s}}^{-1} \Delta^{j|S}(\underline{x}_*)\right\},
\tag{8.2}
\end{eqnarray}\]</span></p>
<p>where <span class="math inline">\(|S|\)</span> denotes the cardinal number (size) of set <span class="math inline">\(S\)</span> and the second sum is taken over all subsets <span class="math inline">\(S\)</span> of explanatory variables, excluding the <span class="math inline">\(j\)</span>-th one, of size <span class="math inline">\(s\)</span>.</p>
<p>Note that the number of all subsets of sizes from 0 to <span class="math inline">\(p-1\)</span> is <span class="math inline">\(2^{p}-1\)</span>, i.e., it is much smaller than number of all permutations <span class="math inline">\(p!\)</span>. Nevertheless, for a large <span class="math inline">\(p\)</span>, it may be feasible to compute Shapley values neither using <a href="shapley.html#eq:SHAP">(8.1)</a> nor <a href="shapley.html#eq:SHAP1">(8.2)</a>. In that case, an estimate based on a sample of permutations may be considered. A Monte Carlo estimator was introduced by <span class="citation">Štrumbelj and Kononenko (<a href="#ref-Strumbelj2014" role="doc-biblioref">2014</a>)</span>. An efficient implementation of computations of Shapley values for tree-based models was used in package SHAP <span class="citation">(Lundberg and Lee <a href="#ref-SHAP" role="doc-biblioref">2017</a>)</span>. </p>
<p>From the properties of Shapley values for cooperative games it follows that, in the context of predictive models, they enjoy the following properties:</p>
<ul>
<li><p>Symmetry: if two explanatory variables <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span> are interchangeable, i.e., if, for any set of explanatory variables <span class="math inline">\(S \subseteq \{1,\dots,p\}\setminus \{j,k\}\)</span> we have got
<span class="math display">\[
\Delta^{j|S}(\underline{x}_*) = \Delta^{k|S}(\underline{x}_*),
\]</span>
then their Shapley values are equal:
<span class="math display">\[
\varphi(\underline{x}_*,j) = \varphi(\underline{x}_*,k).
\]</span></p></li>
<li><p>Dummy feature: if an explanatory variable <span class="math inline">\(j\)</span> does not contribute to any prediction for any set of explanatory variables <span class="math inline">\(S \subseteq \{1,\dots,p\}\setminus \{j\}\)</span>, that is, if
<span class="math display">\[
\Delta^{j|S}(\underline{x}_*) = 0,
\]</span>
then its Shapley value is equal to 0:
<span class="math display">\[
\varphi(\underline{x}_*,j) = 0.
\]</span></p></li>
<li><p>Additivity: if model <span class="math inline">\(f()\)</span> is a sum of two other models <span class="math inline">\(g()\)</span> and <span class="math inline">\(h()\)</span>, then the Shapley value calculated for model <span class="math inline">\(f()\)</span> is a sum of Shapley values for models <span class="math inline">\(g()\)</span> and <span class="math inline">\(h()\)</span>.</p></li>
<li><p>Local accuracy (see Section <a href="breakDown.html#BDMethodGen">6.3.2</a>): the sum of Shapley values is equal to the model’s prediction, that is,
<span class="math display">\[
f(\underline{x}_*) - E_{\underline{X}}\{f(\underline{X})\} = \sum_{j=1}^p   \varphi(\underline{x}_*,j), 
\]</span>
where <span class="math inline">\(\underline{X}\)</span> is the vector of explanatory variables (corresponding to <span class="math inline">\(\underline{x}_*\)</span>) that are treated as random values.</p></li>
</ul>
</div>
<div id="SHAPExample" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Example: Titanic data</h2>
<p>Let us consider the random forest model <code>titanic_rf</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>) and passenger Johnny D (see Section <a href="dataSetsIntro.html#predictions-titanic">4.2.5</a>) as the instance of interest in the Titanic data.</p>
<p>Box plots in Figure <a href="shapley.html#fig:shappJohny02">8.3</a> present the distribution of the contributions <span class="math inline">\(\Delta^{j|\pi(J,j)}(\underline{x}_*)\)</span> for each explanatory variable of the model for 25 random orderings of the explanatory variables. Red and green bars represent, respectively, the negative and positive Shapley values across the orderings. It is clear that the young age of Johnny D results in a positive contribution for all orderings; the resulting Shapley value is equal to 0.2525. On the other hand, the effect of gender is in all cases negative, with the Shapley value equal to -0.0908.</p>
<p>The picture for variables <em>fare</em> and <em>class</em> is more complex, as their contributions can even change the sign, depending on the ordering. Note that Figure <a href="shapley.html#fig:shappJohny02">8.3</a> presents Shapley values separately for each of the two variables. However, it is worth recalling that the iBD plot in Figure <a href="iBreakDown.html#fig:iBreakDownTitanicExamplePlot">7.1</a> indicated an important contribution of an interaction between the two variables. Hence, their contributions should not be separated. Thus, the Shapley values for <em>fare</em> and <em>class</em>, presented in Figure <a href="shapley.html#fig:shappJohny02">8.3</a>, should be interpreted with caution.</p>

<div class="figure" style="text-align: center"><span id="fig:shappJohny02"></span>
<img src="ema_files/figure-html/shappJohny02-1.png" alt="Explanatory-variable attributions for the prediction for Johnny D for the random forest model titanic_rf and the Titanic data based on 25 random orderings. Left-hand-side plot: box plots summarize the distribution of the attributions for each explanatory variable across the orderings. Red and green bars present Shapley values. Right-hand-side plot: Shapley values (mean attributions) without box plots." width="100%" />
<p class="caption">
Figure 8.3: Explanatory-variable attributions for the prediction for Johnny D for the random forest model <code>titanic_rf</code> and the Titanic data based on 25 random orderings. Left-hand-side plot: box plots summarize the distribution of the attributions for each explanatory variable across the orderings. Red and green bars present Shapley values. Right-hand-side plot: Shapley values (mean attributions) without box plots.
</p>
</div>
<p>In most applications, the detailed information about the distribution of variable contributions across the considered orderings of explanatory variables may not be of interest. Thus, one could simplify the plot by presenting only the Shapley values, as illustrated in the right-hand-side panel of Figure <a href="shapley.html#fig:shappJohny02">8.3</a>. Table <a href="shapley.html#tab:shapOrderingTable">8.1</a> presents the Shapley values underlying this plot.</p>
<table>
<caption><span id="tab:shapOrderingTable">Table 8.1: </span> Shapley values for the prediction for Johnny D for the random forest model <code>titanic_rf</code> and the Titanic data based on 25 random orderings.</caption>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="right">Shapley value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age = 8</td>
<td align="right">0.2525</td>
</tr>
<tr class="even">
<td align="left">class = 1st</td>
<td align="right">0.0246</td>
</tr>
<tr class="odd">
<td align="left">embarked = Southampton</td>
<td align="right">-0.0032</td>
</tr>
<tr class="even">
<td align="left">fare = 72</td>
<td align="right">0.0140</td>
</tr>
<tr class="odd">
<td align="left">gender = male</td>
<td align="right">-0.0943</td>
</tr>
<tr class="even">
<td align="left">parch = 0</td>
<td align="right">-0.0097</td>
</tr>
<tr class="odd">
<td align="left">sibsp = 0</td>
<td align="right">0.0027</td>
</tr>
</tbody>
</table>
</div>
<div id="SHAProsCons" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Pros and cons</h2>
<p>Shapley values provide a uniform approach to decompose a model’s predictions into contributions that can be attributed additively to different explanatory variables. <span class="citation">Lundberg and Lee (<a href="#ref-SHAP" role="doc-biblioref">2017</a>)</span> showed that the method unifies different approaches to additive variable attributions, like DeepLIFT <span class="citation">(Shrikumar, Greenside, and Kundaje <a href="#ref-DeepLIFT" role="doc-biblioref">2017</a>)</span>, Layer-Wise Relevance Propagation <span class="citation">(Binder et al. <a href="#ref-LWRP" role="doc-biblioref">2016</a>)</span>, or Local Interpretable Model-agnostic Explanations <span class="citation">(Ribeiro, Singh, and Guestrin <a href="#ref-lime" role="doc-biblioref">2016</a>)</span>. The method has got a strong formal foundation derived from the cooperative games theory. It also enjoys an efficient implementation in Python, with ports or re-implementations in R.</p>
<p>An important drawback of Shapley values is that they provide additive contributions (attributions) of explanatory variables. If the model is not additive, then the Shapley values may be misleading. This issue can be seen as arising from the fact that, in cooperative games, the goal is to distribute the payoff among payers. However, in the predictive modelling context, we want to understand how do the players affect the payoff? Thus, we are not limited to independent payoff-splits for players.</p>
<p>It is worth noting that, for an additive model, the approaches presented in Chapters <a href="breakDown.html#breakDown">6</a>–<a href="iBreakDown.html#iBreakDown">7</a> and in the current one lead to the same attributions. The reason is that, for additive models, different orderings lead to the same contributions. Since Shapley values can be seen as the mean across all orderings, it is essentially an average of identical values, i.e., it also assumes the same value.</p>
<p>An important practical limitation of the general model-agnostic method is that, for large models, the calculation of Shapley values is time-consuming. However, sub-sampling can be used to address the issue. For tree-based models, effective implementations are available.</p>
</div>
<div id="SHAPRcode" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Code snippets for R</h2>
<p>In this section, we use the <code>DALEX</code> package, which is a wrapper for the <code>iBreakDown</code> R package. The package covers all methods presented in this chapter. It is available on <code>CRAN</code> and <code>GitHub</code>. Note that there are also other R packages that offer similar functionalities, like <code>iml</code> <span class="citation">(Molnar, Bischl, and Casalicchio <a href="#ref-imlRPackage" role="doc-biblioref">2018</a>)</span>, <code>fastshap</code> <span class="citation">(Greenwell <a href="#ref-fastshapRpackage" role="doc-biblioref">2020</a>)</span> or <code>shapper</code> <span class="citation">(Maksymiuk, Gosiewska, and Biecek <a href="#ref-shapperPackage" role="doc-biblioref">2019</a>)</span>, which is a wrapper for the Python library <code>SHAP</code> <span class="citation">(Lundberg <a href="#ref-shapPackage" role="doc-biblioref">2019</a>)</span>.</p>
<p>For illustration purposes, we use the <code>titanic_rf</code> random forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>. Recall that the model is developed to predict the probability of survival for passengers of Titanic. Instance-level explanations are calculated for Henry, a 47-year-old passenger that travelled in the first class (see Section <a href="dataSetsIntro.html#predictions-titanic">4.2.5</a>).</p>
<p>We first retrieve the <code>titanic_rf</code> model-object and the data frame for Henry via the <code>archivist</code> hooks, as listed in Section <a href="dataSetsIntro.html#ListOfModelsTitanic">4.2.7</a>. We also retrieve the version of the <code>titanic</code> data with imputed missing values.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="shapley.html#cb95-1"></a>titanic_imputed &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/27e5c&quot;</span>)</span>
<span id="cb95-2"><a href="shapley.html#cb95-2"></a>titanic_rf &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="st"> </span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/4e0fc&quot;</span>)</span>
<span id="cb95-3"><a href="shapley.html#cb95-3"></a>henry &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/a6538&quot;</span>)</span></code></pre></div>
<p>Then we construct the explainer for the model by using function <code>explain()</code> from the <code>DALEX</code> package (see Section <a href="dataSetsIntro.html#ExplainersTitanicRCode">4.2.6</a>). We also load the <code>randomForest</code> package, as the model was fitted by using function <code>randomForest()</code> from this package (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>) and it is important to have the corresponding <code>predict()</code> function available. The model’s prediction for Henry is obtained with the help of the function.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="shapley.html#cb96-1"></a><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</span>
<span id="cb96-2"><a href="shapley.html#cb96-2"></a><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</span>
<span id="cb96-3"><a href="shapley.html#cb96-3"></a>explain_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf,  </span>
<span id="cb96-4"><a href="shapley.html#cb96-4"></a>                        <span class="dt">data =</span> titanic_imputed[, <span class="dv">-9</span>],</span>
<span id="cb96-5"><a href="shapley.html#cb96-5"></a>                           <span class="dt">y =</span> titanic_imputed<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, </span>
<span id="cb96-6"><a href="shapley.html#cb96-6"></a>                       <span class="dt">label =</span> <span class="st">&quot;Random Forest&quot;</span>)</span>
<span id="cb96-7"><a href="shapley.html#cb96-7"></a><span class="kw">predict</span>(explain_rf, henry)</span></code></pre></div>
<pre><code>## [1] 0.246</code></pre>
<p>To compute Shapley values for Henry, we apply function <code>predict_parts()</code> (as in Section <a href="breakDown.html#BDR">6.6</a>) to the explainer-object <code>explain_rf</code> and the data frame for the instance of interest, i.e., Henry. By specifying the <code>type="shap"</code> argument we indicate that we want to compute Shapley values. Additionally, the <code>B=25</code> argument indicates that we want to select 25 random orderings of explanatory variables for which the Shapley values are to be computed. Note that <code>B=25</code> is also the default value of the argument.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="shapley.html#cb98-1"></a>shap_henry &lt;-<span class="st"> </span><span class="kw">predict_parts</span>(<span class="dt">explainer =</span> explain_rf, </span>
<span id="cb98-2"><a href="shapley.html#cb98-2"></a>                      <span class="dt">new_observation =</span> henry, </span>
<span id="cb98-3"><a href="shapley.html#cb98-3"></a>                                 <span class="dt">type =</span> <span class="st">&quot;shap&quot;</span>,</span>
<span id="cb98-4"><a href="shapley.html#cb98-4"></a>                                    <span class="dt">B =</span> <span class="dv">25</span>)</span></code></pre></div>
<p>The resulting object <code>shap_henry</code> is a data frame with variable-specific attributions computed for every ordering. Printing out the object provides various summary statistics of the attributions including, of course, the mean.</p>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="shapley.html#cb99-1"></a>shap_henry</span></code></pre></div>
<pre><code>##                                             min           q1
## Random Forest: age = 47             -0.14872225 -0.081197100
## Random Forest: class = 1st           0.12112732  0.123195061
## Random Forest: embarked = Cherbourg  0.01245129  0.022680335
## Random Forest: fare = 25            -0.03180517 -0.011710693
## Random Forest: gender = male        -0.15670412 -0.145184866
## Random Forest: parch = 0            -0.02795650 -0.007438151
## Random Forest: sibsp = 0            -0.03593203 -0.012978704
##                                           median         mean
## Random Forest: age = 47             -0.040909832 -0.060137381
## Random Forest: class = 1st           0.159974789  0.159090494
## Random Forest: embarked = Cherbourg  0.045746262  0.051056420
## Random Forest: fare = 25            -0.008647485  0.002175261
## Random Forest: gender = male        -0.126003135 -0.126984069
## Random Forest: parch = 0            -0.003043951 -0.005439239
## Random Forest: sibsp = 0            -0.005466244 -0.009070956
##                                                q3          max
## Random Forest: age = 47             -0.0230765745 -0.004967830
## Random Forest: class = 1st           0.1851354780  0.232307204
## Random Forest: embarked = Cherbourg  0.0558871772  0.117857725
## Random Forest: fare = 25             0.0162267784  0.070487540
## Random Forest: gender = male        -0.1115160852 -0.101295877
## Random Forest: parch = 0            -0.0008337109  0.003412778
## Random Forest: sibsp = 0             0.0031207522  0.007650204</code></pre>
<p>By applying the generic function <code>plot()</code> to the <code>shap_henry</code> object, we obtain a graphical illustration of the results.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="shapley.html#cb101-1"></a><span class="kw">plot</span>(shap_henry)</span></code></pre></div>
<p>The resulting plot is shown in Figure <a href="shapley.html#fig:ShapforHenry">8.4</a>. It includes the Shapley values and box plots summarizing the distributions of the variable-specific contributions for the selected random orderings.</p>

<div class="figure" style="text-align: center"><span id="fig:ShapforHenry"></span>
<img src="ema_files/figure-html/ShapforHenry-1.png" alt="A plot of Shapley values with box plots for the titanic_rf model and passenger Henry for the Titanic data, obtained by applying the generic plot() function in R." width="80%" />
<p class="caption">
Figure 8.4: A plot of Shapley values with box plots for the <code>titanic_rf</code> model and passenger Henry for the Titanic data, obtained by applying the generic <code>plot()</code> function in R.
</p>
</div>
<p>To obtain a plot with only Shapley values, i.e., without the box plots, we apply the <code>show_boxplots=FALSE</code> argument in the <code>plot()</code> function call.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="shapley.html#cb102-1"></a><span class="kw">plot</span>(shap_henry, <span class="dt">show_boxplots =</span> <span class="ot">FALSE</span>) </span></code></pre></div>
<p>The resulting plot, shown in Figure <a href="shapley.html#fig:ShapOnlyforHenry">8.5</a>, can be compared to the plot in the right-hand-side panel of Figure <a href="shapley.html#fig:shappJohny02">8.3</a> for Johnny D. The most remarkable difference is related to the contribution of <em>age</em>. The young age of Johnny D markedly increases the chances of survival, contrary to the negative contribution of the age of 47 for Henry.</p>

<div class="figure" style="text-align: center"><span id="fig:ShapOnlyforHenry"></span>
<img src="ema_files/figure-html/ShapOnlyforHenry-1.png" alt="A plot of Shapley values without box plots for the titanic_rf model and passenger Henry for the Titanic data, obtained by applying the generic plot() function in R." width="70%" />
<p class="caption">
Figure 8.5: A plot of Shapley values without box plots for the <code>titanic_rf</code> model and passenger Henry for the Titanic data, obtained by applying the generic <code>plot()</code> function in R.
</p>
</div>
</div>
<div id="SHAPPythonCode" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> Code snippets for Python</h2>
<p>In this section, we use the <code>dalex</code> library for Python. The package covers all methods presented in this chapter. It is available on <code>pip</code> and <code>GitHub</code>. Note that the most popular implementation in Python is available in the <code>shap</code> library <span class="citation">(Lundberg and Lee <a href="#ref-SHAP" role="doc-biblioref">2017</a>)</span>. In this section, however, we show implementations from the <code>dalex</code> library because they are consistent with other methods presented in this book.</p>
<p>For illustration purposes, we use the <code>titanic_rf</code> random forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-python-rf">4.3.2</a>. Instance-level explanations are calculated for Henry, a 47-year-old passenger that travelled in the 1st class (see Section <a href="dataSetsIntro.html#predictions-titanic-python">4.3.5</a>).</p>
<p>In the first step, we create an explainer-object that provides a uniform interface for the predictive model. We use the <code>Explainer()</code> constructor for this purpose (see Section <a href="dataSetsIntro.html#ExplainersTitanicPythonCode">4.3.6</a>).</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="shapley.html#cb103-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb103-2"><a href="shapley.html#cb103-2"></a>henry <span class="op">=</span> pd.DataFrame({<span class="st">&#39;gender&#39;</span>   : [<span class="st">&#39;male&#39;</span>],</span>
<span id="cb103-3"><a href="shapley.html#cb103-3"></a>                       <span class="st">&#39;age&#39;</span>     : [<span class="dv">47</span>],</span>
<span id="cb103-4"><a href="shapley.html#cb103-4"></a>                       <span class="st">&#39;class&#39;</span>   : [<span class="st">&#39;1st&#39;</span>],</span>
<span id="cb103-5"><a href="shapley.html#cb103-5"></a>                       <span class="st">&#39;embarked&#39;</span>: [<span class="st">&#39;Cherbourg&#39;</span>],</span>
<span id="cb103-6"><a href="shapley.html#cb103-6"></a>                       <span class="st">&#39;fare&#39;</span>    : [<span class="dv">25</span>],</span>
<span id="cb103-7"><a href="shapley.html#cb103-7"></a>                       <span class="st">&#39;sibsp&#39;</span>   : [<span class="dv">0</span>],</span>
<span id="cb103-8"><a href="shapley.html#cb103-8"></a>                       <span class="st">&#39;parch&#39;</span>   : [<span class="dv">0</span>]},</span>
<span id="cb103-9"><a href="shapley.html#cb103-9"></a>                      index <span class="op">=</span> [<span class="st">&#39;Henry&#39;</span>])</span>
<span id="cb103-10"><a href="shapley.html#cb103-10"></a></span>
<span id="cb103-11"><a href="shapley.html#cb103-11"></a><span class="im">import</span> dalex <span class="im">as</span> dx</span>
<span id="cb103-12"><a href="shapley.html#cb103-12"></a>titanic_rf_exp <span class="op">=</span> dx.Explainer(titanic_rf, X, y, </span>
<span id="cb103-13"><a href="shapley.html#cb103-13"></a>                  label <span class="op">=</span> <span class="st">&quot;Titanic RF Pipeline&quot;</span>)</span></code></pre></div>
<p>To calculate Shapley values we use the <code>predict_parts()</code> method with the <code>type='shap'</code> argument (see Section <a href="breakDown.html#BDPython">6.7</a>). The first argument indicates the data observation for which the values are to be calculated. Results are stored in the <code>results</code> field.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="shapley.html#cb104-1"></a>bd_henry <span class="op">=</span> titanic_rf_exp.predict_parts(henry, <span class="bu">type</span> <span class="op">=</span> <span class="st">&#39;shap&#39;</span>)</span>
<span id="cb104-2"><a href="shapley.html#cb104-2"></a>bd_henry.result</span></code></pre></div>
<p><img src="figure/shap_python_2.png" width="100%" /></p>
<p>To visualize the obtained values, we simply call the <code>plot()</code> method.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="shapley.html#cb105-1"></a>bd_henry.plot()</span></code></pre></div>
<p>The resulting plot is shown in Figure <a href="shapley.html#fig:shapPython2">8.6</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:shapPython2"></span>
<img src="figure/shap_python_1.png" alt="A plot of Shapley values for the titanic_rf model and passenger Henry for the Titanic data, obtained by applying the plot() method in Python." width="100%" />
<p class="caption">
Figure 8.6: A plot of Shapley values for the <code>titanic_rf</code> model and passenger Henry for the Titanic data, obtained by applying the <code>plot()</code> method in Python.
</p>
</div>
<p>By default, Shapley values are calculated and plotted for all variables in the data. To limit the number of variables included in the graph, we can use the argument <code>max_vars</code> in the <code>plot()</code> method (see Section <a href="breakDown.html#BDPython">6.7</a>).</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-LWRP">
<p>Binder, Alexander, Grégoire Montavon, Sebastian Bach, Klaus-Robert Müller, and Wojciech Samek. 2016. “Layer-Wise Relevance Propagation for Neural Networks with Local Renormalization Layers.” In <em>Artificial Neural Networks and Machine Learning - 25th International Conference on Artificial Neural Networks, Icann 2016, Proceedings</em>, 9887 LNCS:63–71. Lecture Notes in Computer Science. Springer Verlag. <a href="https://doi.org/10.1007/978-3-319-44781-0_8">https://doi.org/10.1007/978-3-319-44781-0_8</a>.</p>
</div>
<div id="ref-fastshapRpackage">
<p>Greenwell, Brandon. 2020. <em>fastshap: Fast Approximate Shapley Values</em>. <a href="https://CRAN.R-project.org/package=fastshap">https://CRAN.R-project.org/package=fastshap</a>.</p>
</div>
<div id="ref-shapPackage">
<p>Lundberg, Scott. 2019. <em>SHAP (SHapley Additive exPlanations)</em>. <a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>.</p>
</div>
<div id="ref-TreeSHAP">
<p>Lundberg, Scott M., Gabriel G. Erion, and Su-In Lee. 2018. “Consistent Individualized Feature Attribution for Tree Ensembles.” <em>CoRR</em> abs/1802.03888. <a href="http://arxiv.org/abs/1802.03888">http://arxiv.org/abs/1802.03888</a>.</p>
</div>
<div id="ref-SHAP">
<p>Lundberg, Scott M, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 4765–74. Montreal: Curran Associates. <a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</a>.</p>
</div>
<div id="ref-shapperPackage">
<p>Maksymiuk, Szymon, Alicja Gosiewska, and Przemyslaw Biecek. 2019. <em>shapper: Wrapper of Python library shap</em>. <a href="https://github.com/ModelOriented/shapper">https://github.com/ModelOriented/shapper</a>.</p>
</div>
<div id="ref-imlRPackage">
<p>Molnar, Christoph, Bernd Bischl, and Giuseppe Casalicchio. 2018. “iml: An R package for Interpretable Machine Learning.” <em>Journal of Open Source Software</em> 3 (26): 786. <a href="https://doi.org/10.21105/joss.00786">https://doi.org/10.21105/joss.00786</a>.</p>
</div>
<div id="ref-lime">
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “"Why should I trust you?": Explaining the Predictions of Any Classifier.” In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Kdd San Francisco, ca</em>, 1135–44. New York, NY: Association for Computing Machinery.</p>
</div>
<div id="ref-shapleybook1952">
<p>Shapley, Lloyd S. 1953. “A Value for n-Person Games.” In <em>Contributions to the Theory of Games Ii</em>, edited by Harold W. Kuhn and Albert W. Tucker, 307–17. Princeton: Princeton University Press.</p>
</div>
<div id="ref-DeepLIFT">
<p>Shrikumar, Avanti, Peyton Greenside, and Anshul Kundaje. 2017. “Learning Important Features Through Propagating Activation Differences.” In <em>ICML</em>, edited by Doina Precup and Yee Whye Teh, 70:3145–53. Proceedings of Machine Learning Research. <a href="http://dblp.uni-trier.de/db/conf/icml/icml2017.html#ShrikumarGK17">http://dblp.uni-trier.de/db/conf/icml/icml2017.html#ShrikumarGK17</a>.</p>
</div>
<div id="ref-imeJLMR">
<p>Štrumbelj, Erik, and Igor Kononenko. 2010. “An Efficient Explanation of Individual Classifications Using Game Theory.” <em>Journal of Machine Learning Research</em> 11 (March): 1–18. <a href="http://dl.acm.org/citation.cfm?id=1756006.1756007">http://dl.acm.org/citation.cfm?id=1756006.1756007</a>.</p>
</div>
<div id="ref-Strumbelj2014">
<p>Štrumbelj, Erik, and Igor Kononenko. 2014. “Explaining prediction models and individual predictions with feature contributions.” <em>Knowledge and Information Systems</em> 41 (3): 647–65. <a href="https://doi.org/10.1007/s10115-013-0679-x">https://doi.org/10.1007/s10115-013-0679-x</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="iBreakDown.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="LIME.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
