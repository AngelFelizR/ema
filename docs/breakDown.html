<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Break-down Plots for Additive Attributions | Explanatory Model Analysis</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Break-down Plots for Additive Attributions | Explanatory Model Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Break-down Plots for Additive Attributions | Explanatory Model Analysis" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-07-20" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="InstanceLevelExploration.html"/>
<link rel="next" href="iBreakDown.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#teminology"><i class="fa fa-check"></i><b>1.4</b> Terminology</a></li>
<li class="chapter" data-level="1.5" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#glassblack"><i class="fa fa-check"></i><b>1.5</b> Black-box models and glass-box models</a></li>
<li class="chapter" data-level="1.6" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#agnosticspecific"><i class="fa fa-check"></i><b>1.6</b> Model-agnostic and model-specific approach</a></li>
<li class="chapter" data-level="1.7" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#bookstructure"><i class="fa fa-check"></i><b>1.7</b> The structure of the book</a></li>
<li class="chapter" data-level="1.8" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#whatisinthebook"><i class="fa fa-check"></i><b>1.8</b> What is included in this book and what is not</a></li>
<li class="chapter" data-level="1.9" data-path="ChapIntroduction.html"><a href="ChapIntroduction.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> Model-development process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#dataunderstanding"><i class="fa fa-check"></i><b>2.4</b> Data understanding</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#fitting"><i class="fa fa-check"></i><b>2.5</b> Model assembly (fitting)</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#validation"><i class="fa fa-check"></i><b>2.6</b> Model audit</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself with R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>3.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#infoDALEX"><i class="fa fa-check"></i><b>3.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.3" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html"><i class="fa fa-check"></i><b>4</b> Do-it-yourself with Python</a>
<ul>
<li class="chapter" data-level="4.1" data-path="doItYourselfWithR.html"><a href="doItYourselfWithR.html#what-to-install"><i class="fa fa-check"></i><b>4.1</b> What to install?</a></li>
<li class="chapter" data-level="4.2" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html#infoDALEXpy"><i class="fa fa-check"></i><b>4.2</b> How to work with <code>dalex</code>?</a></li>
<li class="chapter" data-level="4.3" data-path="doItYourselfWithPython.html"><a href="doItYourselfWithPython.html#code-snippets-for-python"><i class="fa fa-check"></i><b>4.3</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>5</b> Datasets and models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>5.1</b> Sinking of the RMS Titanic</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>5.1.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#r-classification-models-for-titanic"><i class="fa fa-check"></i><b>5.2</b> R classification models for Titanic</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>5.2.1</b> Logistic-regression model</a></li>
<li class="chapter" data-level="5.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>5.2.2</b> Random-forest model</a></li>
<li class="chapter" data-level="5.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>5.2.3</b> Gradient-boosting model</a></li>
<li class="chapter" data-level="5.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>5.2.4</b> Support Vector Machine model for Classification</a></li>
<li class="chapter" data-level="5.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>5.2.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="5.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>5.2.6</b> Models’ explainers</a></li>
<li class="chapter" data-level="5.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>5.2.7</b> List of objects for the Titanic example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#python-classification-models-for-titanic"><i class="fa fa-check"></i><b>5.3</b> Python classification models for Titanic</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-lr"><i class="fa fa-check"></i><b>5.3.1</b> Logistic-regression model</a></li>
<li class="chapter" data-level="5.3.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-rf"><i class="fa fa-check"></i><b>5.3.2</b> Random-forest model</a></li>
<li class="chapter" data-level="5.3.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-gbm"><i class="fa fa-check"></i><b>5.3.3</b> Gradient-boosting model</a></li>
<li class="chapter" data-level="5.3.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-svm"><i class="fa fa-check"></i><b>5.3.4</b> Support Vector Machine model for Classification</a></li>
<li class="chapter" data-level="5.3.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic-python"><i class="fa fa-check"></i><b>5.3.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="5.3.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicPythonCode"><i class="fa fa-check"></i><b>5.3.6</b> Models’ explainers</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>5.4</b> Apartment prices</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>5.4.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#r-regression-model-for-apartment-prices"><i class="fa fa-check"></i><b>5.5</b> R regression model for Apartment prices</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>5.5.1</b> Linear-regression model</a></li>
<li class="chapter" data-level="5.5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>5.5.2</b> Random-forest model</a></li>
<li class="chapter" data-level="5.5.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>5.5.3</b> Support Vector Machine model for Regression</a></li>
<li class="chapter" data-level="5.5.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>5.5.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="5.5.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>5.5.5</b> Models’ explainers</a></li>
<li class="chapter" data-level="5.5.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>5.5.6</b> List of objects for the Apartment prices example</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#python-regression-models-for-apartment-prices"><i class="fa fa-check"></i><b>5.6</b> Python regression models for Apartment prices</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-lr"><i class="fa fa-check"></i><b>5.6.1</b> Linear-regression model</a></li>
<li class="chapter" data-level="5.6.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-rf"><i class="fa fa-check"></i><b>5.6.2</b> Random-forest model</a></li>
<li class="chapter" data-level="5.6.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-svm"><i class="fa fa-check"></i><b>5.6.3</b> Support Vector Machine model for Regression</a></li>
<li class="chapter" data-level="5.6.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-apartments-python"><i class="fa fa-check"></i><b>5.6.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="5.6.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsPythonCode"><i class="fa fa-check"></i><b>5.6.5</b> Models’ explainers</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Instance Level</b></span></li>
<li class="chapter" data-level="6" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>6</b> Introduction to Instance-level Exploration</a></li>
<li class="chapter" data-level="7" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Additive Attributions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="breakDown.html"><a href="breakDown.html#BDIntroduction"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>7.2</b> Intuition</a></li>
<li class="chapter" data-level="7.3" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>7.3</b> Method</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="breakDown.html"><a href="breakDown.html#BDMethodLin"><i class="fa fa-check"></i><b>7.3.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="7.3.2" data-path="breakDown.html"><a href="breakDown.html#BDMethodGen"><i class="fa fa-check"></i><b>7.3.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>7.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.5" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>7.5</b> Pros and cons</a></li>
<li class="chapter" data-level="7.6" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>7.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>7.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="7.6.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>7.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="breakDown.html"><a href="breakDown.html#BDPython"><i class="fa fa-check"></i><b>7.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>8</b> Break-down Plots for Interactions (iBreak-down Plots)</a>
<ul>
<li class="chapter" data-level="8.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9</b> Shapley Additive Explanations (SHAP) and Average Variable Attributions</a>
<ul>
<li class="chapter" data-level="9.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>10</b> Local Interpretable Model-agnostic Explanations (LIME)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="LIME.html"><a href="LIME.html#LIMErepr"><i class="fa fa-check"></i><b>10.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="10.3.2" data-path="LIME.html"><a href="LIME.html#LIMEsample"><i class="fa fa-check"></i><b>10.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="10.3.3" data-path="LIME.html"><a href="LIME.html#LIMEglas"><i class="fa fa-check"></i><b>10.3.3</b> Developing the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="LIME.html"><a href="LIME.html#the-lime-package"><i class="fa fa-check"></i><b>10.6.1</b> The <code>lime</code> package</a></li>
<li class="chapter" data-level="10.6.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>10.6.2</b> The <code>localModel</code> package</a></li>
<li class="chapter" data-level="10.6.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>10.6.3</b> The <code>iml</code> package</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Profiles</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>individual_profile()</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-individual_profile-function"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>individual_profile()</code> function</a></li>
<li class="chapter" data-level="11.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#comparison-of-models-challenger-champion-analysis"><i class="fa fa-check"></i><b>11.6.3</b> Comparison of models (challenger-champion analysis)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>12</b> Ceteris-paribus Oscillations</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a></li>
<li class="chapter" data-level="12.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="12.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>12.6.1</b> Basic use of the <code>variable_attribution()</code> function</a></li>
<li class="chapter" data-level="12.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-variable_attribution-function"><i class="fa fa-check"></i><b>12.6.2</b> Advanced use of the <code>variable_attribution()</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>13</b> Local-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="13.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>13.2</b> Intuition</a></li>
<li class="chapter" data-level="13.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>13.3</b> Method</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>13.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="13.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>13.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="13.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>13.3.3</b> Local-stability plot</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>13.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="13.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>13.5</b> Pros and cons</a></li>
<li class="chapter" data-level="13.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>13.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>14</b> Summary of Instance-level Exploration</a>
<ul>
<li class="chapter" data-level="14.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#summaryInstanceLevelIntro"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>14.2</b> Number of explanatory variables in the model</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.2.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="14.2.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.2.2</b> Medium to large number of explanatory variables</a></li>
<li class="chapter" data-level="14.2.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>14.2.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>14.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="14.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>14.4</b> Models with interactions</a></li>
<li class="chapter" data-level="14.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>14.5</b> Sparse explanations</a></li>
<li class="chapter" data-level="14.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>14.6</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="14.7" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#comparison-of-models-champion-challenger-analysis"><i class="fa fa-check"></i><b>14.7</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Explanatory Model Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="breakDown" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Break-down Plots for Additive Attributions</h1>
<div id="BDIntroduction" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Introduction</h2>
<p>Probably the most commonly asked question when trying to understand a model’s prediction for a single observation is: <em>which variables contribute to this result the most?</em> There is no single best approach that can be used to answer this question. In this chapter, we introduce break-down (BD) plots, which offer a possible solution. The plots can be used to present “variable attributions,” i.e., the decomposition of the model’s prediction into contributions that can be attributed to different explanatory variables. Note that the method is similar to the <code>EXPLAIN</code> algorithm introduced by <span class="citation">Robnik-Šikonja and Kononenko (<a href="#ref-explainPaper" role="doc-biblioref">2008</a>)</span> and implemented in the <code>ExplainPrediction</code> package <span class="citation">(Robnik-Šikonja <a href="#ref-explainPackage" role="doc-biblioref">2018</a>)</span>.</p>
</div>
<div id="BDIntuition" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Intuition</h2>
<p>As mentioned in Section <a href="modelDevelopmentProcess.html#fitting">2.5</a>, we assume that prediction <span class="math inline">\(f(\underline{x})\)</span> is an approximation of the expected value of the dependent variable <span class="math inline">\(Y\)</span> given values of explanatory variables <span class="math inline">\(\underline{x}\)</span>. The underlying idea of BD plots is to capture the contribution of an explanatory variable to the model’s prediction by computing the shift in the expected value of <span class="math inline">\(Y\)</span>, while fixing the values of other variables.</p>
<p>This idea is illustrated in Figure <a href="breakDown.html#fig:BDPrice4">7.1</a>. Consider an example related to the prediction obtained for the random-forest model <code>model_rf</code> for the Titanic data (see Section <a href="dataSetsIntro.html#model-titanic-rf">5.2.2</a>). We are interested in the probability of survival for Johnny D, an 8-years-old passenger travelling in the first class (see Section <a href="dataSetsIntro.html#predictions-titanic">5.2.5</a>). Panel A of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a> shows distribution of the model’s predictions for observations from the Titanic dataset. In particular, the violin plot in the row marked “all data” summarizes the distrbution of predictions for all 2207 observations from the dataset. The red dot indicates the mean value that can be interpreted as an estimate of the expected value of the model’s predictions over the distribution of all explanatory variables. In this example, the mean value is equal to 23.5%.</p>

<div class="figure" style="text-align: center"><span id="fig:BDPrice4"></span>
<img src="figure/break_down_distr.png" alt="Break-down plots show how the contributions attributed to individual explanatory variables change the mean model’s prediction to yield the actual prediction for a particular single instance (observation). Panel A) The first row shows the distribution and the mean value (red dot) of model’s predictions for all data. The next rows show the distribution and the mean value of the predictions when fixing values of subsequent explanatory variables. The last row shows the prediction for the particular instance of interest. B) Red dots indicate the mean predictions from panel A. C) The green and red bars indicate, respectively, positive and negative changes in the mean predictions (contributions attributed to explanatory variables)." width="70%" />
<p class="caption">
Figure 7.1: Break-down plots show how the contributions attributed to individual explanatory variables change the mean model’s prediction to yield the actual prediction for a particular single instance (observation). Panel A) The first row shows the distribution and the mean value (red dot) of model’s predictions for all data. The next rows show the distribution and the mean value of the predictions when fixing values of subsequent explanatory variables. The last row shows the prediction for the particular instance of interest. B) Red dots indicate the mean predictions from panel A. C) The green and red bars indicate, respectively, positive and negative changes in the mean predictions (contributions attributed to explanatory variables).
</p>
</div>
<p>To evaluate the contribution of individual explanatory variables to this particular single-instance prediction, we investigate the changes in the model’s predictions when fixing the values of consecutive variables. For instance, the violin plot in the row marked “age=8” in panel A of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a> summarizes the distribution of the predictions obtained when the <em>age</em> variable takes the value “8 years”, as for Johnny D. Again, the red dot indicates the mean of the predictions and it can be interpreted as an estimate of the expected value of the predictions over the distribution of all explanatory variables other than <em>class</em>. The violin plot in the “class=1st” row describes the distribution and the mean value of predictions with the values of variables <em>age</em> and <em>class</em> set to “8 years” and “1st class”, respectively. Subsequent rows contain similar information for other explanatory variables included in the random-forest model. In the last row, all explanatory variables are fixed at the values describing Johnny D. Hence, the last row contains only one point, the red dot, which corresponds to the model’s prediction, i.e., survival probability, for Johnny D.</p>
<p>The thin grey lines in panel A of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a> show the change of predictions for different individuals when the value of a particular explanatory variable is being replaced by the value indicated in the name of the row. For instance, the lines between the first and the second row indicate that fixing the value of the <em>age</em> variable to “8 years” has a different effect for different individuals. For some individuals (most likely, passengers that are 8 years old) the model’s prediction does not change at all. For others, the predicted value increases (probably for the passengers older than 8 years) or decreases (most likely for the passengers younger than 8 years).</p>
<p>Eventually, however, we may be interested in the mean predictions, or even only in the changes of the means. Thus, simplified plots, similar to those shown in panels B and C of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a>, may be of interest. Note that, in panel C, the row marked “intercept” presents the overall mean value (0.235) of predictions for the entire dataset. Consecutive rows present changes in the mean prediction induced by fixing the value of a particular explanatory variable. Positive changes are indicated with green bars, while negative differences are indicated with red bars. The last row, marked “prediction,” contains the sum of the overall mean value and the changes, i.e., the predicted value of survival probability for Johnny D, indicated by the blue bar.</p>
<p>What can be learned from BD plots as those presented in Figure <a href="breakDown.html#fig:BDPrice4">7.1</a>? The plots offer a summary of effects of a particular explanatory variables on a model’s predictions.</p>
<p>From Figure <a href="breakDown.html#fig:BDPrice4">7.1</a> we can conclude, for instance, that the mean model’s prediction for the random-forest model for the Titanic dataset is equal to 23.5 percent. This is the predicted probability of survival averaged over all people on Titanic. Note that it is not the percentage of inidividuals that survived, but the mean model-prediction. Thus, for a different model, we would most likely obtain a different mean value.</p>
<p>The model’s prediction for Johnny D is equal to 42.2 percent. It is much higher than the mean prediction. The two explanatory variables that influence this prediction the most are <em>class</em> (with the value “1st”) and <em>age</em> (with the value equal to 8). By fixing the values of these two variables, we add 35.6 percentage points to the mean prediction. All other explanatory variables have smaller effects and they actually reduce the increase in the predicted value induced by <em>class</em> an <em>age</em>. For instance, <em>gender</em> (Johnny D was a boy) reduces the predicted surival probability by about 8.3 percentage points.</p>
<p>It is worth noting that the part of the prediction attributed to an explanatory variable depends not only on the variable, but also on the considered value. For instance, in the example presented in Figure <a href="breakDown.html#fig:BDPrice4">7.1</a>, the effect of the <em>embarked</em> harbor is very small. This may be due to the fact that the variable is not very important for prediction. However, it is also possible that the variable is important, but the effect of the value considered for the particular instance (Johnny D, who embarked Titanic in Southampton) may be close to the mean, as compared to all other possible values of the variable.</p>
<p>It is also worth mentioning that, for models that include interactions, the part of the prediction attributed to a variable depends on the order, in which one sets the values of the explanatory variables. Note that the interactions do not have to be explicitly specified in the model structure as it is the case of, for instance, linear-regression models. They may also emerge as a result of fitting to the data a flexible model like, for instance, a regression tree.</p>
<p>To illustrate the point, Figure <a href="breakDown.html#fig:ordering">7.2</a> presents an example for a random-forest model with only three variables fitted to the Titanic data. Subsequently, we focus on the model’s prediction for a 2-year old boy that travelled in the second class. The predicted probability of survival is equal to 0.964, more than a double of the mean model-prediction of 0.407. We would like to understand which explanatory variables drive this prediction. Two possible explanations are illustrated in Figure <a href="breakDown.html#fig:ordering">7.2</a>.</p>
<p><strong>Explanation 1:</strong></p>
<p>We first consider the explanatory variables <em>gender</em>, <em>class</em>, and <em>age</em>, in that order. Figure <a href="breakDown.html#fig:ordering">7.2</a> indicates negative contributions for the first two variables, and a positive contribution for the third one. Thus, the fact that the passenger was a boy decreases the chances of survival, as compared to the mean model-prediction. He traveled in the second class, which further lowers the probability of survival. However, as the boy was very young, this substantially increases the odds of surviving. This last conclusion is the result of the fact that most passengers in the second class were adults; therefore, a kid from the second class had higher chances of survival.</p>
<p><strong>Explanation 2:</strong></p>
<p>We now consider the order of explanatory variables: <em>gender</em>, <em>age</em>, and <em>class</em>. Figure <a href="breakDown.html#fig:ordering">7.2</a> indicates a positive contribution of <em>class</em>, unlike in the first explanation. Again, the fact that the passenger was a boy decreases the chances of survival, as compared to the mean model-prediction. However, he was very young, and this increases the probability of survival as compared to adult men. Finally, the fact that the boy traveled in the second class increases the chance even further. This last conclusion stems from the fact that most kids travelled in the third class; thus, being a child in the second class would increase chances of survival.</p>

<div class="figure" style="text-align: center"><span id="fig:ordering"></span>
<img src="figure/ordering.png" alt="An illustration of the order-dependence of variable attributions. Two break-down plots for the same observation for a random-forest model for the Titanic data set. The contribution attributed to class is negative in the plot at the top and positive in the one at the bottom. The difference is due to the difference in the ordering of explanatory variables used to construct the plots (as seen in the labelling of the rows)." width="80%" />
<p class="caption">
Figure 7.2: An illustration of the order-dependence of variable attributions. Two break-down plots for the same observation for a random-forest model for the Titanic data set. The contribution attributed to class is negative in the plot at the top and positive in the one at the bottom. The difference is due to the difference in the ordering of explanatory variables used to construct the plots (as seen in the labelling of the rows).
</p>
</div>
</div>
<div id="BDMethod" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Method</h2>
<p>In this section, we introduce more formally the method of variable atribution. We first focus on linear models, because their simple and additive structure allows building intuition. Then we consider a more general case.</p>
<div id="BDMethodLin" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Break-down for linear models</h3>
<p>Assume the classical linear-regression model for dependent variable <span class="math inline">\(Y\)</span> with <span class="math inline">\(p\)</span> explanatory variables, the values of which are collected in vector <span class="math inline">\(\underline{x}\)</span>, and a vector of <span class="math inline">\(p\)</span> corresponding coefficients <span class="math inline">\(\underline{\beta}\)</span>. Note that we separately consider <span class="math inline">\(\beta^0\)</span>, which is the intercept. Prediction for <span class="math inline">\(Y\)</span> is given by the expected value of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(\underline{x}\)</span>. In particular, the expected value is given by the following linear combination:</p>
<p><span class="math display" id="eq:BDkinreg">\[\begin{equation}
E_Y(Y | \underline{x}) = f(\underline{x}) = \beta^0 + \underline{x}&#39;\underline{\beta}.
\tag{7.1}
\end{equation}\]</span></p>
<p>Assume that we select a vector of values of explanatory variables <span class="math inline">\(\underline{x}_* \in \mathcal R^p\)</span>. We are interested in the contribution of the <span class="math inline">\(j\)</span>-th explanatory variable to model’s prediction <span class="math inline">\(f(\underline{x}_*)\)</span> for a single observation described by <span class="math inline">\(\underline{x}_*\)</span>.</p>
<!---
Because of the additive structure of the linear model, we expect that this contribution will be linked to ${x}_*^j{\beta}^j$, because the $j$-th variable occurs only in this term. As it will become clear in the sequel, it is easier to interpret the $j$-th explanatory variable contribution if it is centered by subtracting the expected value of $X^j$. This leads the following proposal for the *variable-importance measure*:

\begin{equation}
v(j, \underline{x}_*) = {\beta}^j \{{x}_*^j - E_{X^j}(X^j)\}.
(\#eq:singleBreakDownContribution)
\end{equation}

In equation \@ref(eq:singleBreakDownContribution), $v(j,\underline{x}_*)$ is the contribution of the $j$-th explanatory variable to the model's prediction $f(\underline{x}_*)$. Assume that $E_Y(Y | \underline{x}_*) \approx f(\underline{x}_*)$, where $f(\underline{x}_*)$ is the model's prediction for  $\underline{x}_*$. 
--->
<p>A possible approach to evaluate the contribution is to measure how much the expected value of <span class="math inline">\(Y\)</span> changes after conditioning on <span class="math inline">\({x}^j_*\)</span>. Using the notation <span class="math inline">\(\underline{x}^{j|=X^j}_*\)</span> (see Section <a href="modelDevelopmentProcess.html#notation">2.3</a>) to indicate that we treat the value of the <span class="math inline">\(j\)</span>-th coordinate as a random variable <span class="math inline">\(X^j\)</span>, we can thus define</p>
<p><span class="math display" id="eq:BDattr1">\[\begin{equation}
v(j, \underline{x}_*) = E_Y(Y | \underline{x}_*) - E_{X^j}\left[E_Y\left\{Y | \underline{x}^{j|=X^j}_*\right\}\right]= f(x_*) - E_{X^j}\left\{f\left(\underline{x}^{j|=X^j}_*\right)\right\},
\tag{7.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(v(j, \underline{x}_*)\)</span> is the <em>variable-importance measure</em> for the <span class="math inline">\(j\)</span>-th eplanatory variable evaluated at <span class="math inline">\(\underline{x}_*\)</span> and the last expected value on the right-hand-side of <a href="breakDown.html#eq:BDattr1">(7.2)</a> is taken over the distribution of the variable (treated as random). For the linear-regression model <a href="breakDown.html#eq:BDkinreg">(7.1)</a>, and if the explanatory variables are independent, <span class="math inline">\(v(j,\underline{x}_*)\)</span> can be expressed as follows:</p>
<p><span class="math display" id="eq:BDattr2">\[\begin{equation}
v(j, \underline{x}_*) =  \beta^0 + \underline{x}_*&#39; \underline{\beta} - E_{X^j}\left\{\beta^0 + \left(\underline{x}^{j|=X^j}_*\right)&#39; \underline{\beta}\right\} = {\beta}^j\left\{{x}_*^j - E_{X^j}(X^j)\right\}.
\tag{7.3}
\end{equation}\]</span></p>
<p>Using <a href="breakDown.html#eq:BDattr2">(7.3)</a>, the linear-regression prediction <a href="breakDown.html#eq:BDkinreg">(7.1)</a> may be re-expressed in the following way:</p>
<p><span class="math display">\[
f(\underline{x}_*) = \left\{\beta^0 + {\beta}^1E_{X^1}(X^1) + ... + {\beta}^pE_{X^p}(X^p)\right\} + \left[\left\{{x}^1_* - E_{X^1}(X^1)\right\} {\beta}^1 + ... + \left\{{x}^p_* - E_{X^p}(X^p)\right\} {\beta}^p\right] 
\]</span>
<span class="math display" id="eq:singleBreakDownResult">\[\begin{equation}
 \equiv (mean \ prediction) + \sum_{j=1}^p v(j, \underline{x}_*).
\tag{7.4}
\end{equation}\]</span></p>
<p>Thus, the contributions of the explanatory variables <span class="math inline">\(v(j, \underline{x}_*)\)</span> sum up to the difference between the model’s prediction for <span class="math inline">\(\underline{x}_*\)</span> and the mean prediction.</p>
<p>In practice, given a dataset, the expected value <span class="math inline">\(E_{X^j}(X^j)\)</span> can be estimated by the sample mean <span class="math inline">\(\bar x^j\)</span>. This leads to</p>
<p><span class="math display">\[\begin{equation}
{v}(j, \underline{x}_*) = {\beta}^j ({x}_*^j - \bar x^j).
\end{equation}\]</span></p>
<p>Obviously, the sample mean <span class="math inline">\(\bar x^j\)</span> is an estimator of the expected value <span class="math inline">\(E_{X^j}(X^j)\)</span>, calculated using a dataset. For the sake of simplicity we do not emphasize this difference in the notation. Also, we ignore the fact that, in practice, we never know the true model coefficients and use their estimates instead. We are also silent about the fact that in practice the variables are not independent. We needed this simplified example just to build our intuition.</p>
</div>
<div id="BDMethodGen" class="section level3" number="7.3.2">
<h3><span class="header-section-number">7.3.2</span> Break-down for a general case</h3>
<p>Again, let <span class="math inline">\(v(j, \underline{x}_*)\)</span> denote the variable-importance measure of the <span class="math inline">\(j\)</span>-th variable and instance <span class="math inline">\(\underline{x}_*\)</span>, i.e., the contribution of the <span class="math inline">\(j\)</span>-th variable to the model’s prediction at <span class="math inline">\(\underline{x}_*\)</span>.</p>
<p>We would like the sum of the <span class="math inline">\(v(j, \underline{x}_*)\)</span> for all explanatory variables to be equal to the instance prediction. This property is called <em>local accuracy</em>. Thus, we want that</p>
<p><span class="math display" id="eq:generalBreakDownLocalAccuracy">\[\begin{equation}
f(\underline{x}_*) = v_0 + \sum_{j=1}^p v(j, \underline{x}_*),
\tag{7.5}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(v_0\)</span> denotes the mean model-prediction. Denote by <span class="math inline">\(\underline{X}\)</span> the vector of random values of explanatory variables. If we rewrite equation <a href="breakDown.html#eq:generalBreakDownLocalAccuracy">(7.5)</a> as follows:</p>
<p><span class="math display">\[\begin{equation}
E_{\underline{X}}\{f(\underline{X})|X^1 = {x}^1_*, \ldots, X^p = {x}^p_*\} = E_{\underline{X}}\{f(\underline{X})\} + \sum_{j=1}^p v(j, \underline{x}_*),
\end{equation}\]</span></p>
<p>then a natural proposal for <span class="math inline">\(v(j, \underline{x}_*)\)</span> is</p>
<p><span class="math display" id="eq:generalBreakDownProposition">\[\begin{equation}
v(j, \underline{x}_*) = E_{\underline{X}}\{f(\underline{X}) | X^1 = {x}^1_*, \ldots, X^j = {x}^j_*\} - E_{\underline{X}}\{f(\underline{X}) | X^1 = {x}^1_*, \ldots, X^{j-1} = {x}^{j-1}_*\}. 
\tag{7.6}
\end{equation}\]</span></p>
<p>In other words, the contribution of the <span class="math inline">\(j\)</span>-th variable is the difference between the expected value of the model’s prediction conditional on setting the values of the first <span class="math inline">\(j\)</span> variables equal to their values in <span class="math inline">\(\underline{x}_*\)</span> and the expected value conditional on setting the values of the first <span class="math inline">\(j-1\)</span> variables equal to their values in <span class="math inline">\(\underline{x}_*\)</span>.</p>
<p>Note that the definition does imply the dependence of <span class="math inline">\(v(j, \underline{x}_*)\)</span> on the order of the explanatory variables that is reflected in their indices (superscripts).</p>
<p>To consider more general cases, let <span class="math inline">\(J\)</span> denote a subset of <span class="math inline">\(K\)</span> (<span class="math inline">\(K\leq p\)</span>) indices from <span class="math inline">\(\{1,2,\ldots,p\}\)</span>, i.e., <span class="math inline">\(J=\{j_1,j_2,\ldots,j_K\}\)</span> where each <span class="math inline">\(j_k \in \{1,2,\ldots,p\}\)</span>. Furthermore, let <span class="math inline">\(L\)</span> denote another subset of <span class="math inline">\(M\)</span> (<span class="math inline">\(M\leq p-K\)</span>) indices from <span class="math inline">\(\{1,2,\ldots,p\}\)</span>, distinct from <span class="math inline">\(J\)</span>. That is, <span class="math inline">\(L=\{l_1,l_2,\ldots,l_M\}\)</span> where each <span class="math inline">\(l_m \in \{1,2,\ldots,p\}\)</span> and <span class="math inline">\(J \cap L = \emptyset\)</span>. Let us define now</p>
<p><span class="math display">\[\begin{eqnarray}
\Delta^{L|J}(\underline{x}_*) &amp;\equiv&amp; E_{\underline{X}}\{f(\underline{X}) | X^{l_1} = {x}_*^{l_1},\ldots,X^{l_M} = {x}_*^{l_M},X^{j_1} = {x}_*^{j_1},\ldots,X^{j_K} = {x}_*^{j_K}\}\\
&amp;-&amp; E_{\underline{X}}\{f(\underline{X}) | X^{j_1} = {x}_*^{j_1},\ldots,X^{j_K} = {x}_*^{j_K}\}.
\end{eqnarray}\]</span></p>
<p>In other words, <span class="math inline">\(\Delta^{L|J}(\underline{x}_*)\)</span> is the change between the expected model-prediction, when setting the values of the explanatory variables with indices from the set <span class="math inline">\(J \cup L\)</span> equal to their values in <span class="math inline">\(\underline{x}_*\)</span>, and the expected prediction conditional on setting the values of the explanatory variables with indices from the set <span class="math inline">\(J\)</span> equal to their values in <span class="math inline">\(\underline{x}_*\)</span>.</p>
<p>In particular, for the <span class="math inline">\(l\)</span>-th explanatory variable, let</p>
<p><span class="math display" id="eq:lcondJBD">\[\begin{eqnarray}
\Delta^{l|J}(\underline{x}_*) \equiv \Delta^{\{l\}|J}(\underline{x}_*) &amp;=&amp; E_{\underline{X}}\{f(\underline{X}) | X^{j_1} = {x}_*^{j_1},\ldots,X^{j_K} = {x}_*^{j_K}, X^{l} = {x}_*^{l}\}\\
&amp;-&amp; E_{\underline{X}}\{f(\underline{X}) | X^{j_1} = {x}_*^{j_1},\ldots,X^{j_K} = {x}_*^{j_K}\}.
\tag{7.7}
\end{eqnarray}\]</span></p>
<p>Thus, <span class="math inline">\(\Delta^{l|J}\)</span> is the change between the expected prediction, when setting the values of the explanatory variables with indices from the set <span class="math inline">\(J \cup \{l\}\)</span> equal to their values in <span class="math inline">\(\underline{x}_*\)</span>, and the expected prediction conditional on setting the values of the explanatory variables with indices from the set <span class="math inline">\(J\)</span> equal to their values in <span class="math inline">\(\underline{x}_*\)</span>. Note that, if <span class="math inline">\(J=\emptyset\)</span>, then</p>
<p><span class="math display" id="eq:deltaBreakDownAdditive">\[\begin{equation}
\Delta^{l|\emptyset}(\underline{x}_*) = E_{\underline{X}}\{f(\underline{X}) | X^{l} = {x}_*^{l}\} - E_{\underline{X}}\{f(\underline{X})\} = E_{\underline{X}}\{f(\underline{X}) | X^{l} = {x}_*^{l}\} - v_0.
\tag{7.8}
\end{equation}\]</span></p>
<p>It follows that</p>
<p><span class="math display" id="eq:viBD">\[\begin{equation}
v(j, \underline{x}_*) = \Delta^{j|\{1,\ldots, j-1\}}(\underline{x}_*) = \Delta^{\{1,\ldots, j\}|\emptyset}(\underline{x}_*)-\Delta^{\{1,\ldots, j-1\}|\emptyset}(\underline{x}_*).
\tag{7.9}
\end{equation}\]</span></p>
<p>As it was mentioned in Section <a href="breakDown.html#BDIntuition">7.2</a>, for models that include interactions, the value of the variable-importance measure <span class="math inline">\(v(j, \underline{x}_*)\)</span> depends on the order of conditioning on explanatory variables. A heuristic approach to address this issue consists of choosing an order in which the variables with the largest contributions are selected first. In particular, the following two-step procedure can be considered. In the first step, the ordering is chosen based on the decreasing values of <span class="math inline">\(|\Delta^{k|\emptyset}(\underline{x}_*)|\)</span>. Note that the use of absolute values is needed, because the variable contributions can be positive or negative. In the second step, the variable-importance measure for the <span class="math inline">\(j\)</span>-th variable is calculated as
<span class="math display">\[
v(j, \underline{x}_*) = \Delta ^{j|J}(\underline{x}_*),
\]</span>
where
<span class="math display">\[
J = \{k: |\Delta^{k|\emptyset}(\underline{x}_*)| &lt; |\Delta^{j|\emptyset}(\underline{x}_*)|\}.
\]</span>
That is, <span class="math inline">\(J\)</span> is the set of indices of explanatory variables with scores <span class="math inline">\(|\Delta^{k|\emptyset}(\underline{x}_*)|\)</span> smaller than the corresponding score for variable <span class="math inline">\(j\)</span>.</p>
<p>The time complexity of each of the two steps of the procedure is <span class="math inline">\(O(p)\)</span>, where <span class="math inline">\(p\)</span> is the number of explanatory variables.</p>
<p>Note, that there are also other possible approaches to the problem of calculation of variable attributions. One consists of identifying the interactions that cause a difference in variable-importance measures for different orderings and focusing on those interactions. This approach is discussed in Chapter <a href="iBreakDown.html#iBreakDown">8</a>. The other one consists of calculating an average value of the variance-importance measure across all possible orderings. This approach is presented in Chapter <a href="shapley.html#shapley">9</a>.</p>
</div>
</div>
<div id="BDExample" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Example: Titanic data</h2>
<p>Let us consider the random-forest model <code>titanic_rf</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">5.2.2</a>) and passenger Johnny D (see Section <a href="dataSetsIntro.html#predictions-titanic">5.2.5</a>) as the instance of interest in the Titanic data.</p>
<p>The mean of model’s predictions for all passengers is equal to <span class="math inline">\(v_0=\)</span> 0.2353095. Table <a href="breakDown.html#tab:titanicBreakDownDeltas">7.1</a> presents the scores <span class="math inline">\(|\Delta^{j|\emptyset}(\underline{x}_*)|\)</span> and the expected values <span class="math inline">\(E_{\underline{X}}\{f(\underline{X}) | X^j = {x}^j_*\}\)</span>. Note that, given <a href="breakDown.html#eq:deltaBreakDownAdditive">(7.8)</a> and the fact that <span class="math inline">\(E_{\underline{X}}\{f(\underline{X}) | X^j = {x}^j_*\}&gt;v_0\)</span> for all variables, we have got <span class="math inline">\(E_{\underline{X}}\{f(\underline{X}) | X^j = {x}^j_*\}=|\Delta^{j|\emptyset}(\underline{x}_*)|+v_0\)</span>.</p>
<table style="width:100%;">
<caption><span id="tab:titanicBreakDownDeltas">Table 7.1: </span> Expected values <span class="math inline">\(E_{\underline{X}}\{f(\underline{X}) | X^j = {x}^j_*\}\)</span> and scores <span class="math inline">\(|\Delta^{j|\emptyset}(\underline{x}_*)|\)</span> for the random-forest model <code>titanic_rf</code> and Johnny D for the Titanic data. The scores are sorted in the decreasing order.</caption>
<colgroup>
<col width="53%" />
<col width="23%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">variable <span class="math inline">\(j\)</span></th>
<th align="right"><span class="math inline">\(E_{\underline{X}}\{f(\underline{X}) | X^j = {x}^j_*\}\)</span></th>
<th align="right"><span class="math inline">\(|\Delta^{j|\emptyset}(\underline{x}_*)|\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">age = 8</td>
<td align="right">0.7407795</td>
<td align="right">0.5051210</td>
</tr>
<tr class="even">
<td align="left">class = 1st</td>
<td align="right">0.6561034</td>
<td align="right">0.4204449</td>
</tr>
<tr class="odd">
<td align="left">fare = 72</td>
<td align="right">0.6141968</td>
<td align="right">0.3785383</td>
</tr>
<tr class="even">
<td align="left">sibsp = 0</td>
<td align="right">0.4786182</td>
<td align="right">0.2429597</td>
</tr>
<tr class="odd">
<td align="left">parch = 0</td>
<td align="right">0.4679240</td>
<td align="right">0.2322655</td>
</tr>
<tr class="even">
<td align="left">embarked = Southampton</td>
<td align="right">0.4602620</td>
<td align="right">0.2246035</td>
</tr>
<tr class="odd">
<td align="left">gender = male</td>
<td align="right">0.3459458</td>
<td align="right">0.1102873</td>
</tr>
</tbody>
</table>
<p>Based on the ordering defined by the scores <span class="math inline">\(|\Delta^{j|\emptyset}(\underline{x}_*)|\)</span> from Table <a href="breakDown.html#tab:titanicBreakDownDeltas">7.1</a>, we can compute the variable-importance measures based on the sequential contributions <span class="math inline">\(\Delta^{j|J}(\underline{x}_*)\)</span>. The computed values are presented in Table <a href="breakDown.html#tab:titanicBreakDownDeltasConseq">7.2</a>.</p>
<table>
<caption><span id="tab:titanicBreakDownDeltasConseq">Table 7.2: </span> Variable-importance measures <span class="math inline">\(\Delta^{j|\{1,\ldots,j\}}(\underline{x}_*)\)</span> for the random-forest model <code>titanic_rf</code> and Johnny D for the Titanic data, computed by using the ordering of variables defined in Table <a href="breakDown.html#tab:titanicBreakDownDeltas">7.1</a>.</caption>
<colgroup>
<col width="47%" />
<col width="25%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">variable <span class="math inline">\(j\)</span></th>
<th align="right"><span class="math inline">\(E_{\underline{X}}\left\{ f(\underline{X}) | \underline{X}^{\{1,\ldots,j\}} = \underline{x}^{\{1,\ldots,j\}}_*\right\}\)</span></th>
<th align="right"><span class="math inline">\(\Delta^{j|\{1,\ldots,j\}}(\underline{x}_*)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">intercept <span class="math inline">\((v_0)\)</span></td>
<td align="right">0.2353095</td>
<td align="right">0.2353095</td>
</tr>
<tr class="even">
<td align="left">age = 8</td>
<td align="right">0.5051210</td>
<td align="right">0.2698115</td>
</tr>
<tr class="odd">
<td align="left">class = 1st</td>
<td align="right">0.5906969</td>
<td align="right">0.0855759</td>
</tr>
<tr class="even">
<td align="left">fare = 72</td>
<td align="right">0.5443561</td>
<td align="right">-0.0463407</td>
</tr>
<tr class="odd">
<td align="left">gender = male</td>
<td align="right">0.4611518</td>
<td align="right">-0.0832043</td>
</tr>
<tr class="even">
<td align="left">embarked = Southampton</td>
<td align="right">0.4584422</td>
<td align="right">-0.0027096</td>
</tr>
<tr class="odd">
<td align="left">sibsp = 0</td>
<td align="right">0.4523398</td>
<td align="right">-0.0061024</td>
</tr>
<tr class="even">
<td align="left">parch = 0</td>
<td align="right">0.4220000</td>
<td align="right">-0.0303398</td>
</tr>
<tr class="odd">
<td align="left">prediction</td>
<td align="right">0.4220000</td>
<td align="right">0.4220000</td>
</tr>
</tbody>
</table>
<p>Results from Table <a href="breakDown.html#tab:titanicBreakDownDeltasConseq">7.2</a> are presented in Figure <a href="breakDown.html#fig:BDjohnyExample">7.3</a>. The plot indicates that the largest positive contributions to the predicted probability of survival for Johnny D come from explanatory variables <em>age</em> and <em>class</em>. The contributions of the remaining variables are smaller (in absolute values) and negative.</p>

<div class="figure" style="text-align: center"><span id="fig:BDjohnyExample"></span>
<img src="ema_files/figure-html/BDjohnyExample-1.png" alt="Break-down plot for the random-forest model titanic_rf and Johnny D for the Titanic data." width="70%" />
<p class="caption">
Figure 7.3: Break-down plot for the random-forest model <code>titanic_rf</code> and Johnny D for the Titanic data.
</p>
</div>
</div>
<div id="BDProsCons" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Pros and cons</h2>
<p>BD plots offer a model-agnostic approach that can be applied to any predictive model that returns a single number for a single observation (instance). The approach offers several advantages. The plots are, in general, easy to understand. They are compact; results for many explanatory variables can be presented in a limited space. The approach reduces to an intuitive interpretation for linear models. Numerical complexity of the BD algorithm is linear in the number of explanatory variables.</p>
<p>An important issue is that BD plots may be misleading for models including interactions. This is because the plots show only the additive attributions. Thus, the choice of the ordering of the explanatory variables that is used in the calculation of the variable-importance measures is important. Also, for models with a large number of variables, BD plots may be complex and include many explanatory variables with small contributions to the instance prediction.</p>
<p>To address the issue of dependence of the variable-importance measure on the ordering of the explanatory variables, the heuristic approach described in Section <a href="breakDown.html#BDMethodGen">7.3.2</a> can be applied. Alternative approaches are described in Chapters <a href="iBreakDown.html#iBreakDown">8</a> and <a href="shapley.html#shapley">9</a>.</p>
</div>
<div id="BDR" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Code snippets for R</h2>
<p>In this section, we use the <code>DALEX</code> package, which is a wrapper for the <code>iBreakDown</code> R package <span class="citation">(Gosiewska and Biecek <a href="#ref-iBreakDownRPackage" role="doc-biblioref">2019</a><a href="#ref-iBreakDownRPackage" role="doc-biblioref">a</a>)</span>. The package covers all methods presented in this chapter. It is available on CRAN and GitHub.</p>
<p>For illustration purposes, we use the <code>titanic_rf</code> random-forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-rf">5.2.2</a>. Recall that the model is developed to predict the probability of survival for passengers of Titanic. Instance-level explanations are calculated for Henry, a 47-year-old passenger that travelled in the 1st class (see Section <a href="dataSetsIntro.html#predictions-titanic">5.2.5</a>).</p>
<p>We first retrieve the <code>titanic_rf</code> model-object and the data frame for Henry via the <code>archivist</code> hooks, as listed in Section <a href="dataSetsIntro.html#ListOfModelsTitanic">5.2.7</a>. We also retrieve the version of the <code>titanic</code> data with imputed missing values.</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="breakDown.html#cb70-1"></a>titanic_imputed &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/27e5c&quot;</span>)</span>
<span id="cb70-2"><a href="breakDown.html#cb70-2"></a>titanic_rf &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="st"> </span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/4e0fc&quot;</span>)</span>
<span id="cb70-3"><a href="breakDown.html#cb70-3"></a>(henry &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/a6538&quot;</span>))</span></code></pre></div>
<pre><code>##   class gender age sibsp parch fare  embarked
## 1   1st   male  47     0     0   25 Cherbourg</code></pre>
<p>Then we construct the explainer for the model by using function <code>explain()</code> from the <code>DALEX</code> package (see Section <a href="dataSetsIntro.html#ExplainersTitanicRCode">5.2.6</a>). We also load the <code>randomForest</code> package, as the model was fitted by using function <code>randomForest()</code> from this package (see Section <a href="dataSetsIntro.html#model-titanic-rf">5.2.2</a>) and it is important to have the corresponding <code>predict()</code> function available.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="breakDown.html#cb72-1"></a><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</span>
<span id="cb72-2"><a href="breakDown.html#cb72-2"></a><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</span>
<span id="cb72-3"><a href="breakDown.html#cb72-3"></a>explain_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf,  </span>
<span id="cb72-4"><a href="breakDown.html#cb72-4"></a>                          <span class="dt">data =</span> titanic_imputed[, <span class="dv">-9</span>],</span>
<span id="cb72-5"><a href="breakDown.html#cb72-5"></a>                             <span class="dt">y =</span> titanic_imputed<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, </span>
<span id="cb72-6"><a href="breakDown.html#cb72-6"></a>                         <span class="dt">label =</span> <span class="st">&quot;Random Forest&quot;</span>,</span>
<span id="cb72-7"><a href="breakDown.html#cb72-7"></a>                       <span class="dt">verbose =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p>The Explainer is needed to allow uniform access to predictive models regardless of their internal structure. With this object we can proceed to the model analysis.</p>
<!-- Note that we could have loaded the explainer object by using the `archivist` hook given in Section \@ref(ListOfModelsTitanic). However, creation of an explainer object is a required step for any analysis conducted with the help of `DALEX`package functions. Thus, here (and in subsequent chapters) we prefer to perform this step explicitly.  -->
<div id="basic-use-of-the-predict_parts-function" class="section level3" number="7.6.1">
<h3><span class="header-section-number">7.6.1</span> Basic use of the <code>predict_parts()</code> function</h3>
<p>The <code>DALEX::predict_parts()</code> function decomposes model predictions into parts that can be attributed to individual variables. It calculates the variable-attribution measures for a selected model and the instance of interest. The object obtained as a result of applying the function is a data frame containing the calculated measures.</p>
<p>In the simplest call, the function requires three arguments:</p>
<ul>
<li><code>explainer</code> - an explainer-object, created with function <code>DALEX::explain()</code>;</li>
<li><code>new_observation</code> - an observation to be explained; it should be a data frame with a structure that matches the structure of the dataset used for fitting of the model;</li>
<li><code>type</code> - the method for calculation of variable attribution; the possible methods are “break_down” (the default), “shap”, “oscillations”, and “break_down_interactions”.</li>
</ul>
<p>In the code below, the argument <code>type = "break_down"</code> is explicitly used. The code essentially provides the variable-importance values <span class="math inline">\(\Delta^{j|\{1,\ldots,j\}}(\underline{x}_*)\)</span>.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="breakDown.html#cb73-1"></a>bd_rf &lt;-<span class="st"> </span><span class="kw">predict_parts</span>(<span class="dt">explainer =</span> explain_rf,</span>
<span id="cb73-2"><a href="breakDown.html#cb73-2"></a>                        <span class="dt">new_observation =</span> henry,</span>
<span id="cb73-3"><a href="breakDown.html#cb73-3"></a>                                   <span class="dt">type =</span> <span class="st">&quot;break_down&quot;</span>)</span>
<span id="cb73-4"><a href="breakDown.html#cb73-4"></a>bd_rf</span></code></pre></div>
<pre><code>##                                     contribution
## Random Forest: intercept                   0.235
## Random Forest: class = 1st                 0.185
## Random Forest: gender = male              -0.124
## Random Forest: embarked = Cherbourg        0.105
## Random Forest: age = 47                   -0.092
## Random Forest: fare = 25                  -0.030
## Random Forest: sibsp = 0                  -0.032
## Random Forest: parch = 0                  -0.001
## Random Forest: prediction                  0.246</code></pre>
<p>By applying the generic <code>plot()</code> function to the object resulting from the application of the <code>predict_parts()</code> function we obtain a BD plot, shown in Figure <a href="breakDown.html#fig:BDhenryExample">7.4</a>.</p>

<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="breakDown.html#cb75-1"></a><span class="kw">plot</span>(bd_rf) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BDhenryExample"></span>
<img src="ema_files/figure-html/BDhenryExample-1.png" alt="Break-down plot obtained by the generic plot() function for the random-forest model titanic_rf and Henry for the Titanic data." width="70%" />
<p class="caption">
Figure 7.4: Break-down plot obtained by the generic <code>plot()</code> function for the random-forest model <code>titanic_rf</code> and Henry for the Titanic data.
</p>
</div>
<p>Figure <a href="breakDown.html#fig:BDhenryExample">7.4</a> can be used to compare the explanatory-variable attributions obtained for Henry with those computed for Johnny D (see Figure <a href="breakDown.html#fig:BDjohnyExample">7.3</a>). Both explanations refer to the same random-forest model. We can see that the predicted survival probability for Henry (0.246) is almost the same as the mean prediction (0.235), while the probability for Johnny D is higher (0.422). For Johnny D, this result can be mainly attributed to the positive contribution of <em>age</em> and <em>class</em>. For Henry, <em>class</em> still contributes positively to the chances of survival, but the effect of <em>age</em> is negative. For both passengers the effect of <em>gender</em> is negative. Thus, one could conclude that the difference in the predicted survival probabilities is mainly due to the difference in age of Henry and Johnny D.</p>
</div>
<div id="advanced-use-of-the-predict_parts-function" class="section level3" number="7.6.2">
<h3><span class="header-section-number">7.6.2</span> Advanced use of the <code>predict_parts()</code> function</h3>
<p>Apart from the <code>explainer</code>, <code>new_observation</code>, and <code>type</code> arguments, function <code>predict_parts()</code> allows additional ones. The most commonly used are:</p>
<ul>
<li><code>order</code> - a vector of characters (column names) or integers (column indexes) that specify order of explanatory variables to be used for computing the variable-importance measures; if not specified (default), then a one-step heuristic is used to determine the order;</li>
<li><code>keep_distributions</code> - a logical value (FALSE by default); if TRUE, then additional diagnostic information about conditional distributions of predictons is stored in the resulting object and can be plotted with the generic <code>plot()</code> function.</li>
</ul>
<p>In what follows, we illustrate the use of the arguments.</p>
<p>First, we specify the ordering of the explanatory variables. Toward this end, we can use integer indexes or variable names. The latter option is prerferable in most cases because of transparency. Additionally, to reduce clutter in the plot, we set <code>max_features = 3</code> argument in the <code>plot()</code> function. The resulting plot is presented in Figure <a href="breakDown.html#fig:BDhenryExampleTop">7.5</a>. It is worth noting that the attributions for variables <em>gender</em> and <em>fare</em> do differ from those shown in Figure <a href="breakDown.html#fig:BDhenryExample">7.4</a>. This is the result of the change of the ordering of variables used in computation of the attributions.</p>

<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="breakDown.html#cb76-1"></a>bd_rf_order &lt;-<span class="st"> </span><span class="kw">variable_attribution</span>(<span class="dt">explainer =</span> explain_rf,</span>
<span id="cb76-2"><a href="breakDown.html#cb76-2"></a>                              <span class="dt">new_observation =</span> henry, </span>
<span id="cb76-3"><a href="breakDown.html#cb76-3"></a>                                         <span class="dt">type =</span> <span class="st">&quot;break_down&quot;</span>,</span>
<span id="cb76-4"><a href="breakDown.html#cb76-4"></a>               <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;class&quot;</span>, <span class="st">&quot;age&quot;</span>, <span class="st">&quot;gender&quot;</span>, <span class="st">&quot;fare&quot;</span>, <span class="st">&quot;parch&quot;</span>, <span class="st">&quot;sibsp&quot;</span>, <span class="st">&quot;embarked&quot;</span>))</span>
<span id="cb76-5"><a href="breakDown.html#cb76-5"></a><span class="kw">plot</span>(bd_rf_order, <span class="dt">max_features =</span> <span class="dv">3</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BDhenryExampleTop"></span>
<img src="ema_files/figure-html/BDhenryExampleTop-1.png" alt="Break-down plot for top three variables for the random-forest model titanic_rf and Henry for the Titanic data." width="70%" />
<p class="caption">
Figure 7.5: Break-down plot for top three variables for the random-forest model <code>titanic_rf</code> and Henry for the Titanic data.
</p>
</div>
<p>We can use the <code>keep_distributions = TRUE</code> argument to enrich the resulting object with additional information about conditional distributions of predicted values. Subsequently, we can apply the <code>plot_distributions = TRUE</code> argument in the <code>plot()</code> function to present the distributions as violin plots.</p>

<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="breakDown.html#cb77-1"></a>bd_rf_distr &lt;-<span class="st"> </span><span class="kw">predict_parts</span>(<span class="dt">explainer =</span> explain_rf,</span>
<span id="cb77-2"><a href="breakDown.html#cb77-2"></a>                              <span class="dt">new_observation =</span> henry, </span>
<span id="cb77-3"><a href="breakDown.html#cb77-3"></a>                                        <span class="dt">type =</span> <span class="st">&quot;break_down&quot;</span>,</span>
<span id="cb77-4"><a href="breakDown.html#cb77-4"></a>          <span class="dt">order =</span> <span class="kw">c</span>(<span class="st">&quot;age&quot;</span>, <span class="st">&quot;class&quot;</span>, <span class="st">&quot;fare&quot;</span>, <span class="st">&quot;gender&quot;</span>, <span class="st">&quot;embarked&quot;</span>, <span class="st">&quot;sibsp&quot;</span>, <span class="st">&quot;parch&quot;</span>),</span>
<span id="cb77-5"><a href="breakDown.html#cb77-5"></a>                          <span class="dt">keep_distributions =</span> <span class="ot">TRUE</span>)</span>
<span id="cb77-6"><a href="breakDown.html#cb77-6"></a><span class="kw">plot</span>(bd_rf_distr, <span class="dt">plot_distributions =</span> <span class="ot">TRUE</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:BDhenryExampleDistr"></span>
<img src="ema_files/figure-html/BDhenryExampleDistr-1.png" alt="Break-down plot with violin plots summarizing distributions of predicted values for a selected order of explanatory variables for the random-forest model titanic_rf and Henry for the Titanic data." width="70%" />
<p class="caption">
Figure 7.6: Break-down plot with violin plots summarizing distributions of predicted values for a selected order of explanatory variables for the random-forest model <code>titanic_rf</code> and Henry for the Titanic data.
</p>
</div>
<p>The resulting plot is presented in Figure <a href="breakDown.html#fig:BDhenryExampleDistr">7.6</a>. Red dots indicate the mean model’s predictions. Thin grey lines between violin plots indicate changes in predictions for individual observations. They can be used to track how do the model’s predictions change after consecutive conditionings. A similar code was used to create the plot in panel A of Figure <a href="breakDown.html#fig:BDPrice4">7.1</a> for Johnny D.</p>
</div>
</div>
<div id="BDPython" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Code snippets for Python</h2>
<p>In this section, we use the <code>dalex</code> library for Python. The package covers all methods presented in this chapter. It is available on pip and GitHub.</p>
<p>For illustration purposes, we use the <code>titanic_rf</code> random-forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-python-rf">5.3.2</a>. Recall that the model is developed to predict the probability of survival for passengers of Titanic. Instance-level explanations are calculated for Henry, a 47-year-old passenger that travelled in the 1st class (see Section <a href="dataSetsIntro.html#predictions-titanic-python">5.3.5</a>).</p>
<p>In the first step we create an Explainer, an object that will provide a uniform interface for the predictive model. We use the <code>Explainer</code> constructor for this purpose.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb78-1"><a href="breakDown.html#cb78-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb78-2"><a href="breakDown.html#cb78-2"></a>henry <span class="op">=</span> pd.DataFrame({<span class="st">&#39;gender&#39;</span>: [<span class="st">&#39;male&#39;</span>],</span>
<span id="cb78-3"><a href="breakDown.html#cb78-3"></a>                       <span class="st">&#39;age&#39;</span>: [<span class="dv">47</span>],</span>
<span id="cb78-4"><a href="breakDown.html#cb78-4"></a>                       <span class="st">&#39;class&#39;</span>: [<span class="st">&#39;1st&#39;</span>],</span>
<span id="cb78-5"><a href="breakDown.html#cb78-5"></a>                       <span class="st">&#39;embarked&#39;</span>: [<span class="st">&#39;Southampton&#39;</span>],</span>
<span id="cb78-6"><a href="breakDown.html#cb78-6"></a>                       <span class="st">&#39;fare&#39;</span>: [<span class="dv">25</span>],</span>
<span id="cb78-7"><a href="breakDown.html#cb78-7"></a>                       <span class="st">&#39;sibsp&#39;</span>: [<span class="dv">0</span>],</span>
<span id="cb78-8"><a href="breakDown.html#cb78-8"></a>                       <span class="st">&#39;parch&#39;</span>: [<span class="dv">0</span>]},</span>
<span id="cb78-9"><a href="breakDown.html#cb78-9"></a>                      index <span class="op">=</span> [<span class="st">&#39;Henry&#39;</span>])</span>
<span id="cb78-10"><a href="breakDown.html#cb78-10"></a></span>
<span id="cb78-11"><a href="breakDown.html#cb78-11"></a><span class="im">import</span> dalex <span class="im">as</span> dx</span>
<span id="cb78-12"><a href="breakDown.html#cb78-12"></a>titanic_rf_exp <span class="op">=</span> dx.Explainer(titanic_rf, X, y, label <span class="op">=</span> <span class="st">&quot;Titanic RF Pipeline&quot;</span>)</span></code></pre></div>
<p>To calculate the attributions with the break down method one can use the predict_parts method. The first argument is the observation for which the attributions are to be calculated. The type argument specifies how the attribute is to be calculated.</p>
<p>To plot a waterfall chart just use the <code>plot</code> method. It generates an interactive chart based on the <code>plotly</code> library.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="breakDown.html#cb79-1"></a>bd_henry <span class="op">=</span> exp_rf.predict_parts(henry, <span class="bu">type</span><span class="op">=</span><span class="st">&#39;break_down&#39;</span>)</span>
<span id="cb79-2"><a href="breakDown.html#cb79-2"></a>bd_henry.plot()</span></code></pre></div>
<p><img src="figure/bd_python_1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Advanced users can make use from the argument <code>order</code>. This way, they can force a specific order of variables in the break down method.</p>
<p>If there are many variables in the model, the waterfall diagram may be hard to read. In this situation, the <code>max_vars</code> argument can be used to limit the number of variables presented in the graph.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="breakDown.html#cb80-1"></a>bd_henry <span class="op">=</span> exp_rf.predict_parts(henry, <span class="bu">type</span><span class="op">=</span><span class="st">&#39;break_down&#39;</span>, order<span class="op">=</span>np.array([<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="dv">6</span>]))</span>
<span id="cb80-2"><a href="breakDown.html#cb80-2"></a>bd_henry.plot(max_vars<span class="op">=</span><span class="dv">5</span>)</span></code></pre></div>
<p><img src="figure/bd_python_2.png" width="80%" style="display: block; margin: auto;" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-iBreakDownRPackage">
<p>Gosiewska, Alicja, and Przemyslaw Biecek. 2019a. “iBreakDown: Uncertainty of Model Explanations for Non-additive Predictive Models.” <a href="https://arxiv.org/abs/1903.11420v1">https://arxiv.org/abs/1903.11420v1</a>.</p>
</div>
<div id="ref-explainPaper">
<p>Robnik-Šikonja, Marco, and Igor Kononenko. 2008. “Explaining Classifications for Individual Instances.” <em>IEEE Transactions on Knowledge and Data Engineering</em> 20 (5): 589–600. <a href="https://doi.org/10.1109/tkde.2007.190734">https://doi.org/10.1109/tkde.2007.190734</a>.</p>
</div>
<div id="ref-explainPackage">
<p>Robnik-Šikonja, Marko. 2018. <em>ExplainPrediction: Explanation of Predictions for Classification and Regression Models</em>. <a href="https://CRAN.R-project.org/package=ExplainPrediction">https://CRAN.R-project.org/package=ExplainPrediction</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="InstanceLevelExploration.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="iBreakDown.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
