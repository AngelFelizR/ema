<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visual Exploration, Explanation and Debugging</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visual Exploration, Explanation and Debugging" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visual Exploration, Explanation and Debugging" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2019-06-03">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="ceterisParibus2d.html">

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/PM_VEE/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#notes-to-readers"><i class="fa fa-check"></i><b>1.1</b> Notes to readers</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.2</b> The aim of the book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#three-single-laws"><i class="fa fa-check"></i><b>1.3</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#terminology"><i class="fa fa-check"></i><b>1.4</b> Terminology</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#white-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.5</b> White-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#model-visualization-exploration-and-explanation"><i class="fa fa-check"></i><b>1.6</b> Model visualization, exploration, and explanation</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.7</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#notation"><i class="fa fa-check"></i><b>1.8</b> Notation</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#bookstructure"><i class="fa fa-check"></i><b>1.9</b> The structure of the book</a></li>
<li class="chapter" data-level="1.10" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.10</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="RCodeSnippets.html"><a href="RCodeSnippets.html"><i class="fa fa-check"></i><b>2</b> Do-it-yourself With R</a><ul>
<li class="chapter" data-level="2.1" data-path="RCodeSnippets.html"><a href="RCodeSnippets.html#what-to-install"><i class="fa fa-check"></i><b>2.1</b> What to install?</a></li>
<li class="chapter" data-level="2.2" data-path="RCodeSnippets.html"><a href="RCodeSnippets.html#how-to-work-with-dalex"><i class="fa fa-check"></i><b>2.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="2.3" data-path="RCodeSnippets.html"><a href="RCodeSnippets.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>2.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="PythonCodeSnippets.html"><a href="PythonCodeSnippets.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself With Python</a></li>
<li class="chapter" data-level="4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html"><i class="fa fa-check"></i><b>4</b> Data Sets</a><ul>
<li class="chapter" data-level="4.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>4.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="4.1.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>4.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="4.1.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>4.1.2</b> Logistic regression</a></li>
<li class="chapter" data-level="4.1.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>4.1.3</b> Random forest</a></li>
<li class="chapter" data-level="4.1.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>4.1.4</b> Gradient boosting</a></li>
<li class="chapter" data-level="4.1.5" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>4.1.5</b> Model predictions</a></li>
<li class="chapter" data-level="4.1.6" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>4.1.6</b> Explainers</a></li>
<li class="chapter" data-level="4.1.7" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>4.1.7</b> List of objects for the <code>titanic</code> example</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>4.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="4.2.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>4.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="4.2.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>4.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="4.2.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>4.2.3</b> Random forest</a></li>
<li class="chapter" data-level="4.2.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>4.2.4</b> Model predictions</a></li>
<li class="chapter" data-level="4.2.5" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>4.2.5</b> List of objects for the <code>apartments</code> example</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#HFDataset"><i class="fa fa-check"></i><b>4.3</b> Hire or fire</a><ul>
<li class="chapter" data-level="4.3.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#exploration-HR"><i class="fa fa-check"></i><b>4.3.1</b> Data exploration</a></li>
<li class="chapter" data-level="4.3.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-HR-mr"><i class="fa fa-check"></i><b>4.3.2</b> Multinomial logistic regression</a></li>
<li class="chapter" data-level="4.3.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-HR-rf"><i class="fa fa-check"></i><b>4.3.3</b> Random forest</a></li>
<li class="chapter" data-level="4.3.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#predictionsHR"><i class="fa fa-check"></i><b>4.3.4</b> Model predictions</a></li>
<li class="chapter" data-level="4.3.5" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ListOfModelsHR"><i class="fa fa-check"></i><b>4.3.5</b> List of objects for the <code>HR</code> example</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level-explanation.html"><a href="instance-level-explanation.html"><i class="fa fa-check"></i>Instance-level explanation</a></li>
<li class="chapter" data-level="5" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>5</b> Introduction</a></li>
<li class="chapter" data-level="6" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>6</b> Ceteris-paribus Profiles and What-If Analysis</a><ul>
<li class="chapter" data-level="6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>6.3</b> Method</a></li>
<li class="chapter" data-level="6.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>6.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="6.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>6.5</b> Pros and cons</a></li>
<li class="chapter" data-level="6.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>6.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="6.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>6.6.1</b> Basic use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="6.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-ceteris_paribus-function"><i class="fa fa-check"></i><b>6.6.2</b> Advanced use of the <code>ceteris_paribus</code> function</a></li>
<li class="chapter" data-level="6.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#champion-challenger-analysis"><i class="fa fa-check"></i><b>6.6.3</b> Champion-challenger analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>7</b> Ceteris-paribus Oscillations and Local Variable-importance</a><ul>
<li class="chapter" data-level="7.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>7.2</b> Intuition</a></li>
<li class="chapter" data-level="7.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>7.3</b> Method</a></li>
<li class="chapter" data-level="7.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>7.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>7.5</b> Pros and cons</a></li>
<li class="chapter" data-level="7.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>7.6</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>7.6.1</b> Basic use of the <code>calculate_oscillations</code> function</a></li>
<li class="chapter" data-level="7.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-calculate_oscillations-function"><i class="fa fa-check"></i><b>7.6.2</b> Advanced use of the <code>calculate_oscillations</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html"><i class="fa fa-check"></i><b>8</b> Local Diagnostics With Ceteris-paribus Profiles</a><ul>
<li class="chapter" data-level="8.1" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>8.2</b> Intuition</a></li>
<li class="chapter" data-level="8.3" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>8.3</b> Method</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagNeighbors"><i class="fa fa-check"></i><b>8.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="8.3.2" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>8.3.2</b> Profiles for neighbors</a></li>
<li class="chapter" data-level="8.3.3" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>8.3.3</b> Local-fidelity plot</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagExample"><i class="fa fa-check"></i><b>8.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.5" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>8.5</b> Pros and cons</a></li>
<li class="chapter" data-level="8.6" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#cPLocDiagR"><i class="fa fa-check"></i><b>8.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>9</b> Break Down for Additive Variable Attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="breakDown.html"><a href="breakDown.html#intuition"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="breakDown.html"><a href="breakDown.html#method"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="breakDown.html"><a href="breakDown.html#example-titanic-data"><i class="fa fa-check"></i><b>9.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.4" data-path="breakDown.html"><a href="breakDown.html#pros-and-cons"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="breakDown.html"><a href="breakDown.html#code-snippets-for-r"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="9.5.1" data-path="breakDown.html"><a href="breakDown.html#basic-usage-for-the-break_down-function"><i class="fa fa-check"></i><b>9.5.1</b> Basic usage for the <code>break_down</code> function</a></li>
<li class="chapter" data-level="9.5.2" data-path="breakDown.html"><a href="breakDown.html#advanced-usage-for-the-break_down-function"><i class="fa fa-check"></i><b>9.5.2</b> Advanced usage for the <code>break_down</code> function</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>10</b> iBreakDown for Variable Attributions with Interactions</a><ul>
<li class="chapter" data-level="10.1" data-path="iBreakDown.html"><a href="iBreakDown.html#intuition-1"><i class="fa fa-check"></i><b>10.1</b> Intuition</a></li>
<li class="chapter" data-level="10.2" data-path="iBreakDown.html"><a href="iBreakDown.html#method-1"><i class="fa fa-check"></i><b>10.2</b> Method</a><ul>
<li class="chapter" data-level="10.2.1" data-path="iBreakDown.html"><a href="iBreakDown.html#single-step-contributions"><i class="fa fa-check"></i><b>10.2.1</b> Single step contributions</a></li>
<li class="chapter" data-level="10.2.2" data-path="iBreakDown.html"><a href="iBreakDown.html#two-steps-contributions"><i class="fa fa-check"></i><b>10.2.2</b> Two steps contributions</a></li>
<li class="chapter" data-level="10.2.3" data-path="iBreakDown.html"><a href="iBreakDown.html#sequential-contributions"><i class="fa fa-check"></i><b>10.2.3</b> Sequential contributions</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="iBreakDown.html"><a href="iBreakDown.html#example-titanic"><i class="fa fa-check"></i><b>10.3</b> Example: Titanic</a></li>
<li class="chapter" data-level="10.4" data-path="iBreakDown.html"><a href="iBreakDown.html#pros-and-cons-1"><i class="fa fa-check"></i><b>10.4</b> Pros and cons</a></li>
<li class="chapter" data-level="10.5" data-path="iBreakDown.html"><a href="iBreakDown.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>10.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>11</b> SHapley Additive exPlanations (SHAP) and Average Variable Attributions</a><ul>
<li class="chapter" data-level="11.1" data-path="shapley.html"><a href="shapley.html#intuition-2"><i class="fa fa-check"></i><b>11.1</b> Intuition</a></li>
<li class="chapter" data-level="11.2" data-path="shapley.html"><a href="shapley.html#method-2"><i class="fa fa-check"></i><b>11.2</b> Method</a></li>
<li class="chapter" data-level="11.3" data-path="shapley.html"><a href="shapley.html#titanic"><i class="fa fa-check"></i><b>11.3</b> Titanic</a></li>
<li class="chapter" data-level="11.4" data-path="shapley.html"><a href="shapley.html#pros-and-cons-2"><i class="fa fa-check"></i><b>11.4</b> Pros and cons</a></li>
<li class="chapter" data-level="11.5" data-path="shapley.html"><a href="shapley.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>11.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>12</b> Local Interpretable Model-Agnostic Explanations (LIME)</a><ul>
<li class="chapter" data-level="12.1" data-path="LIME.html"><a href="LIME.html#intuition-3"><i class="fa fa-check"></i><b>12.1</b> Intuition</a></li>
<li class="chapter" data-level="12.2" data-path="LIME.html"><a href="LIME.html#method-3"><i class="fa fa-check"></i><b>12.2</b> Method</a></li>
<li class="chapter" data-level="12.3" data-path="LIME.html"><a href="LIME.html#pros-and-cons-3"><i class="fa fa-check"></i><b>12.3</b> Pros and cons</a></li>
<li class="chapter" data-level="12.4" data-path="LIME.html"><a href="LIME.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>12.4</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.4.1" data-path="LIME.html"><a href="LIME.html#the-lime-pacakge"><i class="fa fa-check"></i><b>12.4.1</b> <strong>The lime pacakge</strong></a></li>
<li class="chapter" data-level="12.4.2" data-path="LIME.html"><a href="LIME.html#the-localmodel-package"><i class="fa fa-check"></i><b>12.4.2</b> <strong>The localModel package</strong></a></li>
<li class="chapter" data-level="12.4.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>12.4.3</b> <strong>The iml package</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="CompareInstance.html"><a href="CompareInstance.html"><i class="fa fa-check"></i><b>13</b> Comparision of Instance-level Explainers</a><ul>
<li class="chapter" data-level="13.1" data-path="CompareInstance.html"><a href="CompareInstance.html#when-to-use"><i class="fa fa-check"></i><b>13.1</b> When to use?</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ModelLevelExplanations.html"><a href="ModelLevelExplanations.html"><i class="fa fa-check"></i><b>14</b> Model level explanations</a></li>
<li class="chapter" data-level="15" data-path="introduction-1.html"><a href="introduction-1.html"><i class="fa fa-check"></i><b>15</b> Introduction</a><ul>
<li class="chapter" data-level="15.1" data-path="introduction-1.html"><a href="introduction-1.html#approaches-to-model-explanations"><i class="fa fa-check"></i><b>15.1</b> Approaches to model explanations</a></li>
<li class="chapter" data-level="15.2" data-path="introduction-1.html"><a href="introduction-1.html#a-bit-of-philosophy-three-laws-for-model-level-explanations"><i class="fa fa-check"></i><b>15.2</b> A bit of philosophy: Three Laws for Model Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="variableImportance.html"><a href="variableImportance.html"><i class="fa fa-check"></i><b>16</b> Feature Importance</a><ul>
<li class="chapter" data-level="16.1" data-path="variableImportance.html"><a href="variableImportance.html#permutation-based-feature-importance"><i class="fa fa-check"></i><b>16.1</b> Permutation Based Feature Importance</a></li>
<li class="chapter" data-level="16.2" data-path="variableImportance.html"><a href="variableImportance.html#example-titanic-1"><i class="fa fa-check"></i><b>16.2</b> Example: Titanic</a></li>
<li class="chapter" data-level="16.3" data-path="variableImportance.html"><a href="variableImportance.html#example-price-prediction"><i class="fa fa-check"></i><b>16.3</b> Example: Price prediction</a></li>
<li class="chapter" data-level="16.4" data-path="variableImportance.html"><a href="variableImportance.html#more-models"><i class="fa fa-check"></i><b>16.4</b> More models</a></li>
<li class="chapter" data-level="16.5" data-path="variableImportance.html"><a href="variableImportance.html#level-frequency"><i class="fa fa-check"></i><b>16.5</b> Level frequency</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="variableEngeneering.html"><a href="variableEngeneering.html"><i class="fa fa-check"></i><b>17</b> Feature effects</a><ul>
<li class="chapter" data-level="17.1" data-path="variableEngeneering.html"><a href="variableEngeneering.html#global-level-vs-instance-level-explanations"><i class="fa fa-check"></i><b>17.1</b> Global level vs instance level explanations</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>18</b> Partial Dependency Profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#definition"><i class="fa fa-check"></i><b>18.1</b> Definition</a></li>
<li class="chapter" data-level="18.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#estimation"><i class="fa fa-check"></i><b>18.2</b> Estimation</a></li>
<li class="chapter" data-level="18.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles"><i class="fa fa-check"></i><b>18.3</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles"><i class="fa fa-check"></i><b>18.4</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="18.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-model-comparisons"><i class="fa fa-check"></i><b>18.5</b> Contrastive Model Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html"><i class="fa fa-check"></i><b>19</b> Conditional Dependency Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#definition-1"><i class="fa fa-check"></i><b>19.1</b> Definition</a></li>
<li class="chapter" data-level="19.2" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#estimation-1"><i class="fa fa-check"></i><b>19.2</b> Estimation</a></li>
<li class="chapter" data-level="19.3" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#example"><i class="fa fa-check"></i><b>19.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>20</b> Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="20.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#definition-2"><i class="fa fa-check"></i><b>20.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="how-pd-cd-and-al-profiles-are-different-and-which-to-choose.html"><a href="how-pd-cd-and-al-profiles-are-different-and-which-to-choose.html"><i class="fa fa-check"></i><b>21</b> How PD, CD and AL Profiles are different and which to choose</a></li>
<li class="chapter" data-level="22" data-path="factorMerger.html"><a href="factorMerger.html"><i class="fa fa-check"></i><b>22</b> Merging Path Plots and Others</a></li>
<li class="chapter" data-level="23" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>23</b> Other topics</a></li>
<li class="chapter" data-level="24" data-path="modelComparisons.html"><a href="modelComparisons.html"><i class="fa fa-check"></i><b>24</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="25" data-path="modelAuditing.html"><a href="modelAuditing.html"><i class="fa fa-check"></i><b>25</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="26" data-path="conceptDrift.html"><a href="conceptDrift.html"><i class="fa fa-check"></i><b>26</b> Concept Drift</a><ul>
<li class="chapter" data-level="26.1" data-path="conceptDrift.html"><a href="conceptDrift.html#introduction-2"><i class="fa fa-check"></i><b>26.1</b> Introduction</a></li>
<li class="chapter" data-level="26.2" data-path="conceptDrift.html"><a href="conceptDrift.html#covariate-drift"><i class="fa fa-check"></i><b>26.2</b> Covariate Drift</a></li>
<li class="chapter" data-level="26.3" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets"><i class="fa fa-check"></i><b>26.3</b> Code snippets</a></li>
<li class="chapter" data-level="26.4" data-path="conceptDrift.html"><a href="conceptDrift.html#residual-drift"><i class="fa fa-check"></i><b>26.4</b> Residual Drift</a></li>
<li class="chapter" data-level="26.5" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets-1"><i class="fa fa-check"></i><b>26.5</b> Code snippets</a></li>
<li class="chapter" data-level="26.6" data-path="conceptDrift.html"><a href="conceptDrift.html#model-drift"><i class="fa fa-check"></i><b>26.6</b> Model Drift</a></li>
<li class="chapter" data-level="26.7" data-path="conceptDrift.html"><a href="conceptDrift.html#code-snippets-2"><i class="fa fa-check"></i><b>26.7</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="27" data-path="DataSets.html"><a href="DataSets.html"><i class="fa fa-check"></i><b>27</b> Data Sets</a><ul>
<li class="chapter" data-level="27.1" data-path="DataSets.html"><a href="DataSets.html#HRdataset"><i class="fa fa-check"></i><b>27.1</b> Hire or Fire? HR in Call Center</a></li>
</ul></li>
<li class="chapter" data-level="28" data-path="Packages.html"><a href="Packages.html"><i class="fa fa-check"></i><b>28</b> Packages</a><ul>
<li class="chapter" data-level="28.1" data-path="Packages.html"><a href="Packages.html#arguments"><i class="fa fa-check"></i><b>28.1</b> Arguments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="chapter" data-level="29" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html"><i class="fa fa-check"></i><b>29</b> Ceteris-paribus Two-dimensional Profiles - a Tool for Pairwise Interactions</a><ul>
<li class="chapter" data-level="29.1" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dIntro"><i class="fa fa-check"></i><b>29.1</b> Introduction</a></li>
<li class="chapter" data-level="29.2" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dIntuition"><i class="fa fa-check"></i><b>29.2</b> Intuition</a></li>
<li class="chapter" data-level="29.3" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dMethod"><i class="fa fa-check"></i><b>29.3</b> Method</a></li>
<li class="chapter" data-level="29.4" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dExample"><i class="fa fa-check"></i><b>29.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="29.5" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2dProsCons"><i class="fa fa-check"></i><b>29.5</b> Pros and cons</a></li>
<li class="chapter" data-level="29.6" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#ceterisParibus2R"><i class="fa fa-check"></i><b>29.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="30" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html"><i class="fa fa-check"></i><b>30</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="30.1" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#introduction-3"><i class="fa fa-check"></i><b>30.1</b> Introduction</a></li>
<li class="chapter" data-level="30.2" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#intuition-4"><i class="fa fa-check"></i><b>30.2</b> Intuition</a></li>
<li class="chapter" data-level="30.3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#method-4"><i class="fa fa-check"></i><b>30.3</b> Method</a></li>
<li class="chapter" data-level="30.4" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#example-wine-quality"><i class="fa fa-check"></i><b>30.4</b> Example: Wine quality</a></li>
<li class="chapter" data-level="30.5" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#pros-and-cons-4"><i class="fa fa-check"></i><b>30.5</b> Pros and Cons</a></li>
<li class="chapter" data-level="30.6" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#code-snippets-3"><i class="fa fa-check"></i><b>30.6</b> Code snippets</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visual Exploration, Explanation and Debugging</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variableAttributionMethods" class="section level1">
<h1><span class="header-section-number">Chapter 30</span> Variable attribution for linear models</h1>
<div id="introduction-3" class="section level2">
<h2><span class="header-section-number">30.1</span> Introduction</h2>
<p>In this chapter we introduce the concept and the intuitions underlying ‘’variable attribution,’’ i.e., the decomposition of the difference between the single-instance and the average model predictions among the different explanatory variables. We can think about the following examples:</p>
<ul>
<li>Assume that we are interested in predicting the risk of heart attack based on person’s age, sex, and smoking habits. A patient may want to know which factors have the highest impact on the his/her risk score.</li>
<li>Consider a model for prediction of apartment prices. An investor may want to know how much of the predicted price may be attributed to, for instance, the location of an apartment.</li>
<li>Consider a model for credit scoring. A customer may want to know if factors like gender, age, or number of children influence model predictions.</li>
</ul>
<p>In each of those cases we want to attribute a part of the model prediction to a single explanatory variable. This can be done directly for linear models. Hence, in this chapter We focus on those models. The method can be easily extended to generalized linear models. Model-agnostic approaches will be presented in Chapters <a href="breakDown.html#breakDown">9</a> and <a href="shapley.html#shapley">11</a>.</p>
</div>
<div id="intuition-4" class="section level2">
<h2><span class="header-section-number">30.2</span> Intuition</h2>
<p>Assume a classical linear model for response <span class="math inline">\(Y\)</span> with <span class="math inline">\(p\)</span> explanatory variables collected in the vector <span class="math inline">\(X = (X_1, X_2, \ldots, X_p)\)</span> and coefficients <span class="math inline">\(\beta = (\beta_0, \beta_1, .., \beta_p)\)</span>, where <span class="math inline">\(\beta_0\)</span> is the intercept. The prediction for <span class="math inline">\(Y\)</span> at point <span class="math inline">\(X=x=(x_1, x_2, \ldots, x_p)\)</span> is given by the expected value of <span class="math inline">\(Y\)</span> conditional on <span class="math inline">\(X=x\)</span>. For a linear model, the expected value is given by the following linear combination:</p>
<p><span class="math display">\[
E_Y(Y | x) = f(x) = \beta_0 + x_1 \beta_1 + \ldots + x_p \beta_p.
\]</span><br />
We are interested in the contribution of the <span class="math inline">\(i\)</span>-th explanatory variable to model prediction <span class="math inline">\(f(x^*)\)</span> for a single observation described by <span class="math inline">\(x^*\)</span>. In this case, the contribution is equal to <span class="math inline">\(x^*_i\beta_i\)</span>, because the <span class="math inline">\(i\)</span>-th variable occurs only in this term. As it will become clear in the sequel, it is easier to interpret the variable’s contribution if <span class="math inline">\(x_i\)</span> is is centered by subtracting a constant <span class="math inline">\(\hat x_i\)</span> (usually, the mean of <span class="math inline">\(x_i\)</span>). This leads the following, intuitive formula for the variable attribution:
<span class="math display">\[
v(f, x^*, i) = \beta_i (x_i^* - \hat x_i).
\]</span></p>
</div>
<div id="method-4" class="section level2">
<h2><span class="header-section-number">30.3</span> Method</h2>
<p>We want to calculate <span class="math inline">\(v(f, x^*, i)\)</span>, which is the contribution of the <span class="math inline">\(i\)</span>-th explanatory variable to the prediction of model <span class="math inline">\(f()\)</span> at point <span class="math inline">\(x^*\)</span>. Assume that <span class="math inline">\(E_Y(Y | x^*) \approx f(x^*)\)</span>, where <span class="math inline">\(f(x^*)\)</span> is the value of the model at <span class="math inline">\(x^*\)</span>. A possible approach to define <span class="math inline">\(v(f, x^*, i)\)</span> is to measure how much the expected model response changes after conditioning on <span class="math inline">\(x_i^*\)</span>:
<span class="math display">\[
v(f, x^*, i) = E_Y(Y | x^*) - E_{X_i}\{E_Y[Y | (x_1^*,\ldots,x_{i-1}^*,X_i,x_{i+1}^*,x_p^*)]\}\approx f(x^*) - E_{X_i}[f(x_{-i}^*)],
\]</span>
where <span class="math inline">\(x_{-i}^*\)</span> indicates that variable <span class="math inline">\(X_i\)</span> in vector <span class="math inline">\(x_{-i}^*\)</span> is treated as random. For the classical linear model, if the explanatory variables are independent, <span class="math inline">\(v(f, x^*, i)\)</span> can be expressed as follows:
<span class="math display">\[
v(f, x^*, i) = f(x^*) - E_{X_i}[f(x_{-i}^*)] = \beta_0 + x_1^* \beta_1 + \ldots + x_p^* \beta_p - E_{X_i}[\beta_0 + x_1^* \beta_1 + \ldots +\beta_i X_i \ldots + x_p^* \beta_p] = \beta_i[x^*_i - E_{X_i}(X_i)].
\]</span>
In practice, given a dataset, the expected value of <span class="math inline">\(X_i\)</span> can be estimated by the sample mean <span class="math inline">\(\bar x_i\)</span>. This leads to<br />
<span class="math display">\[
v(f, x^*, i) = \beta_i (x^*_i - \bar x_i).
\]</span>
Note that the linear-model-based prediction may be re-expressed in the following way:
<span class="math display">\[
f(x^*) = [\beta_0 + \bar x_1 \beta_1 + ... + \bar x_p \beta_p] + [(x_1^* - \bar x_1) \beta_1 + ... + (x_p^* - \bar x_p) \beta_p] 
\]</span>
<span class="math display">\[
 \equiv [average \ prediction] + \sum_{j=1}^p v(f, x^*, j).
\]</span>
Thus, the contributions of the explanatory variables are the differences between the model prediction for <span class="math inline">\(x^*\)</span> and the average prediction.</p>
<p>** NOTE for careful readers **</p>
<p>Obviously, sample mean <span class="math inline">\(\bar x_i\)</span> is an estimator of the expected value <span class="math inline">\(E_{X_i}(X_i)\)</span>, calculated using a dataset. For the sake of simplicity we do not emphasize these differences in the notation. Also, we ignore the fact that, in practice, we never know the model coefficients and we work with an estimated model.</p>
<p>Also, we assumed that the explanatory variables are independent, which may not be the case. We will return to this problem in Section <a href="iBreakDown.html#iBreakDown">10</a>, when we will discuss interactions.</p>
</div>
<div id="example-wine-quality" class="section level2">
<h2><span class="header-section-number">30.4</span> Example: Wine quality</h2>
<p>Figure <a href="variableAttributionMethods.html#fig:attribution1a">30.1</a> shows the relation between alcohol and wine quality, based on the wine dataset <span class="citation">(Cortez et al. <a href="#ref-wine2009">2009</a>)</span>. The linear model is
<span class="math display">\[
quality(alcohol) = 2.5820 + 0.3135 * alcohol.
\]</span>
The weakest wine in the dataset has 8% of alcohol, while the average alcohol concentration is 10.51%. Thus, the contribution of alcohol to the model prediction for the weakest wine is <span class="math inline">\(0.3135 \cdot (8-10.51) = -0.786885\)</span>. This means that low concentration of alcohol for this wine (8%) decreses the predicted quality by <span class="math inline">\(-0.786885\)</span>.</p>
<p>Note, that it would be misleading to use <span class="math inline">\(x_i^*\beta_i = 0.3135*8 = 2.508\)</span> as the alcohol contribution to the quality. The positive value of the product would not correrspond to the intuition that, in the presence of a positive relation, a smaller alcohol concentration should imply a lower quality of the wine.</p>
<div class="figure" style="text-align: center"><span id="fig:attribution1a"></span>
<img src="figure/attribution_1.png" alt="(fig:attribution1a)Relation between wine quality and concentration of alcohol assessed with linear model" width="50%" />
<p class="caption">
Figure 30.1: (fig:attribution1a)Relation between wine quality and concentration of alcohol assessed with linear model
</p>
</div>
</div>
<div id="pros-and-cons-4" class="section level2">
<h2><span class="header-section-number">30.5</span> Pros and Cons</h2>
<p>The introduced values <span class="math inline">\(v(f, x^*, i)\)</span> do not depend on neither scale nor location of <span class="math inline">\(X_i\)</span>; hence, it is easier to understand than, for instance, the standardized value of <span class="math inline">\(\beta_i\)</span>. For the classical linear model, <span class="math inline">\(v(f, x^*, i)\)</span> is not an approximation and it is directly linked with the structure of a model. An obvious diasadvantage is that the definition of <span class="math inline">\(v(f, x^*, i)\)</span> is very much linear-model based. Also, it does not, in any way, reduce the model complexity; if model has 10 parameters then the prediction is decomposed into 10 numbers. Maybe these numbers are easier to understand, but dimensionality of model description has not changed.</p>
</div>
<div id="code-snippets-3" class="section level2">
<h2><span class="header-section-number">30.6</span> Code snippets</h2>
<p>In this section, we present an example of computing variable attributions using the <code>HR</code> dataset (see Section <a href="DataSets.html#HRdataset">27.1</a> for more details).</p>
<p>To calculate variable attributions for a particular point, first we have got to define this point:</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" data-line-number="1">dilbert &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">gender =</span> <span class="kw">factor</span>(<span class="st">&quot;male&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)),</a>
<a class="sourceLine" id="cb175-2" data-line-number="2">                <span class="dt">age =</span> <span class="fl">57.7</span>,</a>
<a class="sourceLine" id="cb175-3" data-line-number="3">                <span class="dt">hours =</span> <span class="fl">42.3</span>,</a>
<a class="sourceLine" id="cb175-4" data-line-number="4">                <span class="dt">evaluation =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb175-5" data-line-number="5">                <span class="dt">salary =</span> <span class="dv">2</span>)</a></code></pre></div>
<p>Variable attributions for linear and generalized linear models may be directly extracted by applying the <code>predict()</code> function, with the argument <code>type = &quot;terms&quot;</code>, to an object containing results of fitting of a model. To illustrate the approach for logistic regression, we build a logistic regression model for the binary variable <code>status == &quot;fired&quot;</code> and extract the estimated model coefficients:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb176-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb176-2" data-line-number="2">model_fired &lt;-<span class="st"> </span><span class="kw">glm</span>(status <span class="op">==</span><span class="st"> &quot;fired&quot;</span> <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> DALEX<span class="op">::</span>HR, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</a>
<a class="sourceLine" id="cb176-3" data-line-number="3"><span class="kw">coef</span>(model_fired)</a></code></pre></div>
<pre><code>##  (Intercept)   gendermale          age        hours   evaluation 
##  5.737945729 -0.066803609 -0.001503314 -0.102021120 -0.425793369 
##       salary 
## -0.015740080</code></pre>
<p>For the new observation, the predicted value of the logit of the probability of being fired is obtained by applying the <code>predict()</code> function:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb178-1" data-line-number="1"><span class="kw">as.vector</span>(pred.inst &lt;-<span class="st"> </span><span class="kw">predict</span>(model_fired, dilbert)) <span class="co"># new pediction</span></a></code></pre></div>
<pre><code>## [1] 0.3858406</code></pre>
<p>On the other hand, variable attributions can be obtained by applying the <code>predict()</code> function with the <code>type=&quot;terms&quot;</code> argument:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" data-line-number="1">(var.attr &lt;-<span class="st"> </span><span class="kw">predict</span>(model_fired, dilbert, <span class="dt">type =</span> <span class="st">&quot;terms&quot;</span>)) <span class="co"># attributions</span></a></code></pre></div>
<pre><code>##        gender         age     hours evaluation      salary
## 1 -0.03361889 -0.02660691 0.7555555  0.5547197 0.007287334
## attr(,&quot;constant&quot;)
## [1] -0.8714962</code></pre>
<p>The largest contributions to the prediction come from variables ‘’hours’’ and ‘’evaluation.’’ Variables ‘’gender’’ and ‘’age’’ slightly decrease the predicted value. The sum of the attributions is equal to</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" data-line-number="1"><span class="kw">sum</span>(var.attr)</a></code></pre></div>
<pre><code>## [1] 1.257337</code></pre>
<p>The attribute <code>constant</code> of object <code>var.attr</code> provides the ‘’average’’ prediction, i.e., the predicted logit for an obsrvation defined by the means of the explanatory variables, as can be seen from the calculation below:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb184-1" data-line-number="1"><span class="kw">coef</span>(model_fired)<span class="op">%*%</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="kw">mean</span>((HR<span class="op">$</span>gender<span class="op">==</span><span class="st">&quot;male&quot;</span>)), <span class="kw">mean</span>(HR<span class="op">$</span>age), <span class="kw">mean</span>(HR<span class="op">$</span>hours), </a>
<a class="sourceLine" id="cb184-2" data-line-number="2">                      <span class="kw">mean</span>(HR<span class="op">$</span>evaluation), <span class="kw">mean</span>(HR<span class="op">$</span>salary))</a></code></pre></div>
<pre><code>##            [,1]
## [1,] -0.8714962</code></pre>
<p>Adding the ‘’average’’ prediction to the sum of the variable attributions results in the new-observation prediction:</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb186-1" data-line-number="1"><span class="kw">attributes</span>(var.attr)<span class="op">$</span>constant <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(var.attr)</a></code></pre></div>
<pre><code>## [1] 0.3858406</code></pre>
<p>Below we illustrate how to implement this approach with the <code>DALEX</code> package. Toward this end, functions <code>explain()</code> and <code>single_prediction()</code> can be used. Object <code>model_fired</code> stores the definition of the logistic-regression model used earlier in this section. The contents of object <code>attribution</code> correspond to the results obtained by using function <code>predict()</code>.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb188-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb188-2" data-line-number="2"></a>
<a class="sourceLine" id="cb188-3" data-line-number="3">explainer_fired &lt;-<span class="st"> </span><span class="kw">explain</span>(model_fired,</a>
<a class="sourceLine" id="cb188-4" data-line-number="4">                 <span class="dt">data =</span> HR,</a>
<a class="sourceLine" id="cb188-5" data-line-number="5">                 <span class="dt">y =</span> HR<span class="op">$</span>status <span class="op">==</span><span class="st"> &quot;fired&quot;</span>,</a>
<a class="sourceLine" id="cb188-6" data-line-number="6">                 <span class="dt">label =</span> <span class="st">&quot;fired&quot;</span>)</a>
<a class="sourceLine" id="cb188-7" data-line-number="7"></a>
<a class="sourceLine" id="cb188-8" data-line-number="8">(attribution &lt;-<span class="st"> </span><span class="kw">single_prediction</span>(explainer_fired, dilbert))</a></code></pre></div>
<pre><code>##                    variable contribution variable_name variable_value
## 1               (Intercept) -0.871496150     Intercept              1
## hours        + hours = 42.3  0.755555494         hours           42.3
## evaluation + evaluation = 2  0.554719716    evaluation              2
## salary         + salary = 2  0.007287334        salary              2
## age            + age = 57.7 -0.026606908           age           57.7
## gender      + gender = male -0.033618893        gender           male
## 11          final_prognosis  0.385840593                             
##            cummulative sign position label
## 1           -0.8714962   -1        1 fired
## hours       -0.1159407    1        2 fired
## evaluation   0.4387791    1        3 fired
## salary       0.4460664    1        4 fired
## age          0.4194595   -1        5 fired
## gender       0.3858406   -1        6 fired
## 11           0.3858406    X        7 fired</code></pre>
<p>After object <code>attribution</code> has been created, a plot presenting the variable attributions can be easily constructed:</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb190-1" data-line-number="1"><span class="kw">plot</span>(attribution)</a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>

<div id="refs" class="references">
<div>
<p>Allaire, JJ, and François Chollet. 2019. <em>Keras: R Interface to ’Keras’</em>. <a href="https://CRAN.R-project.org/package=keras">https://CRAN.R-project.org/package=keras</a>.</p>
</div>
<div>
<p>Apley, Dan. 2018a. <em>ALEPlot: Accumulated Local Effects (Ale) Plots and Partial Dependence (Pd) Plots</em>. <a href="https://CRAN.R-project.org/package=ALEPlot">https://CRAN.R-project.org/package=ALEPlot</a>.</p>
</div>
<div>
<p>———. 2018b. <em>ALEPlot: Accumulated Local Effects (Ale) Plots and Partial Dependence (Pd) Plots</em>. <a href="https://CRAN.R-project.org/package=ALEPlot">https://CRAN.R-project.org/package=ALEPlot</a>.</p>
</div>
<div>
<p>Bach, Sebastian, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. “On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation.” Edited by Oscar Deniz Suarez. <em>PLOS ONE</em> 10 (7): e0130140. <a href="https://doi.org/10.1371/journal.pone.0130140">https://doi.org/10.1371/journal.pone.0130140</a>.</p>
</div>
<div>
<p>Biecek, Przemyslaw. 2018. <em>DALEX: Descriptive mAchine Learning Explanations</em>. <a href="https://pbiecek.github.io/DALEX/">https://pbiecek.github.io/DALEX/</a>.</p>
</div>
<div>
<p>———. 2019. <em>Ingredients: Effects and Importances of Model Ingredients</em>. <a href="https://ModelOriented.github.io/ingredients/">https://ModelOriented.github.io/ingredients/</a>.</p>
</div>
<div>
<p>Biecek, Przemyslaw, and Marcin Kosinski. 2017. “archivist: An R Package for Managing, Recording and Restoring Data Analysis Results.” <em>Journal of Statistical Software</em> 82 (11): 1–28. <a href="https://doi.org/10.18637/jss.v082.i11">https://doi.org/10.18637/jss.v082.i11</a>.</p>
</div>
<div>
<p>Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2016. “mlr: Machine Learning in R.” <em>Journal of Machine Learning Research</em> 17 (170): 1–5. <a href="http://jmlr.org/papers/v17/15-066.html">http://jmlr.org/papers/v17/15-066.html</a>.</p>
</div>
<div>
<p>Breiman, Leo. 2001. “Random Forests.” In <em>Machine Learning</em>, 45:5–32. <a href="https://doi.org/10.1023/A:1010933404324">https://doi.org/10.1023/A:1010933404324</a>.</p>
</div>
<div>
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div>
<p>Casey, Bryan, Ashkon Farhangi, and Roland Vogl. 2018. “Rethinking Explainable Machines: The Gdpr’s ’Right to Explanation’ Debate and the Rise of Algorithmic Audits in Enterprise.” <em>Berkeley Technology Law Journal</em>. <a href="https://ssrn.com/abstract=3143325">https://ssrn.com/abstract=3143325</a>.</p>
</div>
<div>
<p>Cortez, Paulo, António Cerdeira, Fernando Almeida, Telmo Matos, and José Reis. 2009. “Modeling Wine Preferences by Data Mining from Physicochemical Properties.” <em>Decision Support Systems</em> 47 (4): 547–53. <a href="https://doi.org/10.1016/j.dss.2009.05.016">https://doi.org/10.1016/j.dss.2009.05.016</a>.</p>
</div>
<div>
<p>Dastin, Jeffrey. 2018. “Amazon Scraps Secret Ai Recruiting Tool That Showed Bias Against Women.” <em>Reuters</em>. <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G</a>.</p>
</div>
<div>
<p>Demšar, Jaka, and Zoran Bosnić. 2018. “Detecting Concept Drift in Data Streams Using Model Explanation.” <em>Expert Systems with Applications</em> 92 (February): 546–59. <a href="https://doi.org/10.1016/j.eswa.2017.10.003">https://doi.org/10.1016/j.eswa.2017.10.003</a>.</p>
</div>
<div>
<p>Edwards, Lilian, and Michael Veale. 2018. “Enslaving the Algorithm: From a ‘Right to an Explanation’ to a ‘Right to Better Decisions’?” <em>IEEE Security and Privacy</em> 16 (3): 46–54. <a href="https://doi.org/10.1109/MSP.2018.2701152">https://doi.org/10.1109/MSP.2018.2701152</a>.</p>
</div>
<div>
<p>Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2018. “Model Class Reliance: Variable Importance Measures for Any Machine Learning Model Class, from the ’Rashomon’ Perspective.” <em>Journal of Computational and Graphical Statistics</em>. <a href="http://arxiv.org/abs/1801.01489">http://arxiv.org/abs/1801.01489</a>.</p>
</div>
<div>
<p>Fisher, A., C. Rudin, and F. Dominici. 2018. “Model Class Reliance: Variable Importance Measures for any Machine Learning Model Class, from the ‘Rashomon’ Perspective.” <em>ArXiv E-Prints</em>, January.</p>
</div>
<div>
<p>Foster, David. 2017. <em>XgboostExplainer: An R Package That Makes Xgboost Models Fully Interpretable</em>. <a href="https://github.com/AppliedDataSciencePartners/xgboostExplainer/">https://github.com/AppliedDataSciencePartners/xgboostExplainer/</a>.</p>
</div>
<div>
<p>———. 2018. <em>XgboostExplainer: XGBoost Model Explainer</em>.</p>
</div>
<div>
<p>Friedman, Jerome H. 2000. “Greedy Function Approximation: A Gradient Boosting Machine.” <em>Annals of Statistics</em> 29: 1189–1232.</p>
</div>
<div>
<p>GDPR. 2018. “The Eu General Data Protection Regulation (Gdpr) Is the Most Important Change in Data Privacy Regulation in 20 Years.” <a href="https://eugdpr.org/">https://eugdpr.org/</a>.</p>
</div>
<div>
<p>Goldstein, Alex, Adam Kapelner, and Justin Bleich. 2017. <em>ICEbox: Individual Conditional Expectation Plot Toolbox</em>. <a href="https://CRAN.R-project.org/package=ICEbox">https://CRAN.R-project.org/package=ICEbox</a>.</p>
</div>
<div>
<p>Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015a. “Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation.” <em>Journal of Computational and Graphical Statistics</em> 24 (1): 44–65. <a href="https://doi.org/10.1080/10618600.2014.907095">https://doi.org/10.1080/10618600.2014.907095</a>.</p>
</div>
<div>
<p>———. 2015b. “Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation.” <em>Journal of Computational and Graphical Statistics</em> 24 (1): 44–65. <a href="https://doi.org/10.1080/10618600.2014.907095">https://doi.org/10.1080/10618600.2014.907095</a>.</p>
</div>
<div>
<p>Goodman, Bryce, and Seth Flaxman. 2016. “European Union Regulations on Algorithmic Decision-Making and a &quot;Right to Explanation&quot;.” <em>Arxiv</em>. <a href="https://arxiv.org/abs/1606.08813">https://arxiv.org/abs/1606.08813</a>.</p>
</div>
<div>
<p>Gosiewska, Alicja, and Przemyslaw Biecek. 2018. <em>Auditor: Model Audit - Verification, Validation, and Error Analysis</em>. <a href="https://CRAN.R-project.org/package=auditor">https://CRAN.R-project.org/package=auditor</a>.</p>
</div>
<div>
<p>———. 2019a. “iBreakDown: Uncertainty of Model Explanations for Non-additive Predictive Models.” <a href="https://arxiv.org/abs/1903.11420v1">https://arxiv.org/abs/1903.11420v1</a>.</p>
</div>
<div>
<p>———. 2019b. <em>shapper: Wrapper of Python Library ’shap’</em>. <a href="https://github.com/ModelOriented/shapper">https://github.com/ModelOriented/shapper</a>.</p>
</div>
<div>
<p>Gosiewska, Alicja, Aleksandra Gacek, Piotr Lubon, and Przemyslaw Biecek. 2019. “SAFE Ml: Surrogate Assisted Feature Extraction for Model Learning.” <a href="https://arxiv.org/abs/1902.11035">https://arxiv.org/abs/1902.11035</a>.</p>
</div>
<div>
<p>Greenwell, Brandon M. 2017a. “Pdp: An R Package for Constructing Partial Dependence Plots.” <em>The R Journal</em> 9 (1): 421–36. <a href="https://journal.r-project.org/archive/2017/RJ-2017-016/index.html">https://journal.r-project.org/archive/2017/RJ-2017-016/index.html</a>.</p>
</div>
<div>
<p>———. 2017b. “Pdp: An R Package for Constructing Partial Dependence Plots.” <em>The R Journal</em> 9 (1): 421–36. <a href="https://journal.r-project.org/archive/2017/RJ-2017-016/index.html">https://journal.r-project.org/archive/2017/RJ-2017-016/index.html</a>.</p>
</div>
<div>
<p>———. 2017c. “pdp: An R Package for Constructing Partial Dependence Plots.” <em>The R Journal</em> 9 (1): 421–36. <a href="https://journal.r-project.org/archive/2017/RJ-2017-016/index.html">https://journal.r-project.org/archive/2017/RJ-2017-016/index.html</a>.</p>
</div>
<div>
<p>Harrell Jr, Frank E. 2018. <em>Rms: Regression Modeling Strategies</em>. <a href="https://CRAN.R-project.org/package=rms">https://CRAN.R-project.org/package=rms</a>.</p>
</div>
<div>
<p>Hochreiter, Sepp, and Jürgen Schmidhuber. 1997. “Long Short-Term Memory.” <em>Neural Computation</em> 9 (8): 1735–80. <a href="https://doi.org/10.1162/neco.1997.9.8.1735">https://doi.org/10.1162/neco.1997.9.8.1735</a>.</p>
</div>
<div>
<p>Jed Wing, Max Kuhn. Contributions from, Steve Weston, Andre Williams, Chris Keefer, Allan Engelhardt, Tony Cooper, Zachary Mayer, et al. 2016. <em>Caret: Classification and Regression Training</em>. <a href="https://CRAN.R-project.org/package=caret">https://CRAN.R-project.org/package=caret</a>.</p>
</div>
<div>
<p>Kuhn, Max, and Davis Vaughan. 2019. <em>Parsnip: A Common Api to Modeling and Analysis Functions</em>. <a href="https://CRAN.R-project.org/package=parsnip">https://CRAN.R-project.org/package=parsnip</a>.</p>
</div>
<div>
<p>Larson, Jeff, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. “How We Analyzed the Compas Recidivism Algorithm.” <em>ProPublica</em>. <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm</a>.</p>
</div>
<div>
<p>LeDell, Erin, Navdeep Gill, Spencer Aiello, Anqi Fu, Arno Candel, Cliff Click, Tom Kraljevic, et al. 2019. <em>H2o: R Interface for ’H2o’</em>. <a href="https://CRAN.R-project.org/package=h2o">https://CRAN.R-project.org/package=h2o</a>.</p>
</div>
<div>
<p>Liaw, Andy, and Matthew Wiener. 2002a. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="http://CRAN.R-project.org/doc/Rnews/">http://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div>
<p>———. 2002b. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div>
<p>Lundberg, Scott. 2019. <em>SHAP (SHapley Additive exPlanations)</em>. <a href="https://github.com/slundberg/shap">https://github.com/slundberg/shap</a>.</p>
</div>
<div>
<p>Lundberg, Scott M., Gabriel G. Erion, and Su-In Lee. 2018. “Consistent Individualized Feature Attribution for Tree Ensembles.” <em>CoRR</em> abs/1802.03888. <a href="http://arxiv.org/abs/1802.03888">http://arxiv.org/abs/1802.03888</a>.</p>
</div>
<div>
<p>Lundberg, Scott M, and Su-In Lee. 2017. “A Unified Approach to Interpreting Model Predictions.” In <em>Advances in Neural Information Processing Systems 30</em>, edited by I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, 4765–74. Curran Associates, Inc. <a href="http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf">http://papers.nips.cc/paper/7062-a-unified-approach-to-interpreting-model-predictions.pdf</a>.</p>
</div>
<div>
<p>Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2017. <em>E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), Tu Wien</em>. <a href="https://CRAN.R-project.org/package=e1071">https://CRAN.R-project.org/package=e1071</a>.</p>
</div>
<div>
<p>Molnar, Christoph. 2018. <em>Iml: Interpretable Machine Learning</em>. <a href="https://CRAN.R-project.org/package=iml">https://CRAN.R-project.org/package=iml</a>.</p>
</div>
<div>
<p>Molnar, Christoph, Bernd Bischl, and Giuseppe Casalicchio. 2018a. “Iml: An R Package for Interpretable Machine Learning.” <em>JOSS</em> 3 (26). Journal of Open Source Software: 786. <a href="https://doi.org/10.21105/joss.00786">https://doi.org/10.21105/joss.00786</a>.</p>
</div>
<div>
<p>———. 2018b. “Iml: An R Package for Interpretable Machine Learning.” <em>JOSS</em> 3 (26). Journal of Open Source Software: 786. <a href="https://doi.org/10.21105/joss.00786">https://doi.org/10.21105/joss.00786</a>.</p>
</div>
<div>
<p>O’Connell, Mark, Catherine Hurley, and Katarina Domijan. 2017. “Conditional Visualization for Statistical Models: An Introduction to the Condvis Package in R.” <em>Journal of Statistical Software, Articles</em> 81 (5): 1–20. <a href="https://doi.org/10.18637/jss.v081.i05">https://doi.org/10.18637/jss.v081.i05</a>.</p>
</div>
<div>
<p>O’Neil, Cathy. 2016. <em>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</em>. New York, NY, USA: Crown Publishing Group.</p>
</div>
<div>
<p>Paluszynska, Aleksandra, and Przemyslaw Biecek. 2017a. <em>RandomForestExplainer: A Set of Tools to Understand What Is Happening Inside a Random Forest</em>. <a href="https://github.com/MI2DataLab/randomForestExplainer">https://github.com/MI2DataLab/randomForestExplainer</a>.</p>
</div>
<div>
<p>———. 2017b. <em>RandomForestExplainer: Explaining and Visualizing Random Forests in Terms of Variable Importance</em>. <a href="https://CRAN.R-project.org/package=randomForestExplainer">https://CRAN.R-project.org/package=randomForestExplainer</a>.</p>
</div>
<div>
<p>Pedersen, Thomas Lin, and Michaël Benesty. 2018. <em>Lime: Local Interpretable Model-Agnostic Explanations</em>. <a href="https://CRAN.R-project.org/package=lime">https://CRAN.R-project.org/package=lime</a>.</p>
</div>
<div>
<p>Piltaver, Rok, Mitja Luštrek, Matjaž Gams, and Sanda Martinčić-Ipšić. 2016. “What Makes Classification Trees Comprehensible?” <em>Expert Systems with Applications</em> 62: 333–46. <a href="https://doi.org/https://doi.org/10.1016/j.eswa.2016.06.009">https://doi.org/https://doi.org/10.1016/j.eswa.2016.06.009</a>.</p>
</div>
<div>
<p>Puri, Nikaash, Piyush Gupta, Pratiksha Agarwal, Sukriti Verma, and Balaji Krishnamurthy. 2017. “MAGIX: Model Agnostic Globally Interpretable Explanations.” <em>CoRR</em> abs/1706.07160. <a href="http://arxiv.org/abs/1706.07160">http://arxiv.org/abs/1706.07160</a>.</p>
</div>
<div>
<p>R Core Team. 2018. <em>R: A Language and Environment for Statistical Computing</em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.</p>
</div>
<div>
<p>Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. 2016. “Why Should I Trust You?: Explaining the Predictions of Any Classifier.” In, 1135–44. ACM Press. <a href="https://doi.org/10.1145/2939672.2939778">https://doi.org/10.1145/2939672.2939778</a>.</p>
</div>
<div>
<p>Ridgeway, Greg. 2017. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>.</p>
</div>
<div>
<p>Robnik-Sikonja, Marko. 2018. <em>ExplainPrediction: Explanation of Predictions for Classification and Regression Models</em>. <a href="https://CRAN.R-project.org/package=ExplainPrediction">https://CRAN.R-project.org/package=ExplainPrediction</a>.</p>
</div>
<div>
<p>Robnik-Šikonja, Marco, and Igor Kononenko. 2008. “Explaining Classifications for Individual Instances.” <em>IEEE Transactions on Knowledge and Data Engineering</em> 20 (5): 589–600. <a href="https://doi.org/10.1109/TKDE.2007.190734">https://doi.org/10.1109/TKDE.2007.190734</a>.</p>
</div>
<div>
<p>Ross, Casey, and Ike Swetliz. 2018. “IBM’s Watson Supercomputer Recommended ‘Unsafe and Incorrect’ Cancer Treatments, Internal Documents Show.” <em>Statnews</em>. <a href="https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/">https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/</a>.</p>
</div>
<div>
<p>Ruiz, Javier. 2018. “Machine Learning and the Right to Explanation in Gdpr.” <a href="https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr">https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr</a>.</p>
</div>
<div>
<p>Salzberg, Steven. 2014. “Why Google Flu Is a Failure.” <em>Forbes</em>. <a href="https://www.forbes.com/sites/stevensalzberg/2014/03/23/why-google-flu-is-a-failure/">https://www.forbes.com/sites/stevensalzberg/2014/03/23/why-google-flu-is-a-failure/</a>.</p>
</div>
<div>
<p>Shapley, Lloyd S. 1953. “A Value for N-Person Games.” In <em>Contributions to the Theory of Games Ii</em>, edited by Harold W. Kuhn and Albert W. Tucker, 307–17. Princeton: Princeton University Press.</p>
</div>
<div>
<p>Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. 2013. “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps.” <em>CoRR</em> abs/1312.6034. <a href="http://arxiv.org/abs/1312.6034">http://arxiv.org/abs/1312.6034</a>.</p>
</div>
<div>
<p>Sitko, Agnieszka, Aleksandra Grudziąż, and Przemyslaw Biecek. 2018. <em>FactorMerger: The Merging Path Plot</em>. <a href="https://CRAN.R-project.org/package=factorMerger">https://CRAN.R-project.org/package=factorMerger</a>.</p>
</div>
<div>
<p>Staniak, Mateusz, and Przemysław Biecek. 2018. <em>Live: Local Interpretable (Model-Agnostic) Visual Explanations</em>. <a href="https://CRAN.R-project.org/package=live">https://CRAN.R-project.org/package=live</a>.</p>
</div>
<div>
<p>———. 2019. <em>LocalModel: LIME-Based Explanations with Interpretable Inputs Based on Ceteris Paribus Profiles</em>. <a href="https://github.com/ModelOriented/localModel">https://github.com/ModelOriented/localModel</a>.</p>
</div>
<div>
<p>Strobl, Carolin, Anne-Laure Boulesteix, Thomas Kneib, Thomas Augustin, and Achim Zeileis. 2008. “Conditional Variable Importance for Random Forests.” <em>BMC Bioinformatics</em> 9 (1): 307. <a href="https://doi.org/10.1186/1471-2105-9-307">https://doi.org/10.1186/1471-2105-9-307</a>.</p>
</div>
<div>
<p>Strobl, Carolin, Anne-Laure Boulesteix, Achim Zeileis, and Torsten Hothorn. 2007. “Bias in Random Forest Variable Importance Measures: Illustrations, Sources and a Solution.” <em>BMC Bioinformatics</em> 8 (1): 25. <a href="https://doi.org/10.1186/1471-2105-8-25">https://doi.org/10.1186/1471-2105-8-25</a>.</p>
</div>
<div>
<p>Strumbelj, Erik, and Igor Kononenko. 2010. “An Efficient Explanation of Individual Classifications Using Game Theory.” <em>Journal of Machine Learning Research</em> 11 (March). JMLR.org: 1–18. <a href="http://dl.acm.org/citation.cfm?id=1756006.1756007">http://dl.acm.org/citation.cfm?id=1756006.1756007</a>.</p>
</div>
<div>
<p>Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. 2014. “Sequence to Sequence Learning with Neural Networks.” <em>CoRR</em> abs/1409.3215. <a href="http://arxiv.org/abs/1409.3215">http://arxiv.org/abs/1409.3215</a>.</p>
</div>
<div>
<p>Štrumbelj, Erik, and Igor Kononenko. 2014. “Explaining Prediction Models and Individual Predictions with Feature Contributions.” <em>Knowledge and Information Systems</em> 41 (3): 647–65. <a href="https://doi.org/10.1007/s10115-013-0679-x">https://doi.org/10.1007/s10115-013-0679-x</a>.</p>
</div>
<div>
<p>Tatarynowicz, Magda, Kamil Romaszko, and Mateusz Urbański. 2018. <em>ModelDown: Make Static Html Website for Predictive Models</em>. <a href="https://github.com/MI2DataLab/modelDown">https://github.com/MI2DataLab/modelDown</a>.</p>
</div>
<div>
<p>Tufte, Edward R. 1986. <em>The Visual Display of Quantitative Information</em>. Cheshire, CT, USA: Graphics Press.</p>
</div>
<div>
<p>Venables, W. N., and B. D. Ripley. 2010. <em>Modern Applied Statistics with S</em>. Springer Publishing Company, Incorporated.</p>
</div>
<div>
<p>Xie, Yihui. 2018. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-wine2009">
<p>Cortez, Paulo, António Cerdeira, Fernando Almeida, Telmo Matos, and José Reis. 2009. “Modeling Wine Preferences by Data Mining from Physicochemical Properties.” <em>Decision Support Systems</em> 47 (4): 547–53. <a href="https://doi.org/10.1016/j.dss.2009.05.016">https://doi.org/10.1016/j.dss.2009.05.016</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ceterisParibus2d.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
