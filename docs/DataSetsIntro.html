<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visual Exploration, Explanation and Debugging</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visual Exploration, Explanation and Debugging" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visual Exploration, Explanation and Debugging" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2019-04-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="instance-level-explanation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.1</b> The aim of the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#three-single-laws"><i class="fa fa-check"></i><b>1.2</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#terminology"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#white-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.4</b> White-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#model-visualization-exploration-and-explanation"><i class="fa fa-check"></i><b>1.5</b> Model visualization, exploration, and explanation</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.6</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#code-snippets"><i class="fa fa-check"></i><b>1.7</b> Code snippets</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#the-structure-of-the-book"><i class="fa fa-check"></i><b>1.8</b> The structure of the book</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html"><i class="fa fa-check"></i><b>2</b> Data Sets</a><ul>
<li class="chapter" data-level="2.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>2.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="2.1.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#data-cleaning"><i class="fa fa-check"></i><b>2.1.1</b> Data cleaning</a></li>
<li class="chapter" data-level="2.1.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#data-exploration"><i class="fa fa-check"></i><b>2.1.2</b> Data exploration</a></li>
<li class="chapter" data-level="2.1.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_titanic_lmr"><i class="fa fa-check"></i><b>2.1.3</b> Logistic regression is always a good choice</a></li>
<li class="chapter" data-level="2.1.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_titanic_rf"><i class="fa fa-check"></i><b>2.1.4</b> Random Forest to the rescue</a></li>
<li class="chapter" data-level="2.1.5" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#gradient-boosting-for-interactions"><i class="fa fa-check"></i><b>2.1.5</b> Gradient boosting for interactions</a></li>
<li class="chapter" data-level="2.1.6" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model-predictions"><i class="fa fa-check"></i><b>2.1.6</b> Model predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>2.2</b> Apartment Prices</a><ul>
<li class="chapter" data-level="2.2.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#a-tale-of-two-models"><i class="fa fa-check"></i><b>2.2.1</b> A tale of two models</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#HFDataset"><i class="fa fa-check"></i><b>2.3</b> Hire or Fire</a></li>
<li class="chapter" data-level="2.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ListOfModels"><i class="fa fa-check"></i><b>2.4</b> List of Models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level-explanation.html"><a href="instance-level-explanation.html"><i class="fa fa-check"></i>Instance-level explanation</a></li>
<li class="chapter" data-level="3" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>3</b> Introduction</a></li>
<li class="chapter" data-level="4" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>4</b> Ceteris Paribus Profiles - a tool for What-If analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#intuition"><i class="fa fa-check"></i><b>4.2</b> Intuition</a></li>
<li class="chapter" data-level="4.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#method"><i class="fa fa-check"></i><b>4.3</b> Method</a></li>
<li class="chapter" data-level="4.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons"><i class="fa fa-check"></i><b>4.4</b> Pros and cons</a></li>
<li class="chapter" data-level="4.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html"><i class="fa fa-check"></i><b>5</b> Ceteris paribus oscillations - a tool for What-If analysis</a><ul>
<li class="chapter" data-level="5.1" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#introduction-2"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#intuition-1"><i class="fa fa-check"></i><b>5.2</b> Intuition</a></li>
<li class="chapter" data-level="5.3" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#method-1"><i class="fa fa-check"></i><b>5.3</b> Method</a><ul>
<li class="chapter" data-level="5.3.1" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#oscillations"><i class="fa fa-check"></i><b>5.3.1</b> Profile Oscillations</a></li>
<li class="chapter" data-level="5.3.2" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#ceterisParibus2d"><i class="fa fa-check"></i><b>5.3.2</b> Two-dimensional (2D) Ceteris-paribus Profiles</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#example-local-model-fidelity"><i class="fa fa-check"></i><b>5.4</b> Example: Local Model Fidelity</a></li>
<li class="chapter" data-level="5.5" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#pros-and-cons-1"><i class="fa fa-check"></i><b>5.5</b> Pros and cons</a></li>
<li class="chapter" data-level="5.6" data-path="ceterisParibusA.html"><a href="ceterisParibusA.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>5.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html"><i class="fa fa-check"></i><b>6</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="6.1" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#intuition-2"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#method-2"><i class="fa fa-check"></i><b>6.3</b> Method</a></li>
<li class="chapter" data-level="6.4" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#example-wine-quality"><i class="fa fa-check"></i><b>6.4</b> Example: Wine quality</a></li>
<li class="chapter" data-level="6.5" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#pros-and-cons-2"><i class="fa fa-check"></i><b>6.5</b> Pros and Cons</a></li>
<li class="chapter" data-level="6.6" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#code-snippets-1"><i class="fa fa-check"></i><b>6.6</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>7</b> Variable attributions</a><ul>
<li class="chapter" data-level="7.1" data-path="breakDown.html"><a href="breakDown.html#intuition-3"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="breakDown.html"><a href="breakDown.html#method-3"><i class="fa fa-check"></i><b>7.2</b> Method</a></li>
<li class="chapter" data-level="7.3" data-path="breakDown.html"><a href="breakDown.html#example-hire-or-fire"><i class="fa fa-check"></i><b>7.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="7.4" data-path="breakDown.html"><a href="breakDown.html#pros-and-cons-3"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="breakDown.html"><a href="breakDown.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html"><i class="fa fa-check"></i><b>8</b> Variable attribution with interactions</a><ul>
<li class="chapter" data-level="8.1" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#intuition-4"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#method-4"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#example-hire-or-fire-1"><i class="fa fa-check"></i><b>8.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="8.4" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#break-down-plots"><i class="fa fa-check"></i><b>8.4</b> Break Down Plots</a></li>
<li class="chapter" data-level="8.5" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#pros-and-cons-4"><i class="fa fa-check"></i><b>8.5</b> Pros and cons</a></li>
<li class="chapter" data-level="8.6" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>8.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>9</b> Average variable attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="shapley.html"><a href="shapley.html#intuition-5"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="shapley.html"><a href="shapley.html#method-5"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="shapley.html"><a href="shapley.html#example-hire-or-fire-2"><i class="fa fa-check"></i><b>9.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="9.4" data-path="shapley.html"><a href="shapley.html#pros-and-cons-5"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="shapley.html"><a href="shapley.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>10</b> Local approximations with white-box model</a><ul>
<li class="chapter" data-level="10.1" data-path="LIME.html"><a href="LIME.html#intuition-6"><i class="fa fa-check"></i><b>10.1</b> Intuition</a></li>
<li class="chapter" data-level="10.2" data-path="LIME.html"><a href="LIME.html#method-6"><i class="fa fa-check"></i><b>10.2</b> Method</a></li>
<li class="chapter" data-level="10.3" data-path="LIME.html"><a href="LIME.html#example-hire-or-fire-3"><i class="fa fa-check"></i><b>10.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="10.4" data-path="LIME.html"><a href="LIME.html#pros-and-cons-6"><i class="fa fa-check"></i><b>10.4</b> Pros and cons</a></li>
<li class="chapter" data-level="10.5" data-path="LIME.html"><a href="LIME.html#code-snippets-for-r-5"><i class="fa fa-check"></i><b>10.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="10.5.1" data-path="LIME.html"><a href="LIME.html#the-lime-pacakge"><i class="fa fa-check"></i><b>10.5.1</b> <strong>The lime pacakge</strong></a></li>
<li class="chapter" data-level="10.5.2" data-path="LIME.html"><a href="LIME.html#the-live-package"><i class="fa fa-check"></i><b>10.5.2</b> <strong>The live package</strong></a></li>
<li class="chapter" data-level="10.5.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>10.5.3</b> <strong>The iml package</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html"><i class="fa fa-check"></i><b>11</b> Comparision of prediction level explainers</a><ul>
<li class="chapter" data-level="11.1" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html#when-to-use"><i class="fa fa-check"></i><b>11.1</b> When to use?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="12" data-path="introduction-4.html"><a href="introduction-4.html"><i class="fa fa-check"></i><b>12</b> Introduction</a><ul>
<li class="chapter" data-level="12.1" data-path="introduction-4.html"><a href="introduction-4.html#approaches-to-model-explanations"><i class="fa fa-check"></i><b>12.1</b> Approaches to model explanations</a></li>
<li class="chapter" data-level="12.2" data-path="introduction-4.html"><a href="introduction-4.html#a-bit-of-philosophy-three-laws-for-model-level-explanations"><i class="fa fa-check"></i><b>12.2</b> A bit of philosophy: Three Laws for Model Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="variableImportance.html"><a href="variableImportance.html"><i class="fa fa-check"></i><b>13</b> Feature Importance</a><ul>
<li class="chapter" data-level="13.1" data-path="variableImportance.html"><a href="variableImportance.html#permutation-based-feature-importance"><i class="fa fa-check"></i><b>13.1</b> Permutation Based Feature Importance</a></li>
<li class="chapter" data-level="13.2" data-path="variableImportance.html"><a href="variableImportance.html#example-titanic"><i class="fa fa-check"></i><b>13.2</b> Example: Titanic</a></li>
<li class="chapter" data-level="13.3" data-path="variableImportance.html"><a href="variableImportance.html#example-price-prediction"><i class="fa fa-check"></i><b>13.3</b> Example: Price prediction</a></li>
<li class="chapter" data-level="13.4" data-path="variableImportance.html"><a href="variableImportance.html#more-models"><i class="fa fa-check"></i><b>13.4</b> More models</a></li>
<li class="chapter" data-level="13.5" data-path="variableImportance.html"><a href="variableImportance.html#level-frequency"><i class="fa fa-check"></i><b>13.5</b> Level frequency</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="variableEngeneering.html"><a href="variableEngeneering.html"><i class="fa fa-check"></i><b>14</b> Feature effects</a><ul>
<li class="chapter" data-level="14.1" data-path="variableEngeneering.html"><a href="variableEngeneering.html#global-level-vs-instance-level-explanations"><i class="fa fa-check"></i><b>14.1</b> Global level vs instance level explanations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>15</b> Partial Dependency Profiles</a><ul>
<li class="chapter" data-level="15.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#definition"><i class="fa fa-check"></i><b>15.1</b> Definition</a></li>
<li class="chapter" data-level="15.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#estimation"><i class="fa fa-check"></i><b>15.2</b> Estimation</a></li>
<li class="chapter" data-level="15.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles"><i class="fa fa-check"></i><b>15.3</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="15.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles"><i class="fa fa-check"></i><b>15.4</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="15.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-model-comparisons"><i class="fa fa-check"></i><b>15.5</b> Contrastive Model Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html"><i class="fa fa-check"></i><b>16</b> Conditional Dependency Profiles</a><ul>
<li class="chapter" data-level="16.1" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#definition-1"><i class="fa fa-check"></i><b>16.1</b> Definition</a></li>
<li class="chapter" data-level="16.2" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#estimation-1"><i class="fa fa-check"></i><b>16.2</b> Estimation</a></li>
<li class="chapter" data-level="16.3" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#example"><i class="fa fa-check"></i><b>16.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>17</b> Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="17.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#definition-2"><i class="fa fa-check"></i><b>17.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="how-pd-cd-and-al-profiles-are-different-and-which-to-choose.html"><a href="how-pd-cd-and-al-profiles-are-different-and-which-to-choose.html"><i class="fa fa-check"></i><b>18</b> How PD, CD and AL Profiles are different and which to choose</a></li>
<li class="chapter" data-level="19" data-path="factorMerger.html"><a href="factorMerger.html"><i class="fa fa-check"></i><b>19</b> Merging Path Plots and Others</a></li>
<li class="chapter" data-level="20" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>20</b> Other topics</a></li>
<li class="chapter" data-level="21" data-path="modelComparisons.html"><a href="modelComparisons.html"><i class="fa fa-check"></i><b>21</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="22" data-path="modelAuditing.html"><a href="modelAuditing.html"><i class="fa fa-check"></i><b>22</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="23" data-path="concept-drift.html"><a href="concept-drift.html"><i class="fa fa-check"></i><b>23</b> Concept Drift</a><ul>
<li class="chapter" data-level="23.1" data-path="concept-drift.html"><a href="concept-drift.html#introduction-5"><i class="fa fa-check"></i><b>23.1</b> Introduction</a></li>
<li class="chapter" data-level="23.2" data-path="concept-drift.html"><a href="concept-drift.html#covariate-drift"><i class="fa fa-check"></i><b>23.2</b> Covariate Drift</a></li>
<li class="chapter" data-level="23.3" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-2"><i class="fa fa-check"></i><b>23.3</b> Code snippets</a></li>
<li class="chapter" data-level="23.4" data-path="concept-drift.html"><a href="concept-drift.html#residual-drift"><i class="fa fa-check"></i><b>23.4</b> Residual Drift</a></li>
<li class="chapter" data-level="23.5" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-3"><i class="fa fa-check"></i><b>23.5</b> Code snippets</a></li>
<li class="chapter" data-level="23.6" data-path="concept-drift.html"><a href="concept-drift.html#model-drift"><i class="fa fa-check"></i><b>23.6</b> Model Drift</a></li>
<li class="chapter" data-level="23.7" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-4"><i class="fa fa-check"></i><b>23.7</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="24" data-path="DataSets.html"><a href="DataSets.html"><i class="fa fa-check"></i><b>24</b> Data Sets</a><ul>
<li class="chapter" data-level="24.1" data-path="DataSets.html"><a href="DataSets.html#HRdataset"><i class="fa fa-check"></i><b>24.1</b> Hire or Fire? HR in Call Center</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="Packages.html"><a href="Packages.html"><i class="fa fa-check"></i><b>25</b> Packages</a><ul>
<li class="chapter" data-level="25.1" data-path="Packages.html"><a href="Packages.html#arguments"><i class="fa fa-check"></i><b>25.1</b> Arguments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visual Exploration, Explanation and Debugging</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="DataSetsIntro" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Data Sets</h1>
<p>We illustrate techniques introduced in this book on three datasets:</p>
<ul>
<li><em>Sinking of the RMS Titanic</em> as an example of binary classification</li>
<li><em>Apartment prices</em> as an example of regression model</li>
<li><em>Hire or Fire</em> as an example of multi-class classification and interactions</li>
</ul>
<div id="TitanicDataset" class="section level2">
<h2><span class="header-section-number">2.1</span> Sinking of the RMS Titanic</h2>
<div class="figure">
<img src="figure/Titanic.jpg" alt="Titanic sinking by Willy Stöwer" />
<p class="caption">Titanic sinking by Willy Stöwer</p>
</div>
<p>Sinking of the RMS Titanic is one of the deadliest maritime disasters in history (during peacetime). Over 1500 people died as a consequence of collision with an iceberg. Thanks to projects like <em>Encyclopedia titanica</em> <code>https://www.encyclopedia-titanica.org/</code> we have a very rich and precise data about passengers. This dataset is available in the <code>stablelearner</code> package. After some variable transformation it is also avaliable in the <code>DALEX</code> package.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">head</span>(titanic, <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##   gender age class    embarked       country  fare sibsp parch survived
## 1   male  42   3rd Southampton United States  7.11     0     0       no
## 2   male  13   3rd Southampton United States 20.05     0     2       no</code></pre>
<div id="data-cleaning" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Data cleaning</h3>
<p>Feature of interest is the binary variable <code>survived</code>. Let’s build some predictive models for this variable.</p>
<p>First we need to do some data preprocessing. Columns with missing data are filled up</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># missing country is replaced by &quot;X&quot;</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">titanic<span class="op">$</span>country[<span class="kw">is.na</span>(titanic<span class="op">$</span>country)] =<span class="st"> &quot;X&quot;</span></a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="co"># missing age is replaced by average (30)</span></a>
<a class="sourceLine" id="cb3-4" data-line-number="4">titanic<span class="op">$</span>age[<span class="kw">is.na</span>(titanic<span class="op">$</span>age)] =<span class="st"> </span><span class="dv">30</span></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co"># missing fare, sibsp, parch are replaced by 0</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6">titanic<span class="op">$</span>fare[<span class="kw">is.na</span>(titanic<span class="op">$</span>fare)] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">titanic<span class="op">$</span>sibsp[<span class="kw">is.na</span>(titanic<span class="op">$</span>sibsp)] =<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb3-8" data-line-number="8">titanic<span class="op">$</span>parch[<span class="kw">is.na</span>(titanic<span class="op">$</span>parch)] =<span class="st"> </span><span class="dv">0</span></a></code></pre></div>
</div>
<div id="data-exploration" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Data exploration</h3>
<p>It is always a good idea to do data exploration before modelling. But since this book is focused on model exploration we will spend only a few lines on data exploration part. And we will limit ourselves to two-variable summaries for each variable.</p>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-3-1.png" width="576" /><img src="PM_VEE_files/figure-html/unnamed-chunk-3-2.png" width="576" /><img src="PM_VEE_files/figure-html/unnamed-chunk-3-3.png" width="576" /><img src="PM_VEE_files/figure-html/unnamed-chunk-3-4.png" width="576" /><img src="PM_VEE_files/figure-html/unnamed-chunk-3-5.png" width="576" /><img src="PM_VEE_files/figure-html/unnamed-chunk-3-6.png" width="576" /></p>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-4-1.png" width="576" /></p>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-5-1.png" width="576" /></p>
</div>
<div id="model_titanic_lmr" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Logistic regression is always a good choice</h3>
<p>The feature of interest <code>survival</code> is binary, thus a natural choice is a logistic regression. Most of predictive features are categorical except age.</p>
<p>There is no reason to expect a linear relation between age and odds of survival, thus for age we will use linear tail-restricted cubic splines available in the <code>rcs()</code> function in the <code>rms</code> package <span class="citation">(Harrell Jr <a href="#ref-rms">2018</a>)</span>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;rms&quot;</span>)</a>
<a class="sourceLine" id="cb4-2" data-line-number="2">titanic_lmr_v6 &lt;-<span class="st"> </span><span class="kw">lrm</span>(survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span> <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span><span class="kw">rcs</span>(age) <span class="op">+</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>sibsp <span class="op">+</span></a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="st">                   </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, titanic)</a>
<a class="sourceLine" id="cb4-4" data-line-number="4">titanic_lmr_v6</a></code></pre></div>
<pre><code>## Logistic Regression Model
##  
##  lrm(formula = survived == &quot;yes&quot; ~ gender + rcs(age) + class + 
##      sibsp + parch + fare + embarked, data = titanic)
##  
##                         Model Likelihood     Discrimination    Rank Discrim.    
##                            Ratio Test           Indexes           Indexes       
##  Obs           2207    LR chi2     752.73    R2       0.404    C       0.817    
##   FALSE        1496    d.f.            17    g        1.648    Dxy     0.635    
##   TRUE          711    Pr(&gt; chi2) &lt;0.0001    gr       5.195    gamma   0.636    
##  max |deriv| 0.0001                          gp       0.282    tau-a   0.277    
##                                              Brier    0.146                     
##  
##                         Coef    S.E.   Wald Z Pr(&gt;|Z|)
##  Intercept               4.5458 0.5460   8.33 &lt;0.0001 
##  gender=male            -2.7658 0.1587 -17.43 &lt;0.0001 
##  age                    -0.1186 0.0221  -5.37 &lt;0.0001 
##  age&#39;                    0.6339 0.1629   3.89 &lt;0.0001 
##  age&#39;&#39;                  -2.6621 0.7841  -3.39 0.0007  
##  age&#39;&#39;&#39;                  2.8936 1.0131   2.86 0.0043  
##  class=2nd              -1.1029 0.2486  -4.44 &lt;0.0001 
##  class=3rd              -2.0185 0.2466  -8.18 &lt;0.0001 
##  class=deck crew         1.1067 0.3468   3.19 0.0014  
##  class=engineering crew -0.9287 0.2615  -3.55 0.0004  
##  class=restaurant staff -3.1278 0.6571  -4.76 &lt;0.0001 
##  class=victualling crew -1.0473 0.2558  -4.09 &lt;0.0001 
##  sibsp                  -0.4574 0.1012  -4.52 &lt;0.0001 
##  parch                  -0.0970 0.0992  -0.98 0.3282  
##  fare                    0.0021 0.0020   1.05 0.2928  
##  embarked=Cherbourg      0.7725 0.2844   2.72 0.0066  
##  embarked=Queenstown     0.2653 0.3411   0.78 0.4368  
##  embarked=Southampton    0.2287 0.2119   1.08 0.2805  
## </code></pre>
</div>
<div id="model_titanic_rf" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Random Forest to the rescue</h3>
<p>In addition to a logistic regression we will use a random forest model with default settings. Random forest is known for good performance, is able to grasp low-level variable interactions and is quite stable.</p>
<p>Here we are using the <code>randomForest</code> package <span class="citation">(Liaw and Wiener <a href="#ref-randomForestRNews">2002</a>)</span>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">titanic_rf_v6 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(survived <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sibsp <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="st">                           </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, </a>
<a class="sourceLine" id="cb6-4" data-line-number="4">                           <span class="dt">data =</span> titanic)</a>
<a class="sourceLine" id="cb6-5" data-line-number="5">titanic_rf_v6</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = survived ~ class + gender + age + sibsp +      parch + fare + embarked, data = titanic) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 18.58%
## Confusion matrix:
##       no yes class.error
## no  1396 100  0.06684492
## yes  310 401  0.43600563</code></pre>
<p>And a smaller model</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">titanic_rf_v3 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(survived <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age, </a>
<a class="sourceLine" id="cb8-2" data-line-number="2">                           <span class="dt">data =</span> titanic)</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">titanic_rf_v3</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = survived ~ class + gender + age, data = titanic) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##         OOB estimate of  error rate: 20.71%
## Confusion matrix:
##       no yes class.error
## no  1353 143  0.09558824
## yes  314 397  0.44163150</code></pre>
</div>
<div id="gradient-boosting-for-interactions" class="section level3">
<h3><span class="header-section-number">2.1.5</span> Gradient boosting for interactions</h3>
<p>Last model that we will train on this dataset is the gradient boosting model. This family of models is known for being able to grasp deep interactions between variables.</p>
<p>Here we are using the implementation from the <code>gbm</code> package <span class="citation">(Ridgeway <a href="#ref-gbm">2017</a>)</span>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;gbm&quot;</span>)</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">titanic_gbm_v6 &lt;-<span class="st"> </span><span class="kw">gbm</span>(survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span> <span class="op">~</span><span class="st"> </span>class <span class="op">+</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>sibsp <span class="op">+</span></a>
<a class="sourceLine" id="cb10-3" data-line-number="3"><span class="st">                     </span>parch <span class="op">+</span><span class="st"> </span>fare <span class="op">+</span><span class="st"> </span>embarked, <span class="dt">data =</span> titanic, <span class="dt">n.trees =</span> <span class="dv">15000</span>)</a></code></pre></div>
<pre><code>## Distribution not specified, assuming bernoulli ...</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">titanic_gbm_v6</a></code></pre></div>
<pre><code>## gbm(formula = survived == &quot;yes&quot; ~ class + gender + age + sibsp + 
##     parch + fare + embarked, data = titanic, n.trees = 15000)
## A gradient boosted model with bernoulli loss function.
## 15000 iterations were performed.
## There were 7 predictors of which 7 had non-zero influence.</code></pre>
</div>
<div id="model-predictions" class="section level3">
<h3><span class="header-section-number">2.1.6</span> Model predictions</h3>
<p>Having all three models let’s see what are odds of surviving for a 2-years old boy that travels in the 3rd class with 1 parent and 3 siblings.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">henry &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</a>
<a class="sourceLine" id="cb14-2" data-line-number="2">            <span class="dt">class =</span> <span class="kw">factor</span>(<span class="st">&quot;2nd&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;1st&quot;</span>, <span class="st">&quot;2nd&quot;</span>, <span class="st">&quot;3rd&quot;</span>, <span class="st">&quot;deck crew&quot;</span>, <span class="st">&quot;engineering crew&quot;</span>, <span class="st">&quot;restaurant staff&quot;</span>, <span class="st">&quot;victualling crew&quot;</span>)),</a>
<a class="sourceLine" id="cb14-3" data-line-number="3">            <span class="dt">gender =</span> <span class="kw">factor</span>(<span class="st">&quot;male&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;female&quot;</span>, <span class="st">&quot;male&quot;</span>)),</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">            <span class="dt">age =</span> <span class="dv">8</span>,</a>
<a class="sourceLine" id="cb14-5" data-line-number="5">            <span class="dt">sibsp =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb14-6" data-line-number="6">            <span class="dt">parch =</span> <span class="dv">0</span>,</a>
<a class="sourceLine" id="cb14-7" data-line-number="7">            <span class="dt">fare =</span> <span class="dv">72</span>,</a>
<a class="sourceLine" id="cb14-8" data-line-number="8">            <span class="dt">embarked =</span> <span class="kw">factor</span>(<span class="st">&quot;Belfast&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;Belfast&quot;</span>,<span class="st">&quot;Cherbourg&quot;</span>,<span class="st">&quot;Queenstown&quot;</span>,<span class="st">&quot;Southampton&quot;</span>))</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">)</a></code></pre></div>
<p>Logistic regression model says 47% for survival.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw">predict</span>(titanic_lmr_v6, henry, <span class="dt">type =</span> <span class="st">&quot;fitted&quot;</span>)</a></code></pre></div>
<pre><code>##         1 
## 0.4702145</code></pre>
<p>Random forest model says 39% for survival.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1"><span class="kw">predict</span>(titanic_rf_v6, henry, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)</a></code></pre></div>
<pre><code>##      no   yes
## 1 0.656 0.344
## attr(,&quot;class&quot;)
## [1] &quot;matrix&quot; &quot;votes&quot;</code></pre>
<p>Gradient boosting model says 43.6% for survival.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="kw">predict</span>(titanic_gbm_v6, henry, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>, <span class="dt">n.trees =</span> <span class="dv">15000</span>)</a></code></pre></div>
<pre><code>## [1] 0.4322263</code></pre>
<p>Three different opinions. Which one should we trust?
Tools introduced in following sections will help to understand how these models are different.</p>
</div>
</div>
<div id="ApartmentDataset" class="section level2">
<h2><span class="header-section-number">2.2</span> Apartment Prices</h2>
<div class="figure">
<img src="figure/am1974_flicker.jpg" alt="Warsaw skyscrapers by Artur Malinowski Flicker" />
<p class="caption">Warsaw skyscrapers by Artur Malinowski Flicker</p>
</div>
<p>Predicting house prices is a common regression problem for machine learning. Various datasets for house prices are available at websites like Kaggle or UCI Machine Learning Repository.</p>
<p>In this book we will work with a very interesting version of this problem. The <code>apartments</code> dataset is an artificial dataset created to match key characteristics of real apartments in Warsaw. But the dataset is created in a way that two very different models, namely linear regression and random forest, have almost exactly the same accuracy.</p>
<p>Which one we should chose? Based on this dataset we show that visual explainers give a better understanding of key model characteristics and are very helpful in the model selection.</p>
<p>The dataset is available in the <code>DALEX</code> package <span class="citation">(Biecek <a href="#ref-R-DALEX">2018</a><a href="#ref-R-DALEX">b</a>)</span>. Each row corresponds to a single apartment. Features like surface, number of rooms, district or floor are used as predictive features. The problem here is to predict price per a square meter for an apartment, so it’s a regression problem with continuous target.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="kw">head</span>(apartments, <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##   m2.price construction.year surface floor no.rooms    district
## 1     5897              1953      25     3        1 Srodmiescie
## 2     1818              1992     143     9        5     Bielany</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="kw">head</span>(apartments_test, <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##      m2.price construction.year surface floor no.rooms    district
## 1001     4644              1976     131     3        5 Srodmiescie
## 1002     3082              1978     112     9        4     Mokotow</code></pre>
<div id="a-tale-of-two-models" class="section level3">
<h3><span class="header-section-number">2.2.1</span> A tale of two models</h3>
<p>Feature of interest is the variable <code>m2.price</code>, it’s a price (EUR) for a square meter of an apartment.</p>
<p>Let’s build two predictive models for this variable.</p>
<p>For the champion we will use a linear model. Easy to train, easy to test, easy to understand.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb25-1" data-line-number="1">apartments_lm_v5 &lt;-<span class="st"> </span><span class="kw">lm</span>(m2.price <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> apartments)</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">predicted_apartments_lm &lt;-<span class="st"> </span><span class="kw">predict</span>(apartments_lm_v5, apartments_test)</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">rmsd_lm &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((predicted_apartments_lm <span class="op">-</span><span class="st"> </span>apartments_test<span class="op">$</span>m2.price)<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">rmsd_lm</a></code></pre></div>
<pre><code>## [1] 283.0865</code></pre>
<p>The root mean square difference for linear model calculated on test data is 283.1.</p>
<p>Now, let’s train a challenger - a random forest model from <code>randomForest</code> package <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span>. Elastic, popular, able to handle non linear relations.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb27-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb27-2" data-line-number="2"><span class="kw">set.seed</span>(<span class="dv">72</span>)</a>
<a class="sourceLine" id="cb27-3" data-line-number="3">apartments_rf_v5 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(m2.price <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> apartments)</a>
<a class="sourceLine" id="cb27-4" data-line-number="4">predicted_apartments_rf &lt;-<span class="st"> </span><span class="kw">predict</span>(apartments_rf_v5, apartments_test)</a>
<a class="sourceLine" id="cb27-5" data-line-number="5">rmsd_rf &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">mean</span>((predicted_apartments_rf <span class="op">-</span><span class="st"> </span>apartments_test<span class="op">$</span>m2.price)<span class="op">^</span><span class="dv">2</span>))</a>
<a class="sourceLine" id="cb27-6" data-line-number="6">rmsd_rf</a></code></pre></div>
<pre><code>## [1] 282.9519</code></pre>
<p>The root mean square difference for random forest is 283.</p>
<p>The challenger is better in terms of RMSD, but the difference between accuracies is smaller than 10 cents. Shall we choose the model complex but elastic model or the linear model?</p>
</div>
</div>
<div id="HFDataset" class="section level2">
<h2><span class="header-section-number">2.3</span> Hire or Fire</h2>
<p>In this chapter we present an artificial dataset from Human Resources department in a Call Center.</p>
<p>The dataset is available in the <code>DALEX</code> package <span class="citation">(Biecek <a href="#ref-R-DALEX">2018</a><a href="#ref-R-DALEX">b</a>)</span>. Each row corresponds to a single employee in a call center. Features like gender, age, average number of working hours per week, grade from the last evaluation and level of salary are used as predictive features.</p>
<p>The goal here is to first build a model, that will guess when to fire and when to promote an employer, so it’s a classification problem with three classes.</p>
<p>Why we need such model? We want to have objective decisions. That will not be subject to personal preferences of a manager. But is it possible to have an objective model? Would it be fair or it will just replicate some unfairness?</p>
<p>We will use this example to show how to use prediction level explainers to better understand how the model works for selected cases.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb29-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb29-2" data-line-number="2"><span class="kw">head</span>(HR)</a></code></pre></div>
<pre><code>##   gender      age    hours evaluation salary   status
## 1   male 32.58267 41.88626          3      1    fired
## 2 female 41.21104 36.34339          2      5    fired
## 3   male 37.70516 36.81718          3      0    fired
## 4 female 30.06051 38.96032          3      2    fired
## 5   male 21.10283 62.15464          5      3 promoted
## 6   male 40.11812 69.53973          2      0    fired</code></pre>
<p>In this book we are focused on model exploration rather than model building, thus for sake ok simplicity we will use two default models created with random forest <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span> and generalized linear model <span class="citation">(Ripley <a href="#ref-R-nnet">2016</a>)</span>.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb31-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">59</span>)</a>
<a class="sourceLine" id="cb31-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb31-3" data-line-number="3">HR_rf_v5 &lt;-<span class="st"> </span><span class="kw">randomForest</span>(status <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hours <span class="op">+</span><span class="st"> </span>evaluation <span class="op">+</span><span class="st"> </span>salary, <span class="dt">data =</span> HR)</a>
<a class="sourceLine" id="cb31-4" data-line-number="4"></a>
<a class="sourceLine" id="cb31-5" data-line-number="5"><span class="kw">library</span>(<span class="st">&quot;nnet&quot;</span>)</a>
<a class="sourceLine" id="cb31-6" data-line-number="6">HR_glm_v5 &lt;-<span class="st"> </span><span class="kw">multinom</span>(status <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hours <span class="op">+</span><span class="st"> </span>evaluation <span class="op">+</span><span class="st"> </span>salary, <span class="dt">data =</span> HR)</a></code></pre></div>
<pre><code>## # weights:  21 (12 variable)
## initial  value 8620.810629 
## iter  10 value 7002.127738
## iter  20 value 6239.478146
## iter  20 value 6239.478126
## iter  20 value 6239.478124
## final  value 6239.478124 
## converged</code></pre>
</div>
<div id="ListOfModels" class="section level2">
<h2><span class="header-section-number">2.4</span> List of Models</h2>
<p>In previous sections we build a collection of predictive models for dataset about Sinking of RMS Titanic, apartment prices and Human Resources data. These models will be used in next chapters.</p>
<p>The table below summarizes all these models. You can download the binary object with the attached archivist hooks <span class="citation">(Biecek and Kosinski <a href="#ref-archivist">2017</a>)</span>.</p>
<table>
<colgroup>
<col width="23%" />
<col width="28%" />
<col width="16%" />
<col width="20%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th>Model name</th>
<th>Model generator</th>
<th>Dataset</th>
<th>Variables</th>
<th>Link to the model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>titanic_lmr_v6</code></td>
<td><code>rms:: lmr</code></td>
<td><code>DALEX:: titanic</code></td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td><code>archivist:: aread(&quot;pbiecek/models/f285c&quot;)</code></td>
</tr>
<tr class="even">
<td><code>titanic_rf_v6</code></td>
<td><code>randomForest:: randomForest</code></td>
<td><code>DALEX:: titanic</code></td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td><code>archivist:: aread(&quot;pbiecek/models/92753&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>titanic_rf_v3</code></td>
<td><code>randomForest:: randomForest</code></td>
<td><code>DALEX:: titanic</code></td>
<td>gender, age, class</td>
<td><code>archivist:: aread(&quot;pbiecek/models/bcd20&quot;)</code></td>
</tr>
<tr class="even">
<td><code>titanic_gbm_v6</code></td>
<td><code>gbm:: gbm</code></td>
<td><code>DALEX:: titanic</code></td>
<td>gender, age, class, sibsp, parch, fare, embarked</td>
<td><code>archivist:: aread(&quot;pbiecek/models/2bdad&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>apartments_lm_v5</code></td>
<td><code>stats:: lm</code></td>
<td><code>DALEX:: apartments</code></td>
<td>construction .year, surface, floor, no.rooms, district</td>
<td><code>archivist:: aread(&quot;pbiecek/models/55f19&quot;)</code></td>
</tr>
<tr class="even">
<td><code>apartments_rf_v5</code></td>
<td><code>randomForest:: randomForest</code></td>
<td><code>DALEX:: apartments</code></td>
<td>construction .year, surface, floor, no.rooms, district</td>
<td><code>archivist:: aread(&quot;pbiecek/models/fe7a5&quot;)</code></td>
</tr>
<tr class="odd">
<td><code>HR_rf_v5</code></td>
<td><code>randomForest:: randomForest</code></td>
<td><code>DALEX:: HR</code></td>
<td>gender, age, hours, evaluation, salary</td>
<td><code>archivist:: aread(&quot;pbiecek/models/1ecfd&quot;)</code></td>
</tr>
<tr class="even">
<td><code>HR_glm_v5</code></td>
<td><code>stats:: glm</code></td>
<td><code>DALEX:: HR</code></td>
<td>gender, age, hours, evaluation, salary</td>
<td><code>archivist:: aread(&quot;pbiecek/models/f0244&quot;)</code></td>
</tr>
</tbody>
</table>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-rms">
<p>Harrell Jr, Frank E. 2018. <em>Rms: Regression Modeling Strategies</em>. <a href="https://CRAN.R-project.org/package=rms">https://CRAN.R-project.org/package=rms</a>.</p>
</div>
<div id="ref-randomForestRNews">
<p>Liaw, Andy, and Matthew Wiener. 2002. “Classification and Regression by randomForest.” <em>R News</em> 2 (3): 18–22. <a href="https://CRAN.R-project.org/doc/Rnews/">https://CRAN.R-project.org/doc/Rnews/</a>.</p>
</div>
<div id="ref-gbm">
<p>Ridgeway, Greg. 2017. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="https://CRAN.R-project.org/package=gbm">https://CRAN.R-project.org/package=gbm</a>.</p>
</div>
<div id="ref-R-DALEX">
<p>Biecek, Przemyslaw. 2018b. <em>DALEX: Descriptive mAchine Learning Explanations</em>. <a href="https://pbiecek.github.io/DALEX/">https://pbiecek.github.io/DALEX/</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-R-nnet">
<p>Ripley, Brian. 2016. <em>Nnet: Feed-Forward Neural Networks and Multinomial Log-Linear Models</em>. <a href="https://CRAN.R-project.org/package=nnet">https://CRAN.R-project.org/package=nnet</a>.</p>
</div>
<div id="ref-archivist">
<p>Biecek, Przemyslaw, and Marcin Kosinski. 2017. “archivist: An R Package for Managing, Recording and Restoring Data Analysis Results.” <em>Journal of Statistical Software</em> 82 (11): 1–28. <a href="https://doi.org/10.18637/jss.v082.i11">https://doi.org/10.18637/jss.v082.i11</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="instance-level-explanation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
