<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visualisation, Exploration and Explanation</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2018-09-17">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="PredictionExplainers.html">
<link rel="next" href="shapley.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#model-lifecycle"><i class="fa fa-check"></i><b>1.1</b> Model Lifecycle</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#why-do-we-need-model-explainers"><i class="fa fa-check"></i><b>1.2</b> Why do we need model explainers?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#black-box-models-vs-white-box-models"><i class="fa fa-check"></i><b>1.3</b> Black-box models vs White-box models</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#model-agnostic-vs-model-specific"><i class="fa fa-check"></i><b>1.4</b> Model agnostic vs Model specific</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#glossary-notation"><i class="fa fa-check"></i><b>1.5</b> Glossary / Notation</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.6</b> Thanks to</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="prediction-level-explanations.html"><a href="prediction-level-explanations.html"><i class="fa fa-check"></i>Prediction level explanations</a></li>
<li class="chapter" data-level="2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#variable-atribution-vs-what-if-analysis"><i class="fa fa-check"></i><b>2.1</b> Variable atribution vs What-if analysis</a></li>
<li class="chapter" data-level="2.2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#when-to-use"><i class="fa fa-check"></i><b>2.2</b> When to use?</a></li>
<li class="chapter" data-level="2.3" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#three-single-laws"><i class="fa fa-check"></i><b>2.3</b> A bit of philosophy: Three Laws for Prediction Level Explanations</a></li>
<li class="chapter" data-level="2.4" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#example-promoted-or-fired"><i class="fa fa-check"></i><b>2.4</b> Example: Promoted or Fired?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="break-down.html"><a href="break-down.html"><i class="fa fa-check"></i><b>3</b> Break Down</a><ul>
<li class="chapter" data-level="3.1" data-path="break-down.html"><a href="break-down.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="break-down.html"><a href="break-down.html#how-to-read-break-down-plots"><i class="fa fa-check"></i><b>3.2</b> How to read Break Down Plots?</a></li>
<li class="chapter" data-level="3.3" data-path="break-down.html"><a href="break-down.html#how-to-construct-break-down-plots"><i class="fa fa-check"></i><b>3.3</b> How to construct Break Down Plots</a></li>
<li class="chapter" data-level="3.4" data-path="break-down.html"><a href="break-down.html#interactions"><i class="fa fa-check"></i><b>3.4</b> Interactions</a></li>
<li class="chapter" data-level="3.5" data-path="break-down.html"><a href="break-down.html#pros-and-cons"><i class="fa fa-check"></i><b>3.5</b> Pros and cons</a></li>
<li class="chapter" data-level="3.6" data-path="break-down.html"><a href="break-down.html#code-snippets-for-r"><i class="fa fa-check"></i><b>3.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>4</b> Shapley Values</a></li>
<li class="chapter" data-level="5" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>5</b> LIME: Local Interpretable Model-Agnostic Explanations</a></li>
<li class="chapter" data-level="6" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>6</b> Ceteris Paribus Principle</a><ul>
<li class="chapter" data-level="6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-2"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#ceterisParibus1d"><i class="fa fa-check"></i><b>6.2</b> 1D profiles</a></li>
<li class="chapter" data-level="6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#oscillations"><i class="fa fa-check"></i><b>6.3</b> Profile oscillations</a></li>
<li class="chapter" data-level="6.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#d-profiles"><i class="fa fa-check"></i><b>6.4</b> 2D profiles</a></li>
<li class="chapter" data-level="6.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#local-model-fidelity"><i class="fa fa-check"></i><b>6.5</b> Local model fidelity</a></li>
<li class="chapter" data-level="6.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons-1"><i class="fa fa-check"></i><b>6.6</b> Pros and cons</a></li>
<li class="chapter" data-level="6.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>6.7</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="7" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>7</b> Introduction</a><ul>
<li class="chapter" data-level="7.1" data-path="introduction-3.html"><a href="introduction-3.html#example-price-prediction"><i class="fa fa-check"></i><b>7.1</b> Example: Price prediction</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>8</b> Variable Importance</a></li>
<li class="chapter" data-level="9" data-path="marginal-response.html"><a href="marginal-response.html"><i class="fa fa-check"></i><b>9</b> Marginal Response</a><ul>
<li class="chapter" data-level="9.1" data-path="marginal-response.html"><a href="marginal-response.html#partial-dependency-plots"><i class="fa fa-check"></i><b>9.1</b> Partial Dependency Plots</a></li>
<li class="chapter" data-level="9.2" data-path="marginal-response.html"><a href="marginal-response.html#merging-path-plots"><i class="fa fa-check"></i><b>9.2</b> Merging Path Plots</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="performance-diagnostic.html"><a href="performance-diagnostic.html"><i class="fa fa-check"></i><b>10</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="11" data-path="residual-diagnostic.html"><a href="residual-diagnostic.html"><i class="fa fa-check"></i><b>11</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="12" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>12</b> Other topics</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visualisation, Exploration and Explanation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="break-down" class="section level1">
<h1><span class="header-section-number">Chapter 3</span> Break Down</h1>
<p>In this section we introduce tools based on variable relaxation principle. The main goal for these tools is to help understand how model output may be attributed to input variables or sets of variables. Attribution is in most cases additive, thus the model response is decomposed into parts that may be assigned to variables.</p>
<p>Presented explainers are linked with the first law introduced in Section <a href="PredictionExplainers.html#three-single-laws">2.3</a>, i.e. law for prediction’s justifications. Note that there are more tools for variable attribution, some of them will be presented in next sections.</p>
<p>Think of following use cases:</p>
<ul>
<li>Think about a model for hart attack. A patient wants to know which factors have highest impact on the final heart risk score.</li>
<li>Think about a model for apartment prices. An investor wants to know how much of the final price may be attributed to the location of an apartment.</li>
<li>Think about a model for credit scoring. A customer wants to know if factors like gender, age or number of kids influence model decisions.</li>
</ul>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">3.1</span> Introduction</h2>
<p>The name <em>Break Down Plots</em> comes from the way how Break Down plots are working.
The main goal is to decompose model predictions into parts that can be additively attributed to particular variables. See an example in Figure <a href="break-down.html#fig:BDPrice1">3.1</a>.</p>
<p>It is straightforward for linear (and more general: additive) models. But not that obvious for more complex models. In this section we present uniform, model agnostic approach to variable attribution.</p>
<div class="figure" style="text-align: center"><span id="fig:BDPrice1"></span>
<img src="figure/bd_price_1.png" alt="(fig:BDPrice1) An illustration of Break Down Plots. Model prediction for Random Forest models for a single observation (grey bar, 4763.9) is decomposed into parts that can be attributed to population average (the bottom bar, 3515.9) and effects of particular variables. " width="70%" />
<p class="caption">
Figure 3.1: (fig:BDPrice1) An illustration of Break Down Plots. Model prediction for Random Forest models for a single observation (grey bar, 4763.9) is decomposed into parts that can be attributed to population average (the bottom bar, 3515.9) and effects of particular variables.
</p>
</div>
<p>Similar to the Shapley method introduced in the Section <a href="shapley.html#shapley">4</a>, Break Down Plots show additive decomposition of model output. As we will show later, the Shapely method may be perceived as an average from all possible Break Down Paths.
In the last subsection we discuss pros and cons of this approach.</p>
</div>
<div id="how-to-read-break-down-plots" class="section level2">
<h2><span class="header-section-number">3.2</span> How to read Break Down Plots?</h2>
<p>The intuition behind <em>Break Down</em> Plots is to show how model prediction would change if observations in general population will be made more similar to the observation of interest.</p>
<p>This idea is described in Figure <a href="#BDPrice4"><strong>??</strong></a> and let’s trace it step by step.
For a black-box model (here random forest model, but it’s structure is not relevant) we want to decompose prediction for following point:</p>
<ul>
<li>surface: 35</li>
<li>floor: 1</li>
<li>no.rooms: 1</li>
<li>district: Srodmiescie</li>
<li>construction year: 2014</li>
</ul>
<p>The model prediction is 4763.9. How to attribute following features to it?</p>
<p>Baseline for this decomposition is the distribution of model predictions for whole population. In the last row of panel A denoted by <code>all data</code> the violin plot shows distribution of model prediction for whole population (here calculated on the validation dataset). Red dot stand for the average, and the average model prediction, averaged over all points is 3515.9.</p>
<p>Then we check how model prediction would change, if every observation in the population would have variable <code>surface</code> equal to <code>35</code>. New distribution for these modified observation is presented in the second row <code>+ surface = 35</code>. Black intervals between these two rows show how individual prediction change from original model prediction to the prediction calculated with coordinate <code>surface</code> set to <code>35</code>. Again, the red dot stands for the average from model predictions for such modified population. This time the average is 3906.</p>
<p>In the next step we modify all observations in the population again, this time we set the <code>floor</code> variable to <code>1</code>. Again, model prediction will change and black intervals show how individual prediction change. Also the average from all these modified prediction will change. This time the new average is 4330.2.</p>
<p>Such steps are repeated for consecutive variables till all variables are set to the point of interest. In this last step all observations in the population will have coordinates changed to the observation of interests and all model predictions are equal 4763.9.</p>
<p>Tracing distributions is not easy, thus instead of distributions we are focused on averages.
Panel B) shows how the average of distribution changes after each step. The average for whole population was 3515.9. After setting <code>surface</code> to <code>35</code> the average changed by <code>+390.1</code>. In the next step, when all observations were changed to <code>floor = 1</code> the average changed by <code>+424.1</code>.</p>
<p>Break Down Plots, presented in the panel C) shows only these differences. Positive values are presented with green bars while negative differences are marked with yellow bar. They sum up to final model prediction, which is denoted by a grey bar in this example.</p>
<p><strong>NOTE</strong></p>
<p>If the considered model is additive, then the order in which variables are added does not matter.
If the model is not additive, then different orders will lead to different effects.</p>
<p>Simplest way to choose an order is to use a greedy procedure in which we first include variables with largest influence to the average.</p>
<p>Find more details about to this procedure in the next section.</p>
<div class="figure" style="text-align: center"><span id="fig:BDPrice4"></span>
<img src="figure/bd_price_4.png" alt="(fig:BDPrice4) Break Down Plots show how variables move the model prediction from population average to the model prognosis for a single observation. A) The last row shows distribution of predictions for the validation dataset. Then the second row shows distribution for all observations with variable surface set to 35. Each new row fixes a new variable and the last row shows model prediction for a single point. Red dots stands for averages. B) Blue arrows shows how the average change after each new variable is set. The longer the arrow, the largest is the effect of particular variable. C) Detailed information about distribution is removed and only changes in average are presented. " width="70%" />
<p class="caption">
Figure 3.2: (fig:BDPrice4) Break Down Plots show how variables move the model prediction from population average to the model prognosis for a single observation. A) The last row shows distribution of predictions for the validation dataset. Then the second row shows distribution for all observations with variable surface set to 35. Each new row fixes a new variable and the last row shows model prediction for a single point. Red dots stands for averages. B) Blue arrows shows how the average change after each new variable is set. The longer the arrow, the largest is the effect of particular variable. C) Detailed information about distribution is removed and only changes in average are presented.
</p>
</div>
</div>
<div id="how-to-construct-break-down-plots" class="section level2">
<h2><span class="header-section-number">3.3</span> How to construct Break Down Plots</h2>
<p>Let us use the following notation: <span class="math inline">\(x = (x_1, x_2, ..., x_d) \in \mathcal R^d\)</span> is a vector with features. <span class="math inline">\(f_M(x):R^{d} \rightarrow R\)</span> is a model under consideration. It may be a regression or classification model. Additionally <span class="math inline">\(X\)</span> is a dataset with <span class="math inline">\(n\)</span> observations, this dataset will be used to learn joint distribution of features.</p>
<p>For a single observation <span class="math inline">\(x\)</span> the model prediction is equal to <span class="math inline">\(f(x)\)</span>. Our goal is to attribute parts of this score to variables (dimensions) in the <span class="math inline">\(R^{d}\)</span> space.</p>
<p><strong>Model agnostic approach</strong></p>
<p>The intuition behind this approach is to identify components of <span class="math inline">\(x\)</span> that cannot be changed without a significant change in the prediction <span class="math inline">\(f(x)\)</span>. In order to present this approach in a more formal way, we first need to introduce some definitions.</p>
<p><em>Relaxed model prediction</em></p>
<p>Let <span class="math inline">\(f^{IndSet}(x^{*})\)</span> denotes an expected model prediction for <span class="math inline">\(x^{*new*}\)</span> relaxed on the set of indexes <span class="math inline">\(IndSet \subset \{1, \ldots, p\}\)</span>.</p>
<p><span class="math display">\[
f^{IndSet}(x^{*}) = E[f(x)|x_{IndSet} = x^{*}_{IndSet}].
\]</span></p>
<p>Thus <span class="math inline">\(f^{IndSet}(x^{*})\)</span> is an expected value for model response conditioned on variables from set <span class="math inline">\(IndSet\)</span> in such a way, that <span class="math inline">\(\forall_{i\in IndSet} x_i = x^{*}_i\)</span>.</p>
<p>The intuition behind relaxed prediction is that we are interested in an average model response for observations that are equal to <span class="math inline">\(x^{*}\)</span> for features from <span class="math inline">\(IndSet^C\)</span> set and follow the population distribution for features from <span class="math inline">\(IndSet\)</span> set. Clearly, two extreme cases are</p>
<p><span class="math display">\[
f^{\{1, \ldots, p\}}(x^{*}) = f(x^{*}),
\]</span>
which is the case of no relaxation, and
<span class="math display">\[
f^{\emptyset}(x^{new}) = E [f(x)].
\]</span>
which corresponds to full relaxation.</p>
<p>We will say that a variable was relaxed, when we do not fix its value and we let it follow the population distribution.</p>
<p>This will play a crucial part in the algorithm presented in this section.</p>
<p>Since we do not know the joint distribution of <span class="math inline">\(x\)</span>, we will use its estimate instead.
<span class="math display">\[
\widehat {f^{IndSet}(x^{*})} = \frac 1n \sum_{i = 1}^n f(x^i_{-IndSet},x^{*}_{IndSet}).
\]</span>
We will omit the dashes to simplify the notation.</p>
<p><em>Distance to relaxed model prediction</em></p>
<p>Let us define the distance between model prediction and relaxed model prediction for a set of indexes <span class="math inline">\(IndSet\)</span>.</p>
<p><span class="math display">\[
d(x^{*}, IndSet) := |f^{IndSet}(x^{*}) - f(x^{*})|.
\]</span></p>
<p>It is the difference between model prediction for observation <span class="math inline">\(x^{*}\)</span> and observation relaxed on features <span class="math inline">\(indSet\)</span>.
The smaller the difference, the less important are variables in the <span class="math inline">\(indSet\)</span> set.</p>
<p><em>Added feature contribution</em></p>
<p>For j-th feature we define its contribution relative to a set of indexes <span class="math inline">\(IndSet\)</span> (<em>added contribution</em>) as</p>
<p><span class="math display">\[
\text{contribution}^{IndSet}(j) = f^{IndSet \cup \{j\}}(x^{*}) - f^{IndSet}(x^{*}).
\]</span></p>
<p>It is the change in model prediction for <span class="math inline">\(x^{*}\)</span> after relaxation on <span class="math inline">\(j\)</span>.</p>
<p>The model agnostic feature contribution is based on distances to relaxed model predictions. In this approach we look for a series of variables that can be relaxed in such a way so as to move model prediction from <span class="math inline">\(f(x^{*})\)</span> to a fully relaxed prediction <span class="math inline">\(E [f(x)]\)</span> (expected value for all model predictions). The order of features in this series is important. But here we use a greedy strategy in which we add features to the <span class="math inline">\(indSet\)</span> iteratively (one feature per iteration) and minimize locally the distance to relaxed model prediction.</p>
<p>The greedy search can start from a null set of indexes (then in each step a single feature is being relaxed) or it can start from a full set of relaxed features (then in each step a single feature is removed from the set).
The above approaches are called <em>step-up</em> and <em>step-down</em>, respectively.</p>
<p>The algorithm  presents the procedure that generates a sequence of variables with increasing contributions. This sequence corresponds to variables that can be relaxed in such a way so as to minimize the distance to the original prediction. The resulting sequence of <span class="math inline">\(Contributions\)</span> and <span class="math inline">\(Variables\)</span> may be plotted with Break Down Plots. By relaxing consecutive variables one finds a path between single prediction and average model prediction.</p>
<p><strong>Model agnostic break down of model predictions. The <em>step-down</em> approach.</strong></p>
<ol style="list-style-type: decimal">
<li>$p := $ number of variables</li>
<li><span class="math inline">\(IndSet := \{1, \ldots, p\}\)</span>, i.e. set of indexes of all variables</li>
<li>FOR <span class="math inline">\(i \in \{1, \ldots, p\}\)</span></li>
<li>Find new variable that can be relaxed with small loss in relaxed distance to <span class="math inline">\(f(x^{*})\)</span></li>
<li>FOR <span class="math inline">\(j in IndSet\)</span></li>
<li>Calculate relaxed distance with <span class="math inline">\(j\)</span> removed</li>
<li><span class="math inline">\(dist(j) := d(x^{*}, IndSet \setminus \{j\})\)</span></li>
<li>END FOR 5.</li>
<li>Find and remove <span class="math inline">\(j\)</span> that minimizes loss</li>
<li><span class="math inline">\(j_{min} := \text{arg}\min_j dist(j)\)</span></li>
<li><span class="math inline">\(Contribution^{IndSet}(i) := f^{IndSet}(x^{new}) - f^{IndSet \setminus \{j_{min}\}}(x^{*})\)</span></li>
<li><span class="math inline">\(Variables(i) := j_{min}\)</span></li>
<li><span class="math inline">\(IndSet := IndSet \setminus \{j_{min}\}\)</span></li>
<li>END FOR 3.</li>
</ol>
<p><strong>Approach for linear models</strong></p>
<p>For linear models (and also generalized linear models) the scoring function (e.g. link function) may be expressed as linear combination of feature vectors.</p>
<p><span class="math display">\[
f(x^{*}) = (1, x^{*}) (\mu, \beta)^T = \mu + x^{*}_1 \beta_1 + \ldots + x^{*}_p \beta_p.
\]</span></p>
<p>In this case it is easy to attribute the impact of feature <span class="math inline">\(x_i\)</span> to prediction <span class="math inline">\(f(x^{*})\)</span>. The most straightforward approach would be to use the <span class="math inline">\(x^{*}_i \beta_i\)</span> as the attribution. However, it is easier to interpret variable attributions if they are invariant to scale-location transformations of <span class="math inline">\(x_i\)</span>, such as change of the unit or origin. This is why for linear models the variable attributions are defined as <span class="math inline">\((x^{*}_i - \bar x_i) \beta_i\)</span>.</p>
<p>Previous equation may be rewritten as follows:</p>
<p><span class="math display">\[
f(x^{*}) = (1, x^{*}) (\mu, \beta)^T = baseline + (x^{*}_1 - \bar x_1) \beta_1 + ... + (x^{*}_p - \bar x_p) \beta_p
\]</span></p>
<p>where</p>
<p><span class="math display">\[
baseline = \mu + \bar x_1 \beta_1 + ... + \bar x_p \beta_p.
\]</span></p>
<p>Components <span class="math inline">\((x^{*}_i - \bar x_i) \beta_i\)</span> are all expressed in the same units.</p>
</div>
<div id="interactions" class="section level2">
<h2><span class="header-section-number">3.4</span> Interactions</h2>
<p>Break Down decomposition shows how the expected model prediction changes when we move from general population to a particular observation.
Changes here means that values of variables are set to a value observed in a point of interest.
For non additive models the order of relaxations is important.
Therefore the construction of Break Down containes two phases.</p>
<p>A. Order of relaxations is determined.
B. Sequential relaxation is performed.</p>
<p>Let us present each phase in details based on an example.</p>
<p>To determine the order we consider a series of one step relaxations.</p>
<p>With the use of notation introduced in this section, we calculate expected valued for model predictions after a single variable <span class="math inline">\(i\)</span> is set to value observed in <span class="math inline">\(x^*\)</span>.</p>
<p><span class="math display">\[
score_i = f^{\{i\}}(x^*)
\]</span></p>
<p>To determine the effect of this variable, we compare <span class="math inline">\(score_i\)</span> with the average model response <span class="math inline">\(score_0\)</span>. The larger the difference, the larger is the effect of particular value.</p>
<p><span class="math display">\[
diff_i = score_i - f^{\emptyset}(x^*)
\]</span></p>
<p><strong>Example</strong></p>
<p>Let us consider a HR dataset. The observation of interested is (TODO).
The table below shows <span class="math inline">\(score_i\)</span> and <span class="math inline">\(diff_i\)</span> calculated for consecutive variables.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">score</th>
<th align="right">diff</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">hours</td>
<td align="right">0.616200</td>
<td align="right">0.230614</td>
</tr>
<tr class="even">
<td align="left">salary</td>
<td align="right">0.225528</td>
<td align="right">-0.160058</td>
</tr>
<tr class="odd">
<td align="left">evaluation</td>
<td align="right">0.430994</td>
<td align="right">0.045408</td>
</tr>
<tr class="even">
<td align="left">age</td>
<td align="right">0.364258</td>
<td align="right">-0.021328</td>
</tr>
<tr class="odd">
<td align="left">gender</td>
<td align="right">0.391060</td>
<td align="right">0.005474</td>
</tr>
</tbody>
</table>
<p>Once we determine the order we can calculate sequential relaxations.</p>
<table>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="right">cumulative</th>
<th align="right">contribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">0.385586</td>
<td align="right">0.385586</td>
</tr>
<tr class="even">
<td align="left">* hours = 42</td>
<td align="right">0.616200</td>
<td align="right">0.230614</td>
</tr>
<tr class="odd">
<td align="left">* salary = 2</td>
<td align="right">0.400206</td>
<td align="right">-0.215994</td>
</tr>
<tr class="even">
<td align="left">* evaluation = 2</td>
<td align="right">0.405776</td>
<td align="right">0.005570</td>
</tr>
<tr class="odd">
<td align="left">* age = 58</td>
<td align="right">0.497314</td>
<td align="right">0.091538</td>
</tr>
<tr class="even">
<td align="left">* gender = male</td>
<td align="right">0.778000</td>
<td align="right">0.280686</td>
</tr>
<tr class="odd">
<td align="left">final_prognosis</td>
<td align="right">0.778000</td>
<td align="right">0.778000</td>
</tr>
</tbody>
</table>
<p>As we see contributions calculated in the sequential relaxations are different that these calculated in the first step.</p>
<p>Such situation suggests that the model under consideration is not additive.
What we can do with interactions?</p>
<p>Actually it turns out that we can use a very similar technique to identify interactions. We just need to extend bot steps intorduces in this section.</p>
<p>A. Order of relaxations is determined.
B. Sequential relaxation is performed.</p>
<p>For A. we need to calculate second order scores, i.e.</p>
<p><span class="math display">\[
score_{ij} = f^{\{i,j\}}(x^*)
\]</span></p>
<p>And calculate how much the second order score is different than sum of first order scores.</p>
<p><span class="math display">\[
diff_{ij} = score_{ij} - f^{\{i\}}(x^*) - f^{\{j\}}(x^*) + f^{\emptyset}(x^*) = score_{ij} - diff_i - diff_j - f^{\emptyset}(x^*) 
\]</span></p>
<p>Note, that for additive models <span class="math inline">\(diff_{ij}\)</span> shall be close to zero, so the larger is this value the larger deviation from additivness.</p>
<p><strong>Example</strong></p>
<p>Again, let us consider a HR dataset. The observation of interested is (TODO).
The table below shows <span class="math inline">\(score_i\)</span> and <span class="math inline">\(diff_i\)</span> calculated for consecutive variables.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">baseline</th>
<th align="right">diff</th>
<th align="right">diff ij</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">hours</td>
<td align="right">0.616200</td>
<td align="right">0.230614</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">salary</td>
<td align="right">0.225528</td>
<td align="right">-0.160058</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">age:gender</td>
<td align="right">0.516392</td>
<td align="right"></td>
<td align="right">0.146660</td>
</tr>
<tr class="even">
<td align="left">salary:age</td>
<td align="right">0.266226</td>
<td align="right"></td>
<td align="right">0.062026</td>
</tr>
<tr class="odd">
<td align="left">salary:hours</td>
<td align="right">0.400206</td>
<td align="right"></td>
<td align="right">-0.055936</td>
</tr>
<tr class="even">
<td align="left">evaluation</td>
<td align="right">0.430994</td>
<td align="right">0.045408</td>
<td align="right"></td>
</tr>
<tr class="odd">
<td align="left">hours:age</td>
<td align="right">0.635662</td>
<td align="right"></td>
<td align="right">0.040790</td>
</tr>
<tr class="even">
<td align="left">salary:evaluation</td>
<td align="right">0.238126</td>
<td align="right"></td>
<td align="right">-0.032810</td>
</tr>
<tr class="odd">
<td align="left">age</td>
<td align="right">0.364258</td>
<td align="right">-0.021328</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">evaluation:hours</td>
<td align="right">0.677798</td>
<td align="right"></td>
<td align="right">0.016190</td>
</tr>
<tr class="odd">
<td align="left">salary:gender</td>
<td align="right">0.223292</td>
<td align="right"></td>
<td align="right">-0.007710</td>
</tr>
<tr class="even">
<td align="left">evaluation:age</td>
<td align="right">0.415688</td>
<td align="right"></td>
<td align="right">0.006022</td>
</tr>
<tr class="odd">
<td align="left">gender</td>
<td align="right">0.391060</td>
<td align="right">0.005474</td>
<td align="right"></td>
</tr>
<tr class="even">
<td align="left">hours:gender</td>
<td align="right">0.626478</td>
<td align="right"></td>
<td align="right">0.004804</td>
</tr>
<tr class="odd">
<td align="left">evaluation:gender</td>
<td align="right">0.433814</td>
<td align="right"></td>
<td align="right">-0.002654</td>
</tr>
</tbody>
</table>
<p>Again, once we determine the order we can calculate sequential relaxations.</p>
<table>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="right">cummulative</th>
<th align="right">contribution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">0.385586</td>
<td align="right">0.385586</td>
</tr>
<tr class="even">
<td align="left">* hours = 42</td>
<td align="right">0.616200</td>
<td align="right">0.230614</td>
</tr>
<tr class="odd">
<td align="left">* salary = 2</td>
<td align="right">0.400206</td>
<td align="right">-0.215994</td>
</tr>
<tr class="even">
<td align="left">* age:gender = 58:male</td>
<td align="right">0.796856</td>
<td align="right">0.396650</td>
</tr>
<tr class="odd">
<td align="left">* evaluation = 2</td>
<td align="right">0.778000</td>
<td align="right">-0.018856</td>
</tr>
<tr class="even">
<td align="left">final_prognosis</td>
<td align="right">0.778000</td>
<td align="right">0.778000</td>
</tr>
</tbody>
</table>
<div class="figure" style="text-align: center"><span id="fig:bdInter1"></span>
<img src="figure/bd_inter_1.png" alt="(fig:bdInter1) Break Down plot with interactions " width="70%" />
<p class="caption">
Figure 3.3: (fig:bdInter1) Break Down plot with interactions
</p>
</div>
</div>
<div id="pros-and-cons" class="section level2">
<h2><span class="header-section-number">3.5</span> Pros and cons</h2>
<p>Break Down Plots gives a uniform approach to decompose model prediction into parts that can be attributed additively to variables. Below we summarize key strengths and weaknesses of this approach.</p>
<p><strong>Pros</strong></p>
<ul>
<li>Graphical representation of Break Down plots is easy to understand.</li>
<li>Break Down plots are compact, many variables may be presented in a small space.</li>
<li>Break Down plots are model agnostic yet they reduce to intuitive interpretation for linear Gaussian and generalized models.</li>
<li>Break Down plots are faster than other approaches to variable attribution.</li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li>If the model is non-additive then showing only additive contributions may be misleading.</li>
<li>For large number of variables the Break Down plot may be messy with many variables having small contributions.</li>
<li>For non-additive models the Break Down plot will depend on the order of variables being relaxed.</li>
</ul>
</div>
<div id="code-snippets-for-r" class="section level2">
<h2><span class="header-section-number">3.6</span> Code snippets for R</h2>
<p>In this section we present key features of the <code>breakDown</code> package for R <span class="citation">(P. Biecek <a href="#ref-R-breakDown">2018</a><a href="#ref-R-breakDown">a</a>)</span>. This package covers all features presented in this chapter. It is available on CRAN and GitHub. Find more examples at the website of this package <code>https://pbiecek.github.io/breakDown/</code>.</p>
<p><strong>Model preparation</strong></p>
<p>In this section we will present examples based on the <code>apartments</code> dataset. See section TODO for more details.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="kw">head</span>(HR)</a></code></pre></div>
<pre><code>##   gender      age    hours evaluation salary   status
## 1   male 32.58267 41.88626          3      1    fired
## 2 female 41.21104 36.34339          2      5    fired
## 3   male 37.70516 36.81718          3      0    fired
## 4 female 30.06051 38.96032          3      2    fired
## 5   male 21.10283 62.15464          5      3 promoted
## 6   male 40.11812 69.53973          2      0    fired</code></pre>
<p>The problem here is to predict average price for square meter for an apartment. Let’s build a random forest model with <code>randomForest</code> package <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">model &lt;-<span class="st"> </span><span class="kw">randomForest</span>(status <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hours <span class="op">+</span><span class="st"> </span>evaluation <span class="op">+</span><span class="st"> </span>salary, <span class="dt">data =</span> HR)</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">model</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = status ~ gender + age + hours + evaluation +      salary, data = HR) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 27.27%
## Confusion matrix:
##          fired   ok promoted class.error
## fired     2276  382      197   0.2028021
## ok         532 1253      436   0.4358397
## promoted   205  388     2178   0.2140022</code></pre>
<p>Model exploration with <code>breakDown</code> package is performed in three steps.</p>
<p><strong>1. Create an explainer - wrapper around model and validation data.</strong></p>
<p>Since all other functions work in a model agnostic fashion, first we need to define a wrapper around the model. Here we are using the <code>explain()</code> function from <code>DALEX</code> package <span class="citation">(P. Biecek <a href="#ref-R-DALEX">2018</a><a href="#ref-R-DALEX">c</a>)</span>.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">explainer_rf_fired &lt;-<span class="st"> </span><span class="kw">explain</span>(model,</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">                 <span class="dt">data =</span> HR,</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">                 <span class="dt">y =</span> HR<span class="op">$</span>status <span class="op">==</span><span class="st"> &quot;fired&quot;</span>,</a>
<a class="sourceLine" id="cb9-4" data-line-number="4">                 <span class="dt">predict_function =</span> <span class="cf">function</span>(m,x) <span class="kw">predict</span>(m,x, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)[,<span class="dv">1</span>],</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">                 <span class="dt">label =</span> <span class="st">&quot;fired&quot;</span>)</a></code></pre></div>
<p><strong>2. Define point of interest.</strong></p>
<p>Break Down Plots decompose model prediction around a single point.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">new_observation &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">gender =</span> <span class="kw">factor</span>(<span class="st">&quot;male&quot;</span>, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;male&quot;</span>, <span class="st">&quot;female&quot;</span>)),</a>
<a class="sourceLine" id="cb10-2" data-line-number="2">                      <span class="dt">age =</span> <span class="fl">57.7</span>,</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">                      <span class="dt">hours =</span> <span class="fl">42.3</span>,</a>
<a class="sourceLine" id="cb10-4" data-line-number="4">                      <span class="dt">evaluation =</span> <span class="dv">2</span>,</a>
<a class="sourceLine" id="cb10-5" data-line-number="5">                      <span class="dt">salary =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb10-6" data-line-number="6"></a>
<a class="sourceLine" id="cb10-7" data-line-number="7"><span class="kw">predict</span>(model, new_observation, <span class="dt">type =</span> <span class="st">&quot;prob&quot;</span>)</a></code></pre></div>
<pre><code>##   fired    ok promoted
## 1 0.778 0.218    0.004
## attr(,&quot;class&quot;)
## [1] &quot;matrix&quot; &quot;votes&quot;</code></pre>
<p><strong>3. Calculate BD decomposition</strong></p>
<p>The <code>break_down()</code> function calculates BP decomposition for selected model around selected observation.</p>
<p>The result from <code>break_down()</code> function is a data frame with variable attributions.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;breakDown&quot;</span>)</a>
<a class="sourceLine" id="cb12-2" data-line-number="2">bd_rf &lt;-<span class="st"> </span><span class="kw">break_down</span>(explainer_rf_fired,</a>
<a class="sourceLine" id="cb12-3" data-line-number="3">                 new_observation,</a>
<a class="sourceLine" id="cb12-4" data-line-number="4">                 <span class="dt">keep_distributions =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb12-5" data-line-number="5"></a>
<a class="sourceLine" id="cb12-6" data-line-number="6">bd_rf</a></code></pre></div>
<pre><code>##                        contribution
## (Intercept)                   0.376
## * hours = 42                  0.240
## * salary = 2                 -0.202
## * age:gender = 58:male        0.398
## * evaluation = 2             -0.034
## final_prognosis               0.778
## baseline:  0</code></pre>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="kw">plot</span>(bd_rf) </a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1"><span class="kw">plot</span>(bd_rf, <span class="dt">plot_distributions =</span> <span class="ot">TRUE</span>) </a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-breakDown">
<p>Biecek, Przemyslaw. 2018a. <em>BreakDown: Model Agnostic Explainers for Individual Predictions</em>. <a href="https://CRAN.R-project.org/package=breakDown" class="uri">https://CRAN.R-project.org/package=breakDown</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest" class="uri">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-R-DALEX">
<p>Biecek, Przemyslaw. 2018c. <em>DALEX: Descriptive mAchine Learning Explanations</em>. <a href="https://pbiecek.github.io/DALEX/" class="uri">https://pbiecek.github.io/DALEX/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="PredictionExplainers.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="shapley.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
