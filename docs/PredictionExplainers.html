<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visualisation, Exploration and Explanation</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2018-09-17">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="prediction-level-explanations.html">
<link rel="next" href="break-down.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#model-lifecycle"><i class="fa fa-check"></i><b>1.1</b> Model Lifecycle</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#why-do-we-need-model-explainers"><i class="fa fa-check"></i><b>1.2</b> Why do we need model explainers?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#black-box-models-vs-white-box-models"><i class="fa fa-check"></i><b>1.3</b> Black-box models vs White-box models</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#model-agnostic-vs-model-specific"><i class="fa fa-check"></i><b>1.4</b> Model agnostic vs Model specific</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#glossary-notation"><i class="fa fa-check"></i><b>1.5</b> Glossary / Notation</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.6</b> Thanks to</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="prediction-level-explanations.html"><a href="prediction-level-explanations.html"><i class="fa fa-check"></i>Prediction level explanations</a></li>
<li class="chapter" data-level="2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#variable-atribution-vs-what-if-analysis"><i class="fa fa-check"></i><b>2.1</b> Variable atribution vs What-if analysis</a></li>
<li class="chapter" data-level="2.2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#when-to-use"><i class="fa fa-check"></i><b>2.2</b> When to use?</a></li>
<li class="chapter" data-level="2.3" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#three-single-laws"><i class="fa fa-check"></i><b>2.3</b> A bit of philosophy: Three Laws for Prediction Level Explanations</a></li>
<li class="chapter" data-level="2.4" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#example-promoted-or-fired"><i class="fa fa-check"></i><b>2.4</b> Example: Promoted or Fired?</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="break-down.html"><a href="break-down.html"><i class="fa fa-check"></i><b>3</b> Break Down</a><ul>
<li class="chapter" data-level="3.1" data-path="break-down.html"><a href="break-down.html#introduction-1"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="break-down.html"><a href="break-down.html#how-to-read-break-down-plots"><i class="fa fa-check"></i><b>3.2</b> How to read Break Down Plots?</a></li>
<li class="chapter" data-level="3.3" data-path="break-down.html"><a href="break-down.html#how-to-construct-break-down-plots"><i class="fa fa-check"></i><b>3.3</b> How to construct Break Down Plots</a></li>
<li class="chapter" data-level="3.4" data-path="break-down.html"><a href="break-down.html#interactions"><i class="fa fa-check"></i><b>3.4</b> Interactions</a></li>
<li class="chapter" data-level="3.5" data-path="break-down.html"><a href="break-down.html#pros-and-cons"><i class="fa fa-check"></i><b>3.5</b> Pros and cons</a></li>
<li class="chapter" data-level="3.6" data-path="break-down.html"><a href="break-down.html#code-snippets-for-r"><i class="fa fa-check"></i><b>3.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>4</b> Shapley Values</a></li>
<li class="chapter" data-level="5" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>5</b> LIME: Local Interpretable Model-Agnostic Explanations</a></li>
<li class="chapter" data-level="6" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>6</b> Ceteris Paribus Principle</a><ul>
<li class="chapter" data-level="6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-2"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#ceterisParibus1d"><i class="fa fa-check"></i><b>6.2</b> 1D profiles</a></li>
<li class="chapter" data-level="6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#oscillations"><i class="fa fa-check"></i><b>6.3</b> Profile oscillations</a></li>
<li class="chapter" data-level="6.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#d-profiles"><i class="fa fa-check"></i><b>6.4</b> 2D profiles</a></li>
<li class="chapter" data-level="6.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#local-model-fidelity"><i class="fa fa-check"></i><b>6.5</b> Local model fidelity</a></li>
<li class="chapter" data-level="6.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons-1"><i class="fa fa-check"></i><b>6.6</b> Pros and cons</a></li>
<li class="chapter" data-level="6.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>6.7</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="7" data-path="introduction-3.html"><a href="introduction-3.html"><i class="fa fa-check"></i><b>7</b> Introduction</a><ul>
<li class="chapter" data-level="7.1" data-path="introduction-3.html"><a href="introduction-3.html#example-price-prediction"><i class="fa fa-check"></i><b>7.1</b> Example: Price prediction</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>8</b> Variable Importance</a></li>
<li class="chapter" data-level="9" data-path="marginal-response.html"><a href="marginal-response.html"><i class="fa fa-check"></i><b>9</b> Marginal Response</a><ul>
<li class="chapter" data-level="9.1" data-path="marginal-response.html"><a href="marginal-response.html#partial-dependency-plots"><i class="fa fa-check"></i><b>9.1</b> Partial Dependency Plots</a></li>
<li class="chapter" data-level="9.2" data-path="marginal-response.html"><a href="marginal-response.html#merging-path-plots"><i class="fa fa-check"></i><b>9.2</b> Merging Path Plots</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="performance-diagnostic.html"><a href="performance-diagnostic.html"><i class="fa fa-check"></i><b>10</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="11" data-path="residual-diagnostic.html"><a href="residual-diagnostic.html"><i class="fa fa-check"></i><b>11</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="12" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>12</b> Other topics</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visualisation, Exploration and Explanation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="PredictionExplainers" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Introduction</h1>
<p>Prediction level explainers help to understand how the model works for a single prediction. This is the main difference from the model level explainers that were focused on the model in general. Prediction level explainers are always in context of a single observation.</p>
<p>Think about following use-cases</p>
<ul>
<li>One wants to attribute effects of variables to a model predictions. Think about model for hart attack. Having a final score for a patient one wants to understand how much of this score come from smoking or age or gender.</li>
<li>One wants to understand how the model response would change if some inputs are changed. Think about model for hart attack. How the model response would change if a patient cuts the number of smoked cigarettes by half.</li>
<li>Model is not working correctly for a particular point and one wants to understand why predictions for this point are wrong.</li>
</ul>
<div id="variable-atribution-vs-what-if-analysis" class="section level2">
<h2><span class="header-section-number">2.1</span> Variable atribution vs What-if analysis</h2>
<p>There are many different tools that may be used to explore model around a single data point and in following sections we will describe the most popular approaches. They can be divided into two classes.</p>
<ul>
<li>Analysis of the model curvature. Here we treat the model as a function and we are interested in the curvature of this function around the point of interest (see Figure <a href="PredictionExplainers.html#fig:modelResponseCurve">2.1</a>). In section <a href="LIME.html#LIME">5</a> we present the LIME method that approximates the black-box model in a point of interest while in section <a href="ceterisParibus.html#ceterisParibus">6</a> we present Ceteris Paribus profiles that are more focused on conditional changes of model response given only one coordinate is modified.</li>
<li>Analysis of the probabilistic behavior of the model. Here we are interested in decomposition of the model response to parts that can be attributed to particular features.</li>
</ul>
<div class="figure"><span id="fig:modelResponseCurve"></span>
<img src="figure/model_response.png" alt="(fig:modelResponseCurve) Model response surface. We are interested in understanding the model behavior in a single point" width="70%" />
<p class="caption">
Figure 2.1: (fig:modelResponseCurve) Model response surface. We are interested in understanding the model behavior in a single point
</p>
</div>
</div>
<div id="when-to-use" class="section level2">
<h2><span class="header-section-number">2.2</span> When to use?</h2>
<p>There are several use-cases for such explainers. Think about following.</p>
<ul>
<li>Model improvement. If model works particular bad for a selected observation (the residual is very high) then investigation of model responses for miss fitted points may give some hints how to improve the model. For individual predictions it is easier to notice that selected variable should have different a effect.</li>
<li>Additional domain specific validation. Understanding which factors are important for model predictions helps to be critical about model response. If model contributions are against domain knowledge then we may be more skeptical and willing to try another model. On the other hand, if the model response is aligned with domain knowledge we may trust more in these responses. Such trust is important in decisions that may lead to serious consequences like predictive models in medicine.</li>
<li>Model selection. Having multiple candidate models one may select the final response based on model explanations. Even if one model is better in terms of global model performance it may happen that locally other model is better fitted. This moves us towards model consultations that identify different options and allow human to select one of them.</li>
</ul>
</div>
<div id="three-single-laws" class="section level2">
<h2><span class="header-section-number">2.3</span> A bit of philosophy: Three Laws for Prediction Level Explanations</h2>
<p>76 years ago Isaac Asimov devised <a href="https://en.wikipedia.org/wiki/Three_Laws_of_Robotics">Three Laws of Robotics</a>: 1) a robot may not injure a human being, 2) a robot must obey the orders given it by human beings and 3) A robot must protect its own existence. These laws impact discussion around <a href="https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence">Ethics of AI</a>. Today’s robots, like cleaning robots, robotic pets or autonomous cars are far from being conscious enough to be under Asimov’s ethics.</p>
<p>Today we are surrounded by complex predictive algorithms used for decision making. Machine learning models are used in health care, politics, education, judiciary and many other areas. Black box predictive models have far larger influence on our lives than physical robots. Yet, applications of such models are left unregulated despite many examples of their potential harmfulness. See <em>Weapons of Math Destruction</em> by Cathy O’Neil for an excellent overview of potential problems.</p>
<p>It’s clear that we need to control algorithms that may affect us. Such control is in our civic rights. Here we propose three requirements that any predictive model should fulfill.</p>
<ul>
<li><strong>Prediction’s justifications</strong>. For every prediction of a model one should be able to understand which variables affect the prediction and how strongly. Variable attribution to final prediction.</li>
<li><strong>Prediction’s speculations</strong>. For every prediction of a model one should be able to understand how the model prediction would change if input variables were changed. Hypothesizing about what-if scenarios.</li>
<li><strong>Prediction’s validations</strong> For every prediction of a model one should be able to verify how strong are evidences that confirm this particular prediction.</li>
</ul>
<p>There are two ways to comply with these requirements.
One is to use only models that fulfill these conditions by design. White-box models like linear regression or decision trees. In many cases the price for transparency is lower performance.
The other way is to use approximated explainers – techniques that find only approximated answers, but work for any black box model. Here we present such techniques.</p>
</div>
<div id="example-promoted-or-fired" class="section level2">
<h2><span class="header-section-number">2.4</span> Example: Promoted or Fired?</h2>
<p>In this chapter we will use artificial dataset from Human Resources department in a call center to present pros and cons for different techniques of prediction level explainers. At the end of each section there is a collection of examples that shows how to use described techniques in R and Python.</p>
<p>The dataset is available in the <code>DALEX</code> package <span class="citation">(P. Biecek <a href="#ref-R-DALEX">2018</a><a href="#ref-R-DALEX">c</a>)</span>. Each row corresponds to a single employee of a call center. Features like gender, age, average number of working hours per week, grade from the last evaluation and level of salary are used as predictive features.</p>
<p>The problem here is to first build a model, that will determine when to fires and when to promote an employer, so it’s a classification problem with three classes.
But having a model we will use prediction level explainers to better understand how the model works for selected cases.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">head</span>(HR)</a></code></pre></div>
<pre><code>##   gender      age    hours evaluation salary   status
## 1   male 32.58267 41.88626          3      1    fired
## 2 female 41.21104 36.34339          2      5    fired
## 3   male 37.70516 36.81718          3      0    fired
## 4 female 30.06051 38.96032          3      2    fired
## 5   male 21.10283 62.15464          5      3 promoted
## 6   male 40.11812 69.53973          2      0    fired</code></pre>
<p>In this book we are focused on model exploration rather than model building, thus for sake ok simplicity we will use two default models created with random forest <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span> and generalized linear model <span class="citation">(<span class="citeproc-not-found" data-reference-id="R-nnet"><strong>???</strong></span>)</span>.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="kw">set.seed</span>(<span class="dv">59</span>)</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">model_rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(status <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hours <span class="op">+</span><span class="st"> </span>evaluation <span class="op">+</span><span class="st"> </span>salary, <span class="dt">data =</span> HR)</a>
<a class="sourceLine" id="cb3-4" data-line-number="4"></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="kw">library</span>(<span class="st">&quot;nnet&quot;</span>)</a>
<a class="sourceLine" id="cb3-6" data-line-number="6">model_glm &lt;-<span class="st"> </span><span class="kw">multinom</span>(status <span class="op">~</span><span class="st"> </span>gender <span class="op">+</span><span class="st"> </span>age <span class="op">+</span><span class="st"> </span>hours <span class="op">+</span><span class="st"> </span>evaluation <span class="op">+</span><span class="st"> </span>salary, <span class="dt">data =</span> HR)</a></code></pre></div>
<pre><code>## # weights:  21 (12 variable)
## initial  value 8620.810629 
## iter  10 value 7002.127738
## iter  20 value 6239.478146
## iter  20 value 6239.478126
## iter  20 value 6239.478124
## final  value 6239.478124 
## converged</code></pre>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-R-DALEX">
<p>Biecek, Przemyslaw. 2018c. <em>DALEX: Descriptive mAchine Learning Explanations</em>. <a href="https://pbiecek.github.io/DALEX/" class="uri">https://pbiecek.github.io/DALEX/</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest" class="uri">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prediction-level-explanations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="break-down.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
