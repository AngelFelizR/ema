<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>19 Residual-diagnostics Plots | Explanatory Model Analysis</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="19 Residual-diagnostics Plots | Explanatory Model Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="figure/front4.png" />
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="19 Residual-diagnostics Plots | Explanatory Model Analysis" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="twitter:image" content="figure/front4.png" />

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-08-31" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="accumulatedLocalProfiles.html"/>
<link rel="next" href="summaryModelLevel.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain, and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.1</b> The aim of the book</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.2</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#teminology"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#glassblack"><i class="fa fa-check"></i><b>1.4</b> Black-box models and glass-box models</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#agnosticspecific"><i class="fa fa-check"></i><b>1.5</b> Model-agnostic and model-specific approach</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.6</b> The structure of the book</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#whatisinthebook"><i class="fa fa-check"></i><b>1.7</b> What is included in this book and what is not</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.8</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> Model-development process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#dataunderstanding"><i class="fa fa-check"></i><b>2.4</b> Data understanding</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#fitting"><i class="fa fa-check"></i><b>2.5</b> Model assembly (fitting)</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#validation"><i class="fa fa-check"></i><b>2.6</b> Model audit</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="do-it-yourself.html"><a href="do-it-yourself.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself</a>
<ul>
<li class="chapter" data-level="3.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#doItYourselfWithR"><i class="fa fa-check"></i><b>3.1</b> Do-it-yourself with R</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#what-to-install"><i class="fa fa-check"></i><b>3.1.1</b> What to install?</a></li>
<li class="chapter" data-level="3.1.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#infoDALEX"><i class="fa fa-check"></i><b>3.1.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.1.3" data-path="do-it-yourself.html"><a href="do-it-yourself.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.1.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#doItYourselfWithPython"><i class="fa fa-check"></i><b>3.2</b> Do-it-yourself with Python</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#what-to-install-1"><i class="fa fa-check"></i><b>3.2.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#infoDALEXpy"><i class="fa fa-check"></i><b>3.2.2</b> How to work with <code>dalex</code>?</a></li>
<li class="chapter" data-level="3.2.3" data-path="do-it-yourself.html"><a href="do-it-yourself.html#code-snippets-for-python"><i class="fa fa-check"></i><b>3.2.3</b> Code snippets for Python</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>4</b> Datasets and models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>4.1</b> Sinking of the RMS Titanic</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>4.1.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-rms-titanic-snippets-for-r"><i class="fa fa-check"></i><b>4.2</b> Models for RMS Titanic, snippets for R</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>4.2.1</b> Logistic regression model</a></li>
<li class="chapter" data-level="4.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>4.2.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>4.2.3</b> Gradient boosting model</a></li>
<li class="chapter" data-level="4.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>4.2.4</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>4.2.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>4.2.6</b> Models’ explainers</a></li>
<li class="chapter" data-level="4.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>4.2.7</b> List of model-objects</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-rms-titanic-snippets-for-python"><i class="fa fa-check"></i><b>4.3</b> Models for RMS Titanic, snippets for Python</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-lr"><i class="fa fa-check"></i><b>4.3.1</b> Logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-rf"><i class="fa fa-check"></i><b>4.3.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.3.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-gbm"><i class="fa fa-check"></i><b>4.3.3</b> Gradient boosting model</a></li>
<li class="chapter" data-level="4.3.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-svm"><i class="fa fa-check"></i><b>4.3.4</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.3.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic-python"><i class="fa fa-check"></i><b>4.3.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.3.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicPythonCode"><i class="fa fa-check"></i><b>4.3.6</b> Models’ explainers</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>4.4</b> Apartment prices</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>4.4.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-apartment-prices-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Models for Apartment prices, snippets for R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>4.5.1</b> Linear regression model</a></li>
<li class="chapter" data-level="4.5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>4.5.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.5.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>4.5.3</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.5.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>4.5.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.5.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>4.5.5</b> Models’ explainers</a></li>
<li class="chapter" data-level="4.5.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>4.5.6</b> List of model-objects</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-apartment-prices-snippets-for-python"><i class="fa fa-check"></i><b>4.6</b> Models for Apartment prices, snippets for Python</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-lr"><i class="fa fa-check"></i><b>4.6.1</b> Linear regression model</a></li>
<li class="chapter" data-level="4.6.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-rf"><i class="fa fa-check"></i><b>4.6.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.6.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-svm"><i class="fa fa-check"></i><b>4.6.3</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.6.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-apartments-python"><i class="fa fa-check"></i><b>4.6.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.6.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsPythonCode"><i class="fa fa-check"></i><b>4.6.5</b> Models’ explainers</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Instance Level</b></span></li>
<li class="chapter" data-level="5" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>5</b> Introduction to Instance-level Exploration</a></li>
<li class="chapter" data-level="6" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>6</b> Break-down Plots for Additive Attributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="breakDown.html"><a href="breakDown.html#BDIntroduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>6.3</b> Method</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="breakDown.html"><a href="breakDown.html#BDMethodLin"><i class="fa fa-check"></i><b>6.3.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="6.3.2" data-path="breakDown.html"><a href="breakDown.html#BDMethodGen"><i class="fa fa-check"></i><b>6.3.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>6.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="6.5" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>6.5</b> Pros and cons</a></li>
<li class="chapter" data-level="6.6" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>6.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>6.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="6.6.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>6.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="breakDown.html"><a href="breakDown.html#BDPython"><i class="fa fa-check"></i><b>6.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Interactions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a></li>
<li class="chapter" data-level="7.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a></li>
<li class="chapter" data-level="7.6" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDPythonCode"><i class="fa fa-check"></i><b>7.6</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>8</b> Shapley Additive Explanations (SHAP) for Average Attributions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
<li class="chapter" data-level="8.6" data-path="shapley.html"><a href="shapley.html#SHAPPythonCode"><i class="fa fa-check"></i><b>8.6</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>9</b> Local Interpretable Model-agnostic Explanations (LIME)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>9.2</b> Intuition</a></li>
<li class="chapter" data-level="9.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>9.3</b> Method</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="LIME.html"><a href="LIME.html#LIMErepr"><i class="fa fa-check"></i><b>9.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="9.3.2" data-path="LIME.html"><a href="LIME.html#LIMEsample"><i class="fa fa-check"></i><b>9.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="9.3.3" data-path="LIME.html"><a href="LIME.html#LIMEglas"><i class="fa fa-check"></i><b>9.3.3</b> Fitting the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>9.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>9.5</b> Pros and cons</a></li>
<li class="chapter" data-level="9.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>9.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="LIME.html"><a href="LIME.html#LIMERcodelime"><i class="fa fa-check"></i><b>9.6.1</b> The <code>lime</code> package</a></li>
<li class="chapter" data-level="9.6.2" data-path="LIME.html"><a href="LIME.html#LIMERcodelocMod"><i class="fa fa-check"></i><b>9.6.2</b> The <code>localModel</code> package</a></li>
<li class="chapter" data-level="9.6.3" data-path="LIME.html"><a href="LIME.html#LIMERcodeiml"><i class="fa fa-check"></i><b>9.6.3</b> The <code>iml</code> package</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="LIME.html"><a href="LIME.html#LIMEPythoncode"><i class="fa fa-check"></i><b>9.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>10</b> Ceteris-paribus Profiles</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a></li>
<li class="chapter" data-level="10.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-predict_profile-function"><i class="fa fa-check"></i><b>10.6.1</b> Basic use of the <code>predict_profile()</code> function</a></li>
<li class="chapter" data-level="10.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-predict_profile-function"><i class="fa fa-check"></i><b>10.6.2</b> Advanced use of the <code>predict_profile()</code> function</a></li>
<li class="chapter" data-level="10.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#comparison-of-models-champion-challenger"><i class="fa fa-check"></i><b>10.6.3</b> Comparison of models (champion-challenger)</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPPython"><i class="fa fa-check"></i><b>10.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Oscillations</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscPython"><i class="fa fa-check"></i><b>11.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>12</b> Local-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="12.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagneighbours"><i class="fa fa-check"></i><b>12.3.1</b> Nearest neighbours</a></li>
<li class="chapter" data-level="12.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>12.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="12.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>12.3.3</b> Local-stability plot</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="12.7" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagPython"><i class="fa fa-check"></i><b>12.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>13</b> Summary of Instance-level Exploration</a>
<ul>
<li class="chapter" data-level="13.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#summaryInstanceLevelIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>13.2</b> Number of explanatory variables in the model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-a-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.2</b> Medium to a large number of explanatory variables</a></li>
<li class="chapter" data-level="13.2.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>13.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="13.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>13.4</b> Models with interactions</a></li>
<li class="chapter" data-level="13.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>13.5</b> Sparse explanations</a></li>
<li class="chapter" data-level="13.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>13.6</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="13.7" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#comparison-of-models-champion-challenger-analysis"><i class="fa fa-check"></i><b>13.7</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="part"><span><b>III Dataset Level</b></span></li>
<li class="chapter" data-level="14" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>14</b> Introduction to Dataset-level Exploration</a></li>
<li class="chapter" data-level="15" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>15</b> Model-performance Measures</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>15.2</b> Intuition</a></li>
<li class="chapter" data-level="15.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>15.3</b> Method</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>15.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="15.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>15.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="15.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>15.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="15.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>15.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>15.4</b> Example</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>15.4.1</b> Apartment prices</a></li>
<li class="chapter" data-level="15.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>15.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>15.5</b> Pros and cons</a></li>
<li class="chapter" data-level="15.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>15.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="15.7" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformancePython"><i class="fa fa-check"></i><b>15.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>16</b> Variable-importance Measures</a>
<ul>
<li class="chapter" data-level="16.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a></li>
<li class="chapter" data-level="16.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>16.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="16.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="16.7" data-path="featureImportance.html"><a href="featureImportance.html#featureImportancePython"><i class="fa fa-check"></i><b>16.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>17</b> Partial-dependence Profiles</a>
<ul>
<li class="chapter" data-level="17.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPs"><i class="fa fa-check"></i><b>17.3.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clusteredPDPs"><i class="fa fa-check"></i><b>17.3.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#groupedPDPs"><i class="fa fa-check"></i><b>17.3.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastivePDPs"><i class="fa fa-check"></i><b>17.3.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>17.4</b> Example: apartment-prices data</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPPython"><i class="fa fa-check"></i><b>17.7</b> Code snippets for Python</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-2"><i class="fa fa-check"></i><b>17.7.1</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.7.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-2"><i class="fa fa-check"></i><b>17.7.2</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>18</b> Local-dependence and Accumulated-local Profiles</a>
<ul>
<li class="chapter" data-level="18.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#local-dependence-profile"><i class="fa fa-check"></i><b>18.3.1</b> Local-dependence profile</a></li>
<li class="chapter" data-level="18.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>18.3.2</b> Accumulated-local profile</a></li>
<li class="chapter" data-level="18.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#dependence-profiles-for-a-model-with-interaction-and-correlated-explanatory-variables-an-example"><i class="fa fa-check"></i><b>18.3.3</b> Dependence profiles for a model with interaction and correlated explanatory variables: an example</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: apartment-prices data</a></li>
<li class="chapter" data-level="18.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="18.7" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPPython"><i class="fa fa-check"></i><b>18.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>19</b> Residual-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="19.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntroResidualDiagnostic"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntuitionResidualDiagnostic"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#MethodResidualDiagnostic"><i class="fa fa-check"></i><b>19.3</b> Method</a></li>
<li class="chapter" data-level="19.4" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ExampleResidualDiagnostic"><i class="fa fa-check"></i><b>19.4</b> Example: apartment-prices data</a></li>
<li class="chapter" data-level="19.5" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ProsConsResidualDiagnostic"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#RcodeResidualDiagnostic"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="19.7" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#PythoncodeResidualDiagnostic"><i class="fa fa-check"></i><b>19.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html"><i class="fa fa-check"></i><b>20</b> Summary of Dataset-level Exploration</a>
<ul>
<li class="chapter" data-level="20.1" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#summaryModelLevelIntro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#exploration-on-trainingtesting-data"><i class="fa fa-check"></i><b>20.2</b> Exploration on training/testing data</a></li>
<li class="chapter" data-level="20.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>20.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="20.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#comparison-of-models-champion-challenger-analysis"><i class="fa fa-check"></i><b>20.4</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="part"><span><b>IV Use-cases</b></span></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a>
<ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAintro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAdataprep"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r"><i class="fa fa-check"></i><b>21.2.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.2.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#code-snippets-for-python"><i class="fa fa-check"></i><b>21.2.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAdataunderst"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelassembly"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>21.4.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.4.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-1"><i class="fa fa-check"></i><b>21.4.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelaudit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>21.5.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.5.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-2"><i class="fa fa-check"></i><b>21.5.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelunderst"><i class="fa fa-check"></i><b>21.6</b> Model understanding (dataset-level explanations)</a>
<ul>
<li class="chapter" data-level="21.6.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>21.6.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.6.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-3"><i class="fa fa-check"></i><b>21.6.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAinstanceunderst"><i class="fa fa-check"></i><b>21.7</b> Instance-level explanations</a>
<ul>
<li class="chapter" data-level="21.7.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFALewy"><i class="fa fa-check"></i><b>21.7.1</b> Robert Lewandowski</a></li>
<li class="chapter" data-level="21.7.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>21.7.2</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.7.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-4"><i class="fa fa-check"></i><b>21.7.3</b> Code snippets for Python</a></li>
<li class="chapter" data-level="21.7.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFACR7"><i class="fa fa-check"></i><b>21.7.4</b> CR7</a></li>
<li class="chapter" data-level="21.7.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFASzczesny"><i class="fa fa-check"></i><b>21.7.5</b> Wojciech Szczęsny</a></li>
<li class="chapter" data-level="21.7.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAMessi"><i class="fa fa-check"></i><b>21.7.6</b> Lionel Messi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>22</b> Reproducibility</a>
<ul>
<li class="chapter" data-level="22.1" data-path="reproducibility.html"><a href="reproducibility.html#package-versions-for-r"><i class="fa fa-check"></i><b>22.1</b> Package versions for R</a></li>
<li class="chapter" data-level="22.2" data-path="reproducibility.html"><a href="reproducibility.html#package-versions-for-python"><i class="fa fa-check"></i><b>22.2</b> Package versions for Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Explanatory Model Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="residualDiagnostic" class="section level1" number="19">
<h1><span class="header-section-number">19</span> Residual-diagnostics Plots</h1>
<div id="IntroResidualDiagnostic" class="section level2" number="19.1">
<h2><span class="header-section-number">19.1</span> Introduction</h2>
<p>In this chapter, we present methods that are useful for a detailed examination of both overall and instance-specific model performance. In particular, we focus on graphical methods that use residuals. The methods may be used for several purposes:</p>
<ul>
<li><p>In Part II of the book, we discussed tools for single-instance exploration. Residuals can be used to identify potentially problematic instances. The single-instance explainers can then be used in the problematic cases to understand, for instance, which factors contribute most to the errors in prediction.</p></li>
<li><p>For most models, residuals should express a random behavior with certain properties (like, e.g., being concentrated around 0). If we find any systematic deviations from the expected behavior, they may signal an issue with a model (for instance, an omitted explanatory variable or a wrong functional form of a variable included in the model).</p></li>
<li><p>In Chapter <a href="modelPerformance.html#modelPerformance">15</a>, we discussed measures that can be used to evaluate the overall performance of a predictive model. Sometimes, however, we may be more interested in cases with the largest prediction errors, which can be identified with the help of residuals.</p></li>
</ul>
<p>Residual diagnostics is a classical topic related to statistical modelling. It is most often discussed in the context of the evaluation of goodness-of-fit of a model. That is, residuals are computed using the training data and used to assess whether the model predictions “fit” the observed values of the dependent variable. The literature on the topic is vast, as essentially every book on statistical modeling includes some discussion about residuals. Thus, in this chapter, we are not aiming at being exhaustive. Rather, our goal is to present selected concepts that underlie the use of residuals for predictive models.</p>
</div>
<div id="IntuitionResidualDiagnostic" class="section level2" number="19.2">
<h2><span class="header-section-number">19.2</span> Intuition</h2>
<p>As it was mentioned in Section <a href="modelDevelopmentProcess.html#notation">2.3</a>, we primarily focus on models describing the expected value of the dependent variable as a function of explanatory variables. In such a case, for a “perfect” predictive model, the predicted value of the dependent variable should be exactly equal to the actual value of the variable for every observation. Perfect prediction is rarely, if ever, expected. In practice, we want the predictions to be reasonably close to the actual values. This suggests that we can use the difference between the predicted and the actual value of the dependent variable to quantify the quality of predictions obtained from a model. The difference is called a <em>residual</em>.</p>
<p>For a single observation, residual will almost always be different from zero. While a large (absolute) value of a residual may indicate a problem with a prediction for a particular observation, it does not mean that the quality of predictions obtained from a model is unsatisfactory in general. To evaluate the quality, we should investigate the “behavior” of residuals for a group of observations. In other words, we should look at the distribution of the values of residuals.</p>
<p>For a “good” model, residuals should deviate from zero randomly, i.e., not systematically. Thus, their distribution should be symmetric around zero, implying that their mean (or median) value should be zero. Also, residuals should be close to zero themselves, i.e., they should show low variability.</p>
<p>Usually, to verify these properties, graphical methods are used. For instance, a histogram can be used to check the symmetry and location of the distribution of residuals. Note that a model may imply a concrete distribution for residuals. In such a case, the distributional assumption can be verified by using a suitable graphical method like, for instance, a quantile-quantile plot. If the assumption is found to be violated, one might want to be careful when using predictions obtained from the model.</p>
</div>
<div id="MethodResidualDiagnostic" class="section level2" number="19.3">
<h2><span class="header-section-number">19.3</span> Method</h2>
<p>As it was already mentioned in Chapter <a href="modelDevelopmentProcess.html#modelDevelopmentProcess">2</a>, for a continuous dependent variable <span class="math inline">\(Y\)</span>, residual <span class="math inline">\(r_i\)</span> for the <span class="math inline">\(i\)</span>-th observation in a dataset is the difference between the observed value of <span class="math inline">\(Y\)</span> and the corresponding model prediction:</p>
<p><span class="math display" id="eq:resid">\[\begin{equation}
r_i = y_i - f(\underline{x}_i) = y_i - \widehat{y}_i.
\tag{19.1}
\end{equation}\]</span></p>
<p><em>Standardized residuals</em> are defined as</p>
<p><span class="math display" id="eq:standresid">\[\begin{equation}
\tilde{r}_i = \frac{r_i}{\sqrt{\mbox{Var}(r_i)}},
\tag{19.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mbox{Var}(r_i)\)</span> is the variance of the residual <span class="math inline">\(r_i\)</span>.</p>
<p>Of course, in practice, the variance of <span class="math inline">\(r_i\)</span> is usually unknown. Hence, the estimated value of <span class="math inline">\(\mbox{Var}(r_i)\)</span> is used in <a href="residualDiagnostic.html#eq:standresid">(19.2)</a>. Residuals defined in this way are often called the <em>Pearson residuals</em> <span class="citation">(Galecki and Burzykowski <a href="#ref-Galecki2013" role="doc-biblioref">2013</a>)</span>. Their distribution should be approximately standard-normal. For the classical linear-regression model, <span class="math inline">\(\mbox{Var}(r_i)\)</span> can be estimated by using the design matrix. On the other hand, for count data, the variance can be estimated by <span class="math inline">\(f(\underline{x}_i)\)</span>, i.e., the expected value of the count. In general, for complicated models, it may be hard to estimate <span class="math inline">\(\mbox{Var}(r_i)\)</span>, so it is often approximated by a constant for all residuals.</p>
<!-- Consider, for example, the classical linear-regression model. According to the model, for the $i$-th observation, the dependent variable $Y_i$ should follow a normal distribution with mean $f(x_i)$ and variance $\sigma^2$. Thus, the standardized residual $\tilde{r}_i = r_i/\sigma$. If the model is correct, $\tilde{r}_i$ should have a standard-normal distribution. The Pearson residual is defined as $r_i/\widehat{\sigma}$, where $\widehat{\sigma}$ is the estimated value of $\sigma$, and has, approximately, also a standard-normal distribution.  -->
<p>Definition <a href="residualDiagnostic.html#eq:standresid">(19.2)</a> can also be applied to a binary dependent variable if the model prediction <span class="math inline">\(f(\underline{x}_i)\)</span> is the probability of observing <span class="math inline">\(y_i\)</span> and upon coding the two possible values of the variable as 0 and 1. However, in this case, the range of possible values of <span class="math inline">\(r_i\)</span> is restricted to <span class="math inline">\([-1,1]\)</span>, which limits the usefulness of the residuals. For this reason, more often the Pearson residuals are used. Note that, if the observed values of the explanatory-variable vectors <span class="math inline">\(\underline{x}_i\)</span> lead to different predictions <span class="math inline">\(f(\underline{x}_i)\)</span> for different observations in a dataset, the distribution of the Pearson residuals will not be approximated by the standard-normal one. This is the case when, for instance, one (or more) of the explanatory variables is continuous. Nevertheless, in that case, the index plot may still be useful to detect observations with large residuals. The standard-normal approximation is more likely to apply in the situation when the observed values of vectors <span class="math inline">\(\underline{x}_i\)</span> split the data into a few, say <span class="math inline">\(K\)</span>, groups, with observations in group <span class="math inline">\(k\)</span> (<span class="math inline">\(k=1,\ldots,K\)</span>) sharing the same predicted value <span class="math inline">\(f_k\)</span>. This may be happen if all explanatory variables are categorical with a limited number of categories. In that case, one can consider averaging residuals <span class="math inline">\(r_i\)</span> per group and standardizing them by <span class="math inline">\(\sqrt{f_k(1-f_k)/n_k}\)</span>, where <span class="math inline">\(n_k\)</span> is the number of observations in group <span class="math inline">\(k\)</span>.</p>
<p>For categorical data, residuals are usually defined in terms of differences in predictions for the dummy binary variable indicating the category observed for the <span class="math inline">\(i\)</span>-th observation.</p>
<!---
A histogram of the estimated residuals can be used to check the symmetry and location of their distribution. An index plot of residuals, i.e., the plot of residuals against the corresponding observation number, may be used to identify observations with large residuals.
--->
<p>Let us consider the classical linear-regression model. In that case, residuals should be normally distributed with mean zero and variance defined by the diagonal of hat-matrix <span class="math inline">\(\underline X(\underline X^T \underline X)^{-1}\underline X^T\)</span>. For independent explanatory variables, it should lead to a constant variance of residuals. Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a> presents examples of classical diagnostic plots for linear-regression models that can be used to check whether the assumptions are fulfilled. In fact, the plots in Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a> suggest issues with the assumptions.</p>
<p>In particular, the top-left panel presents the residuals in function of the estimated linear combination of explanatory variables, i.e., predicted (fitted) values. For a well-fitting model, the plot should show points scattered symmetrically around the horizontal straight line at 0. However, the scatter in the top-left panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a> has got a shape of a funnel, reflecting increasing variability of residuals for increasing fitted values. This indicates a violation of the homoscedasticity, i.e., the constancy of variance, assumption. Also, the smoothed line suggests that the mean of residuals becomes increasingly positive for increasing fitted values. This indicates a violation of the assumption that residuals have got zero-mean.</p>
<p>The top-right panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a> presents the scale-location plot, i.e., the plot of <span class="math inline">\(\sqrt{\tilde{r}_i}\)</span> in function of the fitted values <span class="math inline">\(f(\underline{x}_i)\)</span>. For a well-fitting model, the plot should show points scattered symmetrically across the horizontal axis. This is clearly not the case of the plot in Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a>, which indicates a violation of the homoscedasticity assumption.</p>
<p>The bottom-left panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a> presents the plot of standardized residuals in the function of <em>leverage</em>. Leverage is a measure of the distance between <span class="math inline">\(\underline{x}_i\)</span> and the vector of mean values for all explanatory variables <span class="citation">(Kutner et al. <a href="#ref-Kutner2005" role="doc-biblioref">2005</a>)</span>. A large leverage value for the <span class="math inline">\(i\)</span>-th observation, say <span class="math inline">\(l_i\)</span>, indicates that <span class="math inline">\(\underline{x}_i\)</span> is distant from the center of all observed values of the vector of explanatory variables. Importantly, a large leverage value implies that the observation may have an important influence on predicted/fitted values. In fact, for the classical linear-regression model, it can be shown that the predicted sum-of-squares, defined in <a href="modelPerformance.html#eq:PRESS">(15.5)</a>, can be written as</p>
<p><span class="math display" id="eq:leveragePRESS">\[\begin{equation}
PRESS = \sum_{i=1}^{n} (\widehat{y}_{i(-i)} - y_i)^2 =  \sum_{i=1}^{n} \frac{r_i^2}{(1-l_{i})^2}.
\tag{19.3}
\end{equation}\]</span></p>
<p>Thus, <a href="residualDiagnostic.html#eq:leveragePRESS">(19.3)</a> indicates that observations with a large <span class="math inline">\(r_i\)</span> (or <span class="math inline">\(\tilde{r}_i\)</span>) and a large <span class="math inline">\(l_i\)</span> have an important influence on the overall predictive performance of the model. Hence, the plot of standardized residuals in the function of leverage can be used to detect such influential observations. Note that the plot can also be used to check homoscedasticity because, under that assumption, it should show a symmetric scatter of points around the horizontal line at 0. This is not the case of the plot presented in the bottom-left panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a>. Hence, the plot suggests that the assumption is not fulfilled. However, it does not indicate any particular influential observations, which should be located in the upper-right or lower-right corners of the plot. <!---, above the dashed red line. On such charts, usually, areas with Cook's  values exceeding 0.5 are marked with dashed lines. But for the presented data, the leverages are not large, so the whole presented area corresponds to Cook values smaller than 0.5.--></p>
<p>Note that the plot of standardized residuals in function of leverage can also be used to detect observations with large differences between the predicted and observed value of the dependent variable. In particular, given that <span class="math inline">\({\tilde{r}_i}\)</span> should have approximately standard-normal distribution, only about 0.5% of them should be larger, in absolute value, than 2.57. If there is an excess of such observations, this could be taken as a signal of issues with the fit of the model. At least two such observations (59 and 143) are indicated in the plot shown in the bottom-left panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a>.</p>
<p>Finally, the bottom-right panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a> presents an example of a normal quantile-quantile plot. In particular, the vertical axis represents the ordered values of the standardized residuals, whereas the horizontal axis represents the corresponding values expected from the standard normal distribution. If the normality assumption is fulfilled, the plot should show a scatter of points close to the <span class="math inline">\(45^{\circ}\)</span> diagonal. Clearly, this is not the case of the plot in the bottom-right panel of Figure <a href="residualDiagnostic.html#fig:residuals1234">19.1</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:residuals1234"></span>
<img src="figure/residuals1234.png" alt="Diagnostic plots for a linear-regression model. Clockwise from the top-left: residuals in function of fitted values, a scale-location plot, a normal quantile-quantile plot, and a leverage plot. In each panel, indexes of the three most extreme observations are indicated." width="100%" />
<p class="caption">
Figure 19.1: Diagnostic plots for a linear-regression model. Clockwise from the top-left: residuals in function of fitted values, a scale-location plot, a normal quantile-quantile plot, and a leverage plot. In each panel, indexes of the three most extreme observations are indicated.
</p>
</div>
<!--
[TOMASZ: NOT SURE IF THE BELOW IS WORTH INCLUDING. WE DO NOT SEEM TO LOOK AT QQ PLOTS. PERHAPS WE SHOULD?]

For models implying concrete distributional assumptions one can define a generalization of residuals called *pseudo-residuals* [Zucchini, MacDonald, Langrock "Hidden Markov Models for Time Series. An Introduction Using R. (
Second Edition)]. Assume that, according to the model, the dependent variable for the $i$-th observation should have a distribution with the cumulative distribution function $F_i(y)$, i.e., $P(Y_i \leq y) = F_i(y)$. In that case, the *uniform pseudo-residual* is defined as follows:

$$
u_i=F_i(y_i).
$$

If the model correctly describes the distribution of the dependent variable, then the pseudo-residual, obtained by transforming the variable by its cumulative distribution function, should have a uniform distribution on the interval $[0,1]$. A histogram of the estimated residuals could be used to check the uniform-distribution assumption.

Note that a value of $u_i$ close to 0 or 1 indicates that $y_i$ is located in one of the tails of the model-predicted distribution, i.e., it is unlikely from the point of view of the distribution. Excess of such values would indicate a systematic failure of the model to provide good predictions.  

However, uniform pseudo-residuals are not very useful for detection of observations for which model fails to yield good predictions. This is because it is difficult to discriminate between values very close to 0 or 1, like 0.975 and 0.999. For this reason, often, *normal pseudo-residuals* are used. They are defined as follows:

$$
\tilde{u}_i=\Phi^{-1}(u_i),
$$

where $\Phi()$ denotes the cumulative distribution function of the standard normal distribution. If the model is correct, normal pseudo-residuals should have the standard-normal distribution. A quantile-quantile plot of the estimated residuals could be used to check the normal-distribution assumption. Note that, for $u_i=0.975$ and 0.999, we get clearly distinguishable values of $\tilde{u}_i=1.96$ and 3.09, respectively. 

It is worth noting that the normal pseudo-residual measures, in general, the deviation of the observed value of the dependent variable from the model-predicted median of the corresponding distribution. This is because 

\begin{equation}
\tilde{u}_i=0 \rightarrow \Phi^{-1}(u_i)=0  \rightarrow u_i=\Phi(0)=\frac{1}{2} \rightarrow F_i(y_i)=\frac{1}{2}.
(\#eq:pseudomedian)
\end{equation}

The last equality in \@ref(eq:pseudomedian) implies that $y_i$ is equal to the median of the corresponding distribution of the dependent variable. 

Consider, for example, the classical linear-regression model. In this case, $F_i$ is the cumulative distribution function of a normal distribution with mean $f(x_i)$ and variance $\sigma^2$. It follows that the uniform pseudo-residual is equal to

$$
u_i=F_i(y_i)=\Phi\left\{\frac{y_i-f(x_i)}{\sigma}\right\}=\Phi\left(\frac{r_i}{\sigma}\right)=\Phi\left(\tilde{r_i}\right).
$$

If the model correctly captures the distribution of the dependent variable, the standardized residual $\tilde{r}_i$ should follow a standard-normal distribution. Consequently, $u_i$, obtained by transforming $\tilde{r}_i$ by its cumulative distribution function $\Phi()$, should follow a uniform distribution, as required for the uniform pseudo-residual.

On the other hand, the normal pseudo-residual for the linear-regression model is given by

$$
\tilde{u}_i=\Phi^{-1}\{F_i(y_i)\}=\Phi^{-1}\left\{\Phi\left(\frac{r_i}{\sigma}\right)\right\}=\tilde{r_i}.
$$
Thus, in this case, the normal pseudo-residual is simply the standardized residual. Consequently, $\tilde{u}_i$ should follow a standard-normal distribution, as required for the normal pseudo-residual. Moreover, $\tilde{u}_i$ measures the deviation of the observed value of the dependent variable from the model-predicted mean (equal to the median) of the corresponding (normal) distribution.

For a discrete dependent variable, e.g., a count, one can define the *uniform pseudo-residual segments* as follows:

$$
[u^-_i,u^+_i]=[F_i(y^-_i),F_i(y_i)],
$$

where $y^-_i$ is the largest possible value of the dependent variable smaller than $y_i$. Essentially, the length of the interval $[u^-_i,u^+_i]$ is equal to $P(Y_i=y_i)$, the probability of observing $y_i$. Thus, the uniform pseudo-residual segment provides an information on how rare the observed value of the dependent variable is given the corresponding distribution predicted by the model.   

The *normal pseudo-residual segment* is defined as 

$$
[\tilde{u}^-_i,\tilde{u}^+_i]=[\Phi^{-1}\{ F_i(y^-_i)\},\Phi^{-1}\{F_i(y_i)\}].
$$

Essentially, the limits of the interval $[\tilde{u}^-_i,\tilde{u}^+_i]$ are the quantiles of the standard-normal distribution corresponding to $P(Y_i\leq y^-_i)$ and $P(Y_i\leq y_i)$, respectively, so that 

$$
\Phi(\tilde{u}_i)-\Phi(\tilde{u}^-_i)=P(Y_i\leq y_i)-P(Y_i\leq y^-_i)=P(Y_i= y_i).
$$

Furthermore, one can define *normal mid-pseudo-residual* as follows:

$$
\bar{\tilde{u}}_i=\Phi^{-1}\left(\frac{\tilde{u}^-_i+\tilde{u}^+_i}{2}\right).
$$

The normality of estimated mid-pseudo-residuals can be checked by constructing a histogram or a normal quantile-quantile plot.
-->
</div>
<div id="ExampleResidualDiagnostic" class="section level2" number="19.4">
<h2><span class="header-section-number">19.4</span> Example: apartment-prices data</h2>
<p>In this section, we consider the linear-regression model <code>apartments_lm</code> (Section <a href="dataSetsIntro.html#model-Apartments-lr">4.5.1</a>) and the random forest model <code>apartments_rf</code> (Section <a href="dataSetsIntro.html#model-Apartments-rf">4.5.2</a>) for the apartment-prices dataset (Section <a href="dataSetsIntro.html#ApartmentDataset">4.4</a>). Recall that the dependent variable of interest, the price per square meter, is continuous. Thus, we can use residuals <span class="math inline">\(r_i\)</span>, as defined in <a href="residualDiagnostic.html#eq:resid">(19.1)</a>. We compute the residuals for the <code>apartments_test</code> testing dataset (see Section <a href="dataSetsIntro.html#predictionsApartments">4.5.4</a>). It is worth noting that, as it was mentioned in Section <a href="modelPerformance.html#modelPerformanceApartments">15.4.1</a>, RMSE for both models is very similar for that dataset. Thus, overall, the two models could be seen as performing similarly on average.</p>
<p>Figures <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a> and <a href="residualDiagnostic.html#fig:plotResidualBoxplot1">19.3</a> summarize the distribution of residuals for both models. In particular, Figure <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a> presents histograms of residuals, while Figure <a href="residualDiagnostic.html#fig:plotResidualBoxplot1">19.3</a> shows box-and-whisker plots for the absolute value of the residuals.</p>

<div class="figure" style="text-align: center"><span id="fig:plotResidualDensity1"></span>
<img src="ema_files/figure-html/plotResidualDensity1-1.png" alt="Histogram of residuals for the linear-regression model apartments_lm and the random forest model apartments_rf for the apartments_test dataset." width="768" />
<p class="caption">
Figure 19.2: Histogram of residuals for the linear-regression model <code>apartments_lm</code> and the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset.
</p>
</div>
<p>Despite the similar value of RMSE, the distributions of residuals for both models are different. In particular, Figure <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a> indicates that the distribution for the linear-regression model is, in fact, split into two separate, normal-like parts, which may suggest omission of a binary explanatory variable in the model. The two components are located around the values of about -200 and 400. As mentioned in the previous chapters, the reason for this behavior of the residuals is the fact that the model does not capture the non-linear relationship between the price and the year of construction. For instance, Figure <a href="partialDependenceProfiles.html#fig:pdpApartment3">17.8</a> indicates that the relationship between the construction year and the price may be U-shaped. In particular, apartments built between 1940 and 1990 appear to be, on average, cheaper than those built earlier or later.</p>
<p>As seen from Figure <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a>, the distribution of residuals for the random forest model is skewed to the right and multimodal. It seems to be centered at a value closer to zero than the distribution for the linear-regression model, but it shows a larger variation. These conclusions are confirmed by the box-and-whisker plots in Figure <a href="residualDiagnostic.html#fig:plotResidualBoxplot1">19.3</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:plotResidualBoxplot1"></span>
<img src="ema_files/figure-html/plotResidualBoxplot1-1.png" alt="Box-and-whisker plots of the absolute values of the residuals of the linear-regression model apartments_lm and the random forest model apartments_rf for the apartments_test dataset. The dots indicate the mean value that corresponds to root-mean-squared-error." width="80%" />
<p class="caption">
Figure 19.3: Box-and-whisker plots of the absolute values of the residuals of the linear-regression model <code>apartments_lm</code> and the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset. The dots indicate the mean value that corresponds to root-mean-squared-error.
</p>
</div>
<p>The plots in Figures <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a> and <a href="residualDiagnostic.html#fig:plotResidualBoxplot1">19.3</a> suggest that the residuals for the random forest model are more frequently smaller than the residuals for the linear-regression model. However, a small fraction of the random forest-model residuals is very large and it is due to them that the RMSE is comparable for the two models.</p>
<p>In the remainder of the section, we focus on the random forest model.</p>
<p>Figure <a href="residualDiagnostic.html#fig:plotResidual1">19.4</a> shows a scatter plot of residuals (vertical axis) in function of the observed (horizontal axis) values of the dependent variable. For a “perfect” predictive model, we would expect the horizontal line at zero. For a “good” model, we would like to see a symmetric scatter of points around the horizontal line at zero, indicating random deviations of predictions from the observed values. The plot in Figure <a href="residualDiagnostic.html#fig:plotResidual1">19.4</a> shows that, for the large observed values of the dependent variable, the residuals are positive, while for small values they are negative. This trend is clearly captured by the smoothed curve included in the graph. Thus, the plot suggests that the predictions are shifted (biased) towards the average.</p>

<div class="figure" style="text-align: center"><span id="fig:plotResidual1"></span>
<img src="ema_files/figure-html/plotResidual1-1.png" alt="Residuals and observed values of the dependent variable for the random forest model apartments_rf for the apartments_test dataset." width="80%" />
<p class="caption">
Figure 19.4: Residuals and observed values of the dependent variable for the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset.
</p>
</div>
<p>The shift towards the average can also be seen from Figure <a href="residualDiagnostic.html#fig:plotPrediction1">19.5</a> that shows a scatter plot of the predicted (vertical axis) and observed (horizontal axis) values of the dependent variable. For a “perfectly” fitting model we would expect a diagonal line (indicated in red). The plot shows that, for large observed values of the dependent variable, the predictions are smaller than the observed values, with an opposite trend for the small observed values of the dependent variable.</p>

<div class="figure" style="text-align: center"><span id="fig:plotPrediction1"></span>
<img src="ema_files/figure-html/plotPrediction1-1.png" alt="Predicted and observed values of the dependent variable for the random forest model apartments_rf for the apartments_test dataset. The red line indicates the diagonal." width="80%" />
<p class="caption">
Figure 19.5: Predicted and observed values of the dependent variable for the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset. The red line indicates the diagonal.
</p>
</div>
<p>Figure <a href="residualDiagnostic.html#fig:plotResidual2">19.6</a> shows an index plot of residuals, i.e., their scatter plot in function of an (arbitrary) identifier of the observation (horizontal axis). The plot indicates an asymmetric distribution of residuals around zero, as there is an excess of large positive (larger than 500) residuals without a corresponding fraction of negative values. This can be linked to the right-skewed distribution seen in Figures <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a> and <a href="residualDiagnostic.html#fig:plotResidualBoxplot1">19.3</a> for the random forest model.</p>

<div class="figure" style="text-align: center"><span id="fig:plotResidual2"></span>
<img src="ema_files/figure-html/plotResidual2-1.png" alt="Index plot of residuals for the random forest model apartments_rf for the apartments_test dataset." width="80%" />
<p class="caption">
Figure 19.6: Index plot of residuals for the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset.
</p>
</div>
<p>Figure <a href="residualDiagnostic.html#fig:plotResidual3">19.7</a> shows a scatter plot of residuals (vertical axis) in function of the predicted (horizontal axis) value of the dependent variable. For a “good” model, we would like to see a symmetric scatter of points around the horizontal line at zero. The plot in Figure <a href="residualDiagnostic.html#fig:plotResidual3">19.7</a>, as the one in Figure <a href="residualDiagnostic.html#fig:plotResidual1">19.4</a>, suggests that the predictions are shifted (biased) towards the average.</p>

<div class="figure" style="text-align: center"><span id="fig:plotResidual3"></span>
<img src="ema_files/figure-html/plotResidual3-1.png" alt="Residuals and predicted values of the dependent variable for the random forest model apartments_rf for the apartments_test dataset." width="55%" />
<p class="caption">
Figure 19.7: Residuals and predicted values of the dependent variable for the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset.
</p>
</div>
<p>The random forest model, as the linear-regression model, assumes that residuals should be homoscedastic, i.e., that they should have a constant variance. Figure <a href="residualDiagnostic.html#fig:plotScaleLocation1">19.8</a> presents a variant of the scale-location plot of residuals, i.e., a scatter plot of the absolute value of residuals (vertical axis) in function of the predicted values of the dependent variable (horizontal axis). The plot includes a smoothed line capturing the average trend. For homoscedastic residuals, we would expect a symmetric scatter around a horizontal line; the smoothed trend should be also horizontal. The plot in Figure <a href="residualDiagnostic.html#fig:plotScaleLocation1">19.8</a> deviates from the expected pattern and indicates that the variability of the residuals depends on the (predicted) value of the dependent variable.</p>
<p>For models like linear regression, such heteroscedasticity of the residuals would be worrying. In random forest models, however, it may be less of concern. This is beacuse it may occur due to the fact that the models reduce variability of residuals by introducing a bias (towards the average). Thus, it is up to the developer of a model to decide whether such a bias (in our example, for the cheapest and most expensive apartments) is a desirable price to pay for the reduced residual variability.</p>

<div class="figure" style="text-align: center"><span id="fig:plotScaleLocation1"></span>
<img src="ema_files/figure-html/plotScaleLocation1-1.png" alt="The scale-location plot of residuals for the random forest model apartments_rf for the apartments_test dataset." width="55%" />
<p class="caption">
Figure 19.8: The scale-location plot of residuals for the random forest model <code>apartments_rf</code> for the <code>apartments_test</code> dataset.
</p>
</div>
</div>
<div id="ProsConsResidualDiagnostic" class="section level2" number="19.5">
<h2><span class="header-section-number">19.5</span> Pros and cons</h2>
<p>Diagnostic methods based on residuals are a very useful tool in model exploration. They allow identifying different types of issues with model fit or prediction, such as problems with distributional assumptions or with the assumed structure of the model (in terms of the selection of the explanatory variables and their form). The methods can help in detecting groups of observations for which a model’s predictions are biased and, hence, require inspection.</p>
<p>A potential complication related to the use of residual diagnostics is that they rely on graphical displays. Hence, for a proper evaluation of a model, one may have to construct and review many graphs. Moreover, interpretation of the patterns seen in graphs may not be straightforward. Also, it may not be immediately obvious which element of the model may have to be changed to remove the potential issue with the model fit or predictions.</p>
</div>
<div id="RcodeResidualDiagnostic" class="section level2" number="19.6">
<h2><span class="header-section-number">19.6</span> Code snippets for R</h2>
<p>In this section, we present diagnostic plots as implemented in the <code>DALEX</code> package for R. The package covers all plots and methods presented in this chapter. Similar functions can be found in packages <code>auditor</code> <span class="citation">(Gosiewska and Biecek <a href="#ref-R-auditor" role="doc-biblioref">2018</a>)</span>, <code>rms</code> <span class="citation">(Harrell Jr <a href="#ref-rms" role="doc-biblioref">2018</a>)</span>, and <code>stats</code> <span class="citation">(Faraway <a href="#ref-Faraway02practicalregression" role="doc-biblioref">2002</a>)</span>.</p>
<p>For illustration purposes, we will show how to create the plots shown in Section <a href="residualDiagnostic.html#ExampleResidualDiagnostic">19.4</a> for the linear-regression model <code>apartments_lm</code> (Section <a href="dataSetsIntro.html#model-Apartments-lr">4.5.1</a>) and the random forest model <code>apartments_rf</code> (Section <a href="dataSetsIntro.html#model-Apartments-rf">4.5.2</a>) for the <code>apartments_test</code> dataset (Section <a href="dataSetsIntro.html#ApartmentDataset">4.4</a>).</p>
<p>We first load the two models via the <code>archivist</code> hooks, as listed in Section <a href="dataSetsIntro.html#ListOfModelsApartments">4.5.6</a>. Subsequently, we construct the corresponding explainers by using function <code>explain()</code> from the <code>DALEX</code> package (see Section <a href="dataSetsIntro.html#ExplainersTitanicRCode">4.2.6</a>). Note that we use the <code>apartments_test</code> data frame without the first column, i.e., the <em>m2.price</em> variable, in the <code>data</code> argument. This will be the dataset to which the model will be applied. The <em>m2.price</em> variable is explicitly specified as the dependent variable in the <code>y</code> argument. We also load the <code>randomForest</code> package, as it is important to have the corresponding <code>predict()</code> function available for the random forest model.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="residualDiagnostic.html#cb231-1"></a><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</span>
<span id="cb231-2"><a href="residualDiagnostic.html#cb231-2"></a>model_apart_lm &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="st"> </span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/55f19&quot;</span>)</span>
<span id="cb231-3"><a href="residualDiagnostic.html#cb231-3"></a>explain_apart_lm &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">explain</span>(<span class="dt">model =</span> model_apart_lm, </span>
<span id="cb231-4"><a href="residualDiagnostic.html#cb231-4"></a>                           <span class="dt">data    =</span> apartments_test[,<span class="op">-</span><span class="dv">1</span>], </span>
<span id="cb231-5"><a href="residualDiagnostic.html#cb231-5"></a>                           <span class="dt">y       =</span> apartments_test<span class="op">$</span>m2.price, </span>
<span id="cb231-6"><a href="residualDiagnostic.html#cb231-6"></a>                           <span class="dt">label   =</span> <span class="st">&quot;Linear Regression&quot;</span>)</span>
<span id="cb231-7"><a href="residualDiagnostic.html#cb231-7"></a><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</span>
<span id="cb231-8"><a href="residualDiagnostic.html#cb231-8"></a>model_apart_rf &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="st"> </span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/fe7a5&quot;</span>)</span>
<span id="cb231-9"><a href="residualDiagnostic.html#cb231-9"></a>explain_apart_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">explain</span>(<span class="dt">model =</span> model_apart_rf, </span>
<span id="cb231-10"><a href="residualDiagnostic.html#cb231-10"></a>                           <span class="dt">data    =</span> apartments_test[,<span class="op">-</span><span class="dv">1</span>], </span>
<span id="cb231-11"><a href="residualDiagnostic.html#cb231-11"></a>                           <span class="dt">y       =</span> apartments_test<span class="op">$</span>m2.price, </span>
<span id="cb231-12"><a href="residualDiagnostic.html#cb231-12"></a>                           <span class="dt">label   =</span> <span class="st">&quot;Random Forest&quot;</span>)</span></code></pre></div>
<p>For exploration of residuals, <code>DALEX</code> includes two useful functions. The <code>model_performance()</code> function can be used to evaluate the distribution of the residuals. On the other hand, the <code>model_diagnostics()</code> function is suitable for investigating the relationship between residuals and other variables.</p>
<p>The <code>model_performance()</code> function was already introduced in Section <a href="modelPerformance.html#modelPerformanceR">15.6</a>. Application of the function to an explainer-object returns an object of class “model_performance” which includes, in addition to selected model-performance measures, a data frame containing the observed and predicted values of the dependent variable together with the residuals.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="residualDiagnostic.html#cb232-1"></a>mr_lm &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">model_performance</span>(explain_apart_lm)</span>
<span id="cb232-2"><a href="residualDiagnostic.html#cb232-2"></a>mr_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">model_performance</span>(explain_apart_rf)</span></code></pre></div>
<p>By applying the <code>plot()</code> function to a “model_performance”-class object we can obtain various plots. The required type of the plot is specified with the help of the <code>geom</code> argument (see Section <a href="modelPerformance.html#modelPerformanceR">15.6</a>). In particular, specifying <code>geom = "histogram"</code> results in a histogram of residuals. In the code below, we apply the <code>plot()</code> function to the “model_performance”-class objects for the linear-regression and random forest models. As a result, we automatically get a single graph with the histograms of residuals for the two models. The resulting graph is shown in Figure <a href="residualDiagnostic.html#fig:plotResidualDensity1">19.2</a></p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="residualDiagnostic.html#cb233-1"></a><span class="kw">library</span>(<span class="st">&quot;ggplot2&quot;</span>)</span>
<span id="cb233-2"><a href="residualDiagnostic.html#cb233-2"></a><span class="kw">plot</span>(mr_lm, mr_rf, <span class="dt">geom =</span> <span class="st">&quot;histogram&quot;</span>) </span></code></pre></div>
<p>The box-and-whisker plots of the residuals for the two models can be constructed by applying the <code>geom = "boxplot"</code> argument. The resulting graph is shown in Figure <a href="residualDiagnostic.html#fig:plotResidualBoxplot1">19.3</a>,</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="residualDiagnostic.html#cb234-1"></a><span class="kw">plot</span>(mr_lm, mr_rf, <span class="dt">geom =</span> <span class="st">&quot;boxplot&quot;</span>)</span></code></pre></div>
<p>Function <code>model_diagnostics()</code> can be applied to an explainer-object to directly compute residuals. The resulting object of class “model_diagnostics” is a data frame in which the residuals and their absolute values are combined with the observed and predicted values of the dependent variable and the observed values of the explanatory variables. The data frame can be used to create various plots illustrating the relationship between residuals and the other variables.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="residualDiagnostic.html#cb235-1"></a>md_lm &lt;-<span class="st"> </span><span class="kw">model_diagnostics</span>(explain_apart_lm)</span>
<span id="cb235-2"><a href="residualDiagnostic.html#cb235-2"></a>md_rf &lt;-<span class="st"> </span><span class="kw">model_diagnostics</span>(explain_apart_rf)</span></code></pre></div>
<p>Application of the <code>plot()</code> function to a <code>model_diagnostics</code>-class object produces, by default, a scatter plot of residuals (on the vertical axis) in function of the predicted values of the dependent variable (on the horizontal axis). By using arguments <code>variable</code> and <code>yvariable</code>, it is possible to specify plots with other variables used for the horizontal and vertical axes, respectively. The two arguments accept, apart from the names of the explanatory variables, the following values:</p>
<ul>
<li><code>"y"</code> for the dependent variable,</li>
<li><code>"y_hat"</code> for the predicted value of the dependent variable,</li>
<li><code>"obs"</code> for the identifiers of observations,</li>
<li><code>"residuals"</code> for residuals,</li>
<li><code>"abs_residuals"</code> for absolute values of residuals.</li>
</ul>
<p>Thus, to obtain the plot of residuals in function of the observed values of the dependent variable, as shown in Figure <a href="residualDiagnostic.html#fig:plotResidual1">19.4</a>, the syntax presented below can be used.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="residualDiagnostic.html#cb236-1"></a><span class="kw">plot</span>(md_rf, <span class="dt">variable =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">yvariable =</span> <span class="st">&quot;residuals&quot;</span>) </span></code></pre></div>
<p>To produce Figure <a href="residualDiagnostic.html#fig:plotPrediction1">19.5</a>, we have got to use the predicted values of the dependent variable on the vertical axis. This is achieved by specifying the <code>yvariable = "y_hat"</code> argument. We add the diagonal reference line to the plot by using the <code>geom_abline()</code> function.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="residualDiagnostic.html#cb237-1"></a><span class="kw">plot</span>(md_rf, <span class="dt">variable =</span> <span class="st">&quot;y&quot;</span>, <span class="dt">yvariable =</span> <span class="st">&quot;y_hat&quot;</span>) <span class="op">+</span></span>
<span id="cb237-2"><a href="residualDiagnostic.html#cb237-2"></a><span class="st">      </span><span class="kw">geom_abline</span>(<span class="dt">colour =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>Figure <a href="residualDiagnostic.html#fig:plotResidual2">19.6</a> presents an index plot of residuals, i.e., residuals (on the vertical axis) in function of identifiers of individual observations (on the horizontal axis). Toward this aim, we use the <code>plot()</code> function call as below.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="residualDiagnostic.html#cb238-1"></a><span class="kw">plot</span>(md_rf, <span class="dt">variable =</span> <span class="st">&quot;ids&quot;</span>, <span class="dt">yvariable =</span> <span class="st">&quot;residuals&quot;</span>)</span></code></pre></div>
<p>Finally, Figure <a href="residualDiagnostic.html#fig:plotScaleLocation1">19.8</a> presents a variant of the scale-location plot, with absolute values of the residuals shown on the vertical scale and the predicted values of the dependent variable on the horizontal scale. The plot is obtained with the syntax shown below.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="residualDiagnostic.html#cb239-1"></a><span class="kw">plot</span>(md_rf, <span class="dt">variable =</span> <span class="st">&quot;y_hat&quot;</span>, <span class="dt">yvariable =</span> <span class="st">&quot;abs_residuals&quot;</span>)</span></code></pre></div>
<p>Note that, by default, all plots produced by applying the <code>plot()</code> function to a “model_diagnostics”-class object include a smoothed curve. To exclude the curve from a plot, one can use the argument <code>smooth = FALSE</code>.</p>
</div>
<div id="PythoncodeResidualDiagnostic" class="section level2" number="19.7">
<h2><span class="header-section-number">19.7</span> Code snippets for Python</h2>
<p>In this section, we use the <code>dalex</code> library for Python. The package covers all methods presented in this chapter. But, as mentioned in Section <a href="residualDiagnostic.html#IntroResidualDiagnostic">19.1</a>, residuals are a classical model-diagnostics tool. Thus, essentially any model-related library includes functions that allow calculation and plotting of residuals.</p>
<p>For illustration purposes, we use the <code>apartments_rf</code> random forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-Apartments-python-rf">4.6.2</a>. Recall that the model is developed to predict the price per square meter of an apartment in Warsaw.</p>
<p>In the first step we create an explainer-object that will provide a uniform interface for the predictive model. We use the <code>Explainer()</code> constructor for this purpose.</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb240-1"><a href="residualDiagnostic.html#cb240-1"></a><span class="im">import</span> dalex <span class="im">as</span> dx</span>
<span id="cb240-2"><a href="residualDiagnostic.html#cb240-2"></a>apartments_rf_exp <span class="op">=</span> dx.Explainer(apartments_rf, X, y,</span>
<span id="cb240-3"><a href="residualDiagnostic.html#cb240-3"></a>      label <span class="op">=</span> <span class="st">&quot;Apartments RF Pipeline&quot;</span>)</span></code></pre></div>
<p>The function that calculates residuals, absolute residuals and observation ids is <code>model_diagnostics()</code>.</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="residualDiagnostic.html#cb241-1"></a>md_rf <span class="op">=</span> apartments_rf_exp.model_diagnostics()</span>
<span id="cb241-2"><a href="residualDiagnostic.html#cb241-2"></a>md_rf.result</span></code></pre></div>
<p><img src="figure/python_model_diagnostics_1.png" width="100%" /></p>
<p>The results can be visualised by applying the <code>plot()</code> method. Figure <a href="residualDiagnostic.html#fig:examplePythonMDiagnostics2">19.9</a> presents the created plot.</p>
<div class="sourceCode" id="cb242"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb242-1"><a href="residualDiagnostic.html#cb242-1"></a>md_rf.plot()</span></code></pre></div>

<div class="figure" style="text-align: center"><span id="fig:examplePythonMDiagnostics2"></span>
<img src="figure/python_model_diagnostics_2.png" alt="Residuals versus predicted values for the random forest model for the Apartments data." width="70%" />
<p class="caption">
Figure 19.9: Residuals versus predicted values for the random forest model for the Apartments data.
</p>
</div>
<p>In the <code>plot()</code> function we can specify what shall be presented on horizontal and vertical axes. Possible values are columns in the <code>md_rf.result</code> data frame, i.e. <code>residuals</code>, <code>abs_residuals</code>, <code>y</code>, <code>y_hat</code>, <code>ids</code> and variable names.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb243-1"><a href="residualDiagnostic.html#cb243-1"></a>mp_rf.plot(variable <span class="op">=</span> <span class="st">&quot;ids&quot;</span>, yvariable <span class="op">=</span> <span class="st">&quot;abs_residuals&quot;</span>)</span></code></pre></div>

<div class="figure" style="text-align: center"><span id="fig:examplePythonMDiagnostics3"></span>
<img src="figure/python_model_diagnostics_3.png" alt="Absolute residuals versus indices of corresponding observations for the random forest model for the Apartments data." width="70%" />
<p class="caption">
Figure 19.10: Absolute residuals versus indices of corresponding observations for the random forest model for the Apartments data.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Faraway02practicalregression">
<p>Faraway, Julian. 2002. <em>Practical Regression and Anova Using R</em>. <a href="https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf">https://cran.r-project.org/doc/contrib/Faraway-PRA.pdf</a>.</p>
</div>
<div id="ref-Galecki2013">
<p>Galecki, A., and T. Burzykowski. 2013. <em>Linear Mixed-Effects Models Using R: A Step-by-Step Approach</em>. Springer Publishing Company, Incorporated.</p>
</div>
<div id="ref-R-auditor">
<p>Gosiewska, Alicja, and Przemyslaw Biecek. 2018. <em>auditor: Model Audit - Verification, Validation, and Error Analysis</em>. <a href="https://CRAN.R-project.org/package=auditor">https://CRAN.R-project.org/package=auditor</a>.</p>
</div>
<div id="ref-rms">
<p>Harrell Jr, Frank E. 2018. <em>Rms: Regression Modeling Strategies</em>. <a href="https://CRAN.R-project.org/package=rms">https://CRAN.R-project.org/package=rms</a>.</p>
</div>
<div id="ref-Kutner2005">
<p>Kutner, M. H., C. J. Nachtsheim, J. Neter, and W. Li. 2005. <em>Applied Linear Statistical Models</em>. New York: McGraw-Hill/Irwin.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="accumulatedLocalProfiles.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summaryModelLevel.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
