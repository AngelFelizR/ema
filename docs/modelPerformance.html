<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>15 Model-performance Measures | Explanatory Model Analysis</title>
  <meta name="description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="15 Model-performance Measures | Explanatory Model Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="figure/front4.png" />
  <meta property="og:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="github-repo" content="pbiecek/ema" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="15 Model-performance Measures | Explanatory Model Analysis" />
  
  <meta name="twitter:description" content="This book introduces unified language for exploration, explanation and examination of predictive machine learning models." />
  <meta name="twitter:image" content="figure/front4.png" />

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski" />


<meta name="date" content="2020-12-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelLevelExploration.html"/>
<link rel="next" href="featureImportance.html"/>
<script src="libs/header-attrs-2.4/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/ema/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>
<style>
.figure {
   padding:40px 0px;
}
</style>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><span style="font-size: large">Explanatory Model Analysis</span><br/>Explore, Explain, and Examine<br/>Predictive Models</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>I Introduction</b></span></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.1</b> The aim of the book</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#three-single-laws"><i class="fa fa-check"></i><b>1.2</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#teminology"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#glassblack"><i class="fa fa-check"></i><b>1.4</b> Black-box models and glass-box models</a></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#agnosticspecific"><i class="fa fa-check"></i><b>1.5</b> Model-agnostic and model-specific approach</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#bookstructure"><i class="fa fa-check"></i><b>1.6</b> The structure of the book</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#whatisinthebook"><i class="fa fa-check"></i><b>1.7</b> What is included in this book and what is not</a></li>
<li class="chapter" data-level="1.8" data-path="introduction.html"><a href="introduction.html#thanksto"><i class="fa fa-check"></i><b>1.8</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html"><i class="fa fa-check"></i><b>2</b> Model Development</a>
<ul>
<li class="chapter" data-level="2.1" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPIntro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#MDPprocess"><i class="fa fa-check"></i><b>2.2</b> Model-development process</a></li>
<li class="chapter" data-level="2.3" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#notation"><i class="fa fa-check"></i><b>2.3</b> Notation</a></li>
<li class="chapter" data-level="2.4" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#dataunderstanding"><i class="fa fa-check"></i><b>2.4</b> Data understanding</a></li>
<li class="chapter" data-level="2.5" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#fitting"><i class="fa fa-check"></i><b>2.5</b> Model assembly (fitting)</a></li>
<li class="chapter" data-level="2.6" data-path="modelDevelopmentProcess.html"><a href="modelDevelopmentProcess.html#validation"><i class="fa fa-check"></i><b>2.6</b> Model audit</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="do-it-yourself.html"><a href="do-it-yourself.html"><i class="fa fa-check"></i><b>3</b> Do-it-yourself</a>
<ul>
<li class="chapter" data-level="3.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#doItYourselfWithR"><i class="fa fa-check"></i><b>3.1</b> Do-it-yourself with R</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#what-to-install"><i class="fa fa-check"></i><b>3.1.1</b> What to install?</a></li>
<li class="chapter" data-level="3.1.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#infoDALEX"><i class="fa fa-check"></i><b>3.1.2</b> How to work with <code>DALEX</code>?</a></li>
<li class="chapter" data-level="3.1.3" data-path="do-it-yourself.html"><a href="do-it-yourself.html#how-to-work-with-archivist"><i class="fa fa-check"></i><b>3.1.3</b> How to work with <code>archivist</code>?</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#doItYourselfWithPython"><i class="fa fa-check"></i><b>3.2</b> Do-it-yourself with Python</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="do-it-yourself.html"><a href="do-it-yourself.html#what-to-install-1"><i class="fa fa-check"></i><b>3.2.1</b> What to install?</a></li>
<li class="chapter" data-level="3.2.2" data-path="do-it-yourself.html"><a href="do-it-yourself.html#infoDALEXpy"><i class="fa fa-check"></i><b>3.2.2</b> How to work with <code>dalex</code>?</a></li>
<li class="chapter" data-level="3.2.3" data-path="do-it-yourself.html"><a href="do-it-yourself.html#code-snippets-for-python"><i class="fa fa-check"></i><b>3.2.3</b> Code snippets for Python</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html"><i class="fa fa-check"></i><b>4</b> Datasets and Models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>4.1</b> Sinking of the RMS Titanic</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-titanic"><i class="fa fa-check"></i><b>4.1.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-rms-titanic-snippets-for-r"><i class="fa fa-check"></i><b>4.2</b> Models for RMS Titanic, snippets for R</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-lmr"><i class="fa fa-check"></i><b>4.2.1</b> Logistic regression model</a></li>
<li class="chapter" data-level="4.2.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-rf"><i class="fa fa-check"></i><b>4.2.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.2.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-gbm"><i class="fa fa-check"></i><b>4.2.3</b> Gradient boosting model</a></li>
<li class="chapter" data-level="4.2.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-svm"><i class="fa fa-check"></i><b>4.2.4</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.2.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic"><i class="fa fa-check"></i><b>4.2.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.2.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicRCode"><i class="fa fa-check"></i><b>4.2.6</b> Models’ explainers</a></li>
<li class="chapter" data-level="4.2.7" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsTitanic"><i class="fa fa-check"></i><b>4.2.7</b> List of model-objects</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-rms-titanic-snippets-for-python"><i class="fa fa-check"></i><b>4.3</b> Models for RMS Titanic, snippets for Python</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-lr"><i class="fa fa-check"></i><b>4.3.1</b> Logistic regression model</a></li>
<li class="chapter" data-level="4.3.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-rf"><i class="fa fa-check"></i><b>4.3.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.3.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-gbm"><i class="fa fa-check"></i><b>4.3.3</b> Gradient boosting model</a></li>
<li class="chapter" data-level="4.3.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-titanic-python-svm"><i class="fa fa-check"></i><b>4.3.4</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.3.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-titanic-python"><i class="fa fa-check"></i><b>4.3.5</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.3.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersTitanicPythonCode"><i class="fa fa-check"></i><b>4.3.6</b> Models’ explainers</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>4.4</b> Apartment prices</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#exploration-apartments"><i class="fa fa-check"></i><b>4.4.1</b> Data exploration</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-apartment-prices-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Models for apartment prices, snippets for R</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-lr"><i class="fa fa-check"></i><b>4.5.1</b> Linear regression model</a></li>
<li class="chapter" data-level="4.5.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-rf"><i class="fa fa-check"></i><b>4.5.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.5.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-svm"><i class="fa fa-check"></i><b>4.5.3</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.5.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictionsApartments"><i class="fa fa-check"></i><b>4.5.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.5.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsRCode"><i class="fa fa-check"></i><b>4.5.5</b> Models’ explainers</a></li>
<li class="chapter" data-level="4.5.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ListOfModelsApartments"><i class="fa fa-check"></i><b>4.5.6</b> List of model-objects</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#models-for-apartment-prices-snippets-for-python"><i class="fa fa-check"></i><b>4.6</b> Models for apartment prices, snippets for Python</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-lr"><i class="fa fa-check"></i><b>4.6.1</b> Linear regression model</a></li>
<li class="chapter" data-level="4.6.2" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-rf"><i class="fa fa-check"></i><b>4.6.2</b> Random forest model</a></li>
<li class="chapter" data-level="4.6.3" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#model-Apartments-python-svm"><i class="fa fa-check"></i><b>4.6.3</b> Support vector machine model</a></li>
<li class="chapter" data-level="4.6.4" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#predictions-apartments-python"><i class="fa fa-check"></i><b>4.6.4</b> Models’ predictions</a></li>
<li class="chapter" data-level="4.6.5" data-path="dataSetsIntro.html"><a href="dataSetsIntro.html#ExplainersApartmentsPythonCode"><i class="fa fa-check"></i><b>4.6.5</b> Models’ explainers</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Instance Level</b></span></li>
<li class="chapter" data-level="5" data-path="InstanceLevelExploration.html"><a href="InstanceLevelExploration.html"><i class="fa fa-check"></i><b>5</b> Introduction to Instance-level Exploration</a></li>
<li class="chapter" data-level="6" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>6</b> Break-down Plots for Additive Attributions</a>
<ul>
<li class="chapter" data-level="6.1" data-path="breakDown.html"><a href="breakDown.html#BDIntroduction"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="breakDown.html"><a href="breakDown.html#BDIntuition"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="breakDown.html"><a href="breakDown.html#BDMethod"><i class="fa fa-check"></i><b>6.3</b> Method</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="breakDown.html"><a href="breakDown.html#BDMethodLin"><i class="fa fa-check"></i><b>6.3.1</b> Break-down for linear models</a></li>
<li class="chapter" data-level="6.3.2" data-path="breakDown.html"><a href="breakDown.html#BDMethodGen"><i class="fa fa-check"></i><b>6.3.2</b> Break-down for a general case</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="breakDown.html"><a href="breakDown.html#BDExample"><i class="fa fa-check"></i><b>6.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="6.5" data-path="breakDown.html"><a href="breakDown.html#BDProsCons"><i class="fa fa-check"></i><b>6.5</b> Pros and cons</a></li>
<li class="chapter" data-level="6.6" data-path="breakDown.html"><a href="breakDown.html#BDR"><i class="fa fa-check"></i><b>6.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="breakDown.html"><a href="breakDown.html#basic-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>6.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="6.6.2" data-path="breakDown.html"><a href="breakDown.html#advanced-use-of-the-predict_parts-function"><i class="fa fa-check"></i><b>6.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="breakDown.html"><a href="breakDown.html#BDPython"><i class="fa fa-check"></i><b>6.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>7</b> Break-down Plots for Interactions</a>
<ul>
<li class="chapter" data-level="7.1" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDIntuition"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDMethod"><i class="fa fa-check"></i><b>7.2</b> Method</a></li>
<li class="chapter" data-level="7.3" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDExample"><i class="fa fa-check"></i><b>7.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="7.4" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDProsCons"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDRcode"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a></li>
<li class="chapter" data-level="7.6" data-path="iBreakDown.html"><a href="iBreakDown.html#iBDPythonCode"><i class="fa fa-check"></i><b>7.6</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>8</b> Shapley Additive Explanations (SHAP) for Average Attributions</a>
<ul>
<li class="chapter" data-level="8.1" data-path="shapley.html"><a href="shapley.html#SHAPIntuition"><i class="fa fa-check"></i><b>8.1</b> Intuition</a></li>
<li class="chapter" data-level="8.2" data-path="shapley.html"><a href="shapley.html#SHAPMethod"><i class="fa fa-check"></i><b>8.2</b> Method</a></li>
<li class="chapter" data-level="8.3" data-path="shapley.html"><a href="shapley.html#SHAPExample"><i class="fa fa-check"></i><b>8.3</b> Example: Titanic data</a></li>
<li class="chapter" data-level="8.4" data-path="shapley.html"><a href="shapley.html#SHAProsCons"><i class="fa fa-check"></i><b>8.4</b> Pros and cons</a></li>
<li class="chapter" data-level="8.5" data-path="shapley.html"><a href="shapley.html#SHAPRcode"><i class="fa fa-check"></i><b>8.5</b> Code snippets for R</a></li>
<li class="chapter" data-level="8.6" data-path="shapley.html"><a href="shapley.html#SHAPPythonCode"><i class="fa fa-check"></i><b>8.6</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>9</b> Local Interpretable Model-agnostic Explanations (LIME)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="LIME.html"><a href="LIME.html#LIMEIntroduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="LIME.html"><a href="LIME.html#LIMEIntuition"><i class="fa fa-check"></i><b>9.2</b> Intuition</a></li>
<li class="chapter" data-level="9.3" data-path="LIME.html"><a href="LIME.html#LIMEMethod"><i class="fa fa-check"></i><b>9.3</b> Method</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="LIME.html"><a href="LIME.html#LIMErepr"><i class="fa fa-check"></i><b>9.3.1</b> Interpretable data representation</a></li>
<li class="chapter" data-level="9.3.2" data-path="LIME.html"><a href="LIME.html#LIMEsample"><i class="fa fa-check"></i><b>9.3.2</b> Sampling around the instance of interest</a></li>
<li class="chapter" data-level="9.3.3" data-path="LIME.html"><a href="LIME.html#LIMEglas"><i class="fa fa-check"></i><b>9.3.3</b> Fitting the glass-box model</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="LIME.html"><a href="LIME.html#LIMEExample"><i class="fa fa-check"></i><b>9.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="9.5" data-path="LIME.html"><a href="LIME.html#LIMEProsCons"><i class="fa fa-check"></i><b>9.5</b> Pros and cons</a></li>
<li class="chapter" data-level="9.6" data-path="LIME.html"><a href="LIME.html#LIMERcode"><i class="fa fa-check"></i><b>9.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="LIME.html"><a href="LIME.html#LIMERcodelime"><i class="fa fa-check"></i><b>9.6.1</b> The <code>lime</code> package</a></li>
<li class="chapter" data-level="9.6.2" data-path="LIME.html"><a href="LIME.html#LIMERcodelocMod"><i class="fa fa-check"></i><b>9.6.2</b> The <code>localModel</code> package</a></li>
<li class="chapter" data-level="9.6.3" data-path="LIME.html"><a href="LIME.html#LIMERcodeiml"><i class="fa fa-check"></i><b>9.6.3</b> The <code>iml</code> package</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="LIME.html"><a href="LIME.html#LIMEPythoncode"><i class="fa fa-check"></i><b>9.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>10</b> Ceteris-paribus Profiles</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntro"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPIntuition"><i class="fa fa-check"></i><b>10.2</b> Intuition</a></li>
<li class="chapter" data-level="10.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPMethod"><i class="fa fa-check"></i><b>10.3</b> Method</a></li>
<li class="chapter" data-level="10.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPExample"><i class="fa fa-check"></i><b>10.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="10.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPProsCons"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPR"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#basic-use-of-the-predict_profile-function"><i class="fa fa-check"></i><b>10.6.1</b> Basic use of the <code>predict_profile()</code> function</a></li>
<li class="chapter" data-level="10.6.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#advanced-use-of-the-predict_profile-function"><i class="fa fa-check"></i><b>10.6.2</b> Advanced use of the <code>predict_profile()</code> function</a></li>
<li class="chapter" data-level="10.6.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#comparison-of-models-champion-challenger"><i class="fa fa-check"></i><b>10.6.3</b> Comparison of models (champion-challenger)</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#CPPython"><i class="fa fa-check"></i><b>10.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>11</b> Ceteris-paribus Oscillations</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntro"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscIntuition"><i class="fa fa-check"></i><b>11.2</b> Intuition</a></li>
<li class="chapter" data-level="11.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscMethod"><i class="fa fa-check"></i><b>11.3</b> Method</a></li>
<li class="chapter" data-level="11.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscExample"><i class="fa fa-check"></i><b>11.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="11.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscProsCons"><i class="fa fa-check"></i><b>11.5</b> Pros and cons</a></li>
<li class="chapter" data-level="11.6" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscR"><i class="fa fa-check"></i><b>11.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#basic-use-of-the-predict_parts-function-1"><i class="fa fa-check"></i><b>11.6.1</b> Basic use of the <code>predict_parts()</code> function</a></li>
<li class="chapter" data-level="11.6.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#advanced-use-of-the-predict_parts-function-1"><i class="fa fa-check"></i><b>11.6.2</b> Advanced use of the <code>predict_parts()</code> function</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#CPOscPython"><i class="fa fa-check"></i><b>11.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="localDiagnostics.html"><a href="localDiagnostics.html"><i class="fa fa-check"></i><b>12</b> Local-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="12.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntro"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagIntuition"><i class="fa fa-check"></i><b>12.2</b> Intuition</a></li>
<li class="chapter" data-level="12.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagMethod"><i class="fa fa-check"></i><b>12.3</b> Method</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagneighbours"><i class="fa fa-check"></i><b>12.3.1</b> Nearest neighbours</a></li>
<li class="chapter" data-level="12.3.2" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagLFplot"><i class="fa fa-check"></i><b>12.3.2</b> Local-fidelity plot</a></li>
<li class="chapter" data-level="12.3.3" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProfiles"><i class="fa fa-check"></i><b>12.3.3</b> Local-stability plot</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagExample"><i class="fa fa-check"></i><b>12.4</b> Example: Titanic</a></li>
<li class="chapter" data-level="12.5" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagProsCons"><i class="fa fa-check"></i><b>12.5</b> Pros and cons</a></li>
<li class="chapter" data-level="12.6" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagR"><i class="fa fa-check"></i><b>12.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="12.7" data-path="localDiagnostics.html"><a href="localDiagnostics.html#cPLocDiagPython"><i class="fa fa-check"></i><b>12.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html"><i class="fa fa-check"></i><b>13</b> Summary of Instance-level Exploration</a>
<ul>
<li class="chapter" data-level="13.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#summaryInstanceLevelIntro"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#number-of-explanatory-variables-in-the-model"><i class="fa fa-check"></i><b>13.2</b> Number of explanatory variables in the model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#low-to-medium-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.1</b> Low to medium number of explanatory variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#medium-to-a-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.2</b> Medium to a large number of explanatory variables</a></li>
<li class="chapter" data-level="13.2.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#very-large-number-of-explanatory-variables"><i class="fa fa-check"></i><b>13.2.3</b> Very large number of explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#correlated-explanatory-variables"><i class="fa fa-check"></i><b>13.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="13.4" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#models-with-interactions"><i class="fa fa-check"></i><b>13.4</b> Models with interactions</a></li>
<li class="chapter" data-level="13.5" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#sparse-explanations"><i class="fa fa-check"></i><b>13.5</b> Sparse explanations</a></li>
<li class="chapter" data-level="13.6" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#additional-uses-of-model-exploration-and-explanation"><i class="fa fa-check"></i><b>13.6</b> Additional uses of model exploration and explanation</a></li>
<li class="chapter" data-level="13.7" data-path="summaryInstanceLevel.html"><a href="summaryInstanceLevel.html#comparison-of-models-champion-challenger-analysis"><i class="fa fa-check"></i><b>13.7</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="part"><span><b>III Dataset Level</b></span></li>
<li class="chapter" data-level="14" data-path="modelLevelExploration.html"><a href="modelLevelExploration.html"><i class="fa fa-check"></i><b>14</b> Introduction to Dataset-level Exploration</a></li>
<li class="chapter" data-level="15" data-path="modelPerformance.html"><a href="modelPerformance.html"><i class="fa fa-check"></i><b>15</b> Model-performance Measures</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntro"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceIntuition"><i class="fa fa-check"></i><b>15.2</b> Intuition</a></li>
<li class="chapter" data-level="15.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethod"><i class="fa fa-check"></i><b>15.3</b> Method</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCont"><i class="fa fa-check"></i><b>15.3.1</b> Continuous dependent variable</a></li>
<li class="chapter" data-level="15.3.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodBin"><i class="fa fa-check"></i><b>15.3.2</b> Binary dependent variable</a></li>
<li class="chapter" data-level="15.3.3" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCateg"><i class="fa fa-check"></i><b>15.3.3</b> Categorical dependent variable</a></li>
<li class="chapter" data-level="15.3.4" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceMethodCount"><i class="fa fa-check"></i><b>15.3.4</b> Count dependent variable</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="modelPerformance.html"><a href="modelPerformance.html#example"><i class="fa fa-check"></i><b>15.4</b> Example</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceApartments"><i class="fa fa-check"></i><b>15.4.1</b> Apartment prices</a></li>
<li class="chapter" data-level="15.4.2" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceTitanic"><i class="fa fa-check"></i><b>15.4.2</b> Titanic data</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceProsCons"><i class="fa fa-check"></i><b>15.5</b> Pros and cons</a></li>
<li class="chapter" data-level="15.6" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformanceR"><i class="fa fa-check"></i><b>15.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="15.7" data-path="modelPerformance.html"><a href="modelPerformance.html#modelPerformancePython"><i class="fa fa-check"></i><b>15.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="featureImportance.html"><a href="featureImportance.html"><i class="fa fa-check"></i><b>16</b> Variable-importance Measures</a>
<ul>
<li class="chapter" data-level="16.1" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntro"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceIntuition"><i class="fa fa-check"></i><b>16.2</b> Intuition</a></li>
<li class="chapter" data-level="16.3" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceMethod"><i class="fa fa-check"></i><b>16.3</b> Method</a></li>
<li class="chapter" data-level="16.4" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceTitanic"><i class="fa fa-check"></i><b>16.4</b> Example: Titanic data</a></li>
<li class="chapter" data-level="16.5" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceProsCons"><i class="fa fa-check"></i><b>16.5</b> Pros and cons</a></li>
<li class="chapter" data-level="16.6" data-path="featureImportance.html"><a href="featureImportance.html#featureImportanceR"><i class="fa fa-check"></i><b>16.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="16.7" data-path="featureImportance.html"><a href="featureImportance.html#featureImportancePython"><i class="fa fa-check"></i><b>16.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>17</b> Partial-dependence Profiles</a>
<ul>
<li class="chapter" data-level="17.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPIntuition"><i class="fa fa-check"></i><b>17.2</b> Intuition</a></li>
<li class="chapter" data-level="17.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPMethod"><i class="fa fa-check"></i><b>17.3</b> Method</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPs"><i class="fa fa-check"></i><b>17.3.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clusteredPDPs"><i class="fa fa-check"></i><b>17.3.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#groupedPDPs"><i class="fa fa-check"></i><b>17.3.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.3.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastivePDPs"><i class="fa fa-check"></i><b>17.3.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPExample"><i class="fa fa-check"></i><b>17.4</b> Example: apartment-prices data</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.4.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles"><i class="fa fa-check"></i><b>17.4.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPProsCons"><i class="fa fa-check"></i><b>17.5</b> Pros and cons</a></li>
<li class="chapter" data-level="17.6" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPR"><i class="fa fa-check"></i><b>17.6</b> Code snippets for R</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.1</b> Partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.2</b> Clustered partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.3</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.6.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-1"><i class="fa fa-check"></i><b>17.6.4</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#PDPPython"><i class="fa fa-check"></i><b>17.7</b> Code snippets for Python</a>
<ul>
<li class="chapter" data-level="17.7.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependence-profiles-2"><i class="fa fa-check"></i><b>17.7.1</b> Grouped partial-dependence profiles</a></li>
<li class="chapter" data-level="17.7.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-partial-dependence-profiles-2"><i class="fa fa-check"></i><b>17.7.2</b> Contrastive partial-dependence profiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>18</b> Local-dependence and Accumulated-local Profiles</a>
<ul>
<li class="chapter" data-level="18.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPIntuition"><i class="fa fa-check"></i><b>18.2</b> Intuition</a></li>
<li class="chapter" data-level="18.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPMethod"><i class="fa fa-check"></i><b>18.3</b> Method</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#local-dependence-profile"><i class="fa fa-check"></i><b>18.3.1</b> Local-dependence profile</a></li>
<li class="chapter" data-level="18.3.2" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#accumulated-local-profile"><i class="fa fa-check"></i><b>18.3.2</b> Accumulated-local profile</a></li>
<li class="chapter" data-level="18.3.3" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#dependence-profiles-for-a-model-with-interaction-and-correlated-explanatory-variables-an-example"><i class="fa fa-check"></i><b>18.3.3</b> Dependence profiles for a model with interaction and correlated explanatory variables: an example</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#CDPExample"><i class="fa fa-check"></i><b>18.4</b> Example: apartment-prices data</a></li>
<li class="chapter" data-level="18.5" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPProsCons"><i class="fa fa-check"></i><b>18.5</b> Pros and cons</a></li>
<li class="chapter" data-level="18.6" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPR"><i class="fa fa-check"></i><b>18.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="18.7" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#ALPPython"><i class="fa fa-check"></i><b>18.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html"><i class="fa fa-check"></i><b>19</b> Residual-diagnostics Plots</a>
<ul>
<li class="chapter" data-level="19.1" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntroResidualDiagnostic"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#IntuitionResidualDiagnostic"><i class="fa fa-check"></i><b>19.2</b> Intuition</a></li>
<li class="chapter" data-level="19.3" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#MethodResidualDiagnostic"><i class="fa fa-check"></i><b>19.3</b> Method</a></li>
<li class="chapter" data-level="19.4" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ExampleResidualDiagnostic"><i class="fa fa-check"></i><b>19.4</b> Example: apartment-prices data</a></li>
<li class="chapter" data-level="19.5" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#ProsConsResidualDiagnostic"><i class="fa fa-check"></i><b>19.5</b> Pros and cons</a></li>
<li class="chapter" data-level="19.6" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#RcodeResidualDiagnostic"><i class="fa fa-check"></i><b>19.6</b> Code snippets for R</a></li>
<li class="chapter" data-level="19.7" data-path="residualDiagnostic.html"><a href="residualDiagnostic.html#PythoncodeResidualDiagnostic"><i class="fa fa-check"></i><b>19.7</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html"><i class="fa fa-check"></i><b>20</b> Summary of Dataset-level Exploration</a>
<ul>
<li class="chapter" data-level="20.1" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#summaryModelLevelIntro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#exploration-on-trainingtesting-data"><i class="fa fa-check"></i><b>20.2</b> Exploration on training/testing data</a></li>
<li class="chapter" data-level="20.3" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#correlated-explanatory-variables-1"><i class="fa fa-check"></i><b>20.3</b> Correlated explanatory variables</a></li>
<li class="chapter" data-level="20.4" data-path="summaryModelLevel.html"><a href="summaryModelLevel.html#comparison-of-models-champion-challenger-analysis-1"><i class="fa fa-check"></i><b>20.4</b> Comparison of models (champion-challenger analysis)</a></li>
</ul></li>
<li class="part"><span><b>IV Use-cases</b></span></li>
<li class="chapter" data-level="21" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html"><i class="fa fa-check"></i><b>21</b> FIFA 19</a>
<ul>
<li class="chapter" data-level="21.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAintro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAdataprep"><i class="fa fa-check"></i><b>21.2</b> Data preparation</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r"><i class="fa fa-check"></i><b>21.2.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.2.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-1"><i class="fa fa-check"></i><b>21.2.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAdataunderst"><i class="fa fa-check"></i><b>21.3</b> Data understanding</a></li>
<li class="chapter" data-level="21.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelassembly"><i class="fa fa-check"></i><b>21.4</b> Model assembly</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>21.4.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.4.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-2"><i class="fa fa-check"></i><b>21.4.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelaudit"><i class="fa fa-check"></i><b>21.5</b> Model audit</a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>21.5.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.5.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-3"><i class="fa fa-check"></i><b>21.5.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAmodelunderst"><i class="fa fa-check"></i><b>21.6</b> Model understanding (dataset-level explanations)</a>
<ul>
<li class="chapter" data-level="21.6.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>21.6.1</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.6.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-4"><i class="fa fa-check"></i><b>21.6.2</b> Code snippets for Python</a></li>
</ul></li>
<li class="chapter" data-level="21.7" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAinstanceunderst"><i class="fa fa-check"></i><b>21.7</b> Instance-level explanations</a>
<ul>
<li class="chapter" data-level="21.7.1" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFALewy"><i class="fa fa-check"></i><b>21.7.1</b> Robert Lewandowski</a></li>
<li class="chapter" data-level="21.7.2" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>21.7.2</b> Code snippets for R</a></li>
<li class="chapter" data-level="21.7.3" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#code-snippets-for-python-5"><i class="fa fa-check"></i><b>21.7.3</b> Code snippets for Python</a></li>
<li class="chapter" data-level="21.7.4" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFACR7"><i class="fa fa-check"></i><b>21.7.4</b> CR7</a></li>
<li class="chapter" data-level="21.7.5" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFASzczesny"><i class="fa fa-check"></i><b>21.7.5</b> Wojciech Szczęsny</a></li>
<li class="chapter" data-level="21.7.6" data-path="UseCaseFIFA.html"><a href="UseCaseFIFA.html#FIFAMessi"><i class="fa fa-check"></i><b>21.7.6</b> Lionel Messi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="22" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>22</b> Reproducibility</a>
<ul>
<li class="chapter" data-level="22.1" data-path="reproducibility.html"><a href="reproducibility.html#package-versions-for-r"><i class="fa fa-check"></i><b>22.1</b> Package versions for R</a></li>
<li class="chapter" data-level="22.2" data-path="reproducibility.html"><a href="reproducibility.html#package-versions-for-python"><i class="fa fa-check"></i><b>22.2</b> Package versions for Python</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/ModelOriented/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Explanatory Model Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelPerformance" class="section level1" number="15">
<h1><span class="header-section-number">15</span> Model-performance Measures</h1>
<div id="modelPerformanceIntro" class="section level2" number="15.1">
<h2><span class="header-section-number">15.1</span> Introduction</h2>
<!---As it was pointed out in Section \@ref(fitting), we are interested in predictions for the random variable $Y$. Some of this information can be extracted from the observed independent variables $\underline X$, so in modelling, we are focused on understanding the conditional distribution of $Y|\underline X$. We're trying to approximates expected value with the class of models $f(\underline\theta; \underline X)$. Based on the observed data, we're constructing the $f(\underline{\hat\theta}; \underline X)$ model. [TOMASZ: THIS IS CONFUSING HERE. ALSO, IT IS BETTER TO AVOID MATHEMATICAL NOTATION IN INTRODUCTION, WHICH SHOULD BE ACCESSIBLE TO EVERYONE.  ]--->
<p>In this chapter, we present measures that are useful for the evaluation of the overall performance of a (predictive) model.</p>
<p>As it was mentioned in Sections <a href="modelDevelopmentProcess.html#MDPIntro">2.1</a> and <a href="modelDevelopmentProcess.html#fitting">2.5</a>, in general, we can distinguish between the explanatory and predictive approaches to statistical modelling. <span class="citation">Leo Breiman (<a href="#ref-twoCultures" role="doc-biblioref">2001</a><a href="#ref-twoCultures" role="doc-biblioref">b</a>)</span> indicates that validation of a model can be based on evaluation of <em>goodness-of-fit</em> (GoF) or on evaluation of predictive accuracy (which we will term <em>goodness-of-predicton</em>, GoP). In principle, GoF is mainly used for explanatory models, while GoP is applied for predictive models. In a nutshell, GoF pertains to the question: how well do the model’s predictions explain (fit) dependent-variable values of the observations used for developing the model? On the other hand, GoP is related to the question: how well does the model predict the value of the dependent variable for a new observation? For some measures, their interpretation in terms of GoF or GoP depends on whether they are computed by using training or testing data.</p>
<p>The measures may be applied for several purposes, including:</p>
<ul>
<li>model evaluation: we may want to know how good the model is, i.e., how reliable are the model’s predictions (how frequent and how large errors may we expect)?;</li>
<li>model comparison: we may want to compare two or more models in order to choose between them;</li>
<li>out-of-sample and out-of-time comparisons: we may want to check a model’s performance when applied to new data to evaluate if performance has not worsened.</li>
</ul>
<p>Depending on the nature of the dependent variable (continuous, binary, categorical, count, etc.), different model-performance measures may be used. Moreover, the list of useful measures is growing as new applications emerge. In this chapter, we discuss only a selected set of measures, some of which are used in dataset-level exploration techniques introduced in subsequent chapters. We also limit ourselves to the two basic types of dependent variables continuous (including count) and categorical (including binary) considered in our book.</p>
</div>
<div id="modelPerformanceIntuition" class="section level2" number="15.2">
<h2><span class="header-section-number">15.2</span> Intuition</h2>
<p>Most model-performance measures are based on the comparison of the model’s predictions with the (known) values of the dependent variable in a dataset. For an ideal model, the predictions and the dependent-variable values should be equal. In practice, it is never the case, and we want to quantify the disagreement.</p>
<p>In principle, model-performance measures may be computed for the training dataset, i.e., the data used for developing the model. However, in that case there is a serious risk that the computed values will overestimate the quality of the model’s predictive performance. A more meaningful approach is to apply the measures to an independent testing dataset. Alternatively, a bias-correction strategy can be used when applying them to the training data. Toward this aim, various strategies have been proposed, such as cross-validation or bootstrapping <span class="citation">(Kuhn and Johnson <a href="#ref-Kuhn2013" role="doc-biblioref">2013</a>; Harrell <a href="#ref-Harrell2015" role="doc-biblioref">2015</a>; Steyerberg <a href="#ref-Steyerberg2019" role="doc-biblioref">2019</a>)</span>. In what follows, we mainly consider the simple data-split strategy, i.e., we assume that the available data are split into a training set and a testing set. The model is created on the former, and the latter set is used to assess the model’s performance.</p>
<p>It is worth mentioning that there are two important aspects of prediction: <em>calibration</em> and <em>discrimination</em> <span class="citation">(Harrell, Lee, and Mark <a href="#ref-Harrell1996" role="doc-biblioref">1996</a>)</span>. Calibration refers to the extent of bias in predicted values, i.e., the mean difference between the predicted and true values. Discrimination refers to the ability of the predictions to distinguish between individual true values. For instance, consider a model to be used for weather forecasts in a region where, on average, it rains half the year. A simple model that predicts that every other day is rainy is well-calibrated because, on average, the resulting predicted risk of a rainy day in a year is 50%, which agrees with the actual situation. However, the model is not very much discriminative (for each calendar day, the probability of a correct prediction is 50%, the same as for a fair-coin toss) and, hence, not very useful.</p>
<p>Thus, in addition to overall measures of GoP, we may need separate measures for calibration and discrimination of a model. Note that, for the latter, we may want to weigh differently the situation when the prediction is, for instance, larger than the true value, as compared to the case when it is smaller. Depending on the decision on how to weigh different types of disagreement, we may need different measures.</p>
<p>In the best possible scenario, we can specify a single model-performance measure before the model is created and then optimize the model for this measure. But, in practice, a more common scenario is to use several performance measures, which are often selected after the model has been created.</p>
</div>
<div id="modelPerformanceMethod" class="section level2" number="15.3">
<h2><span class="header-section-number">15.3</span> Method</h2>
<p>Assume that we have got a training dataset with <span class="math inline">\(n\)</span> observations on <span class="math inline">\(p\)</span> explanatory variables and on a dependent variable <span class="math inline">\(Y\)</span>. Let <span class="math inline">\(\underline{x}_i\)</span> denote the (column) vector of values of the explanatory variables for the <span class="math inline">\(i\)</span>-th observation, and <span class="math inline">\(y_i\)</span> the corresponding value of the dependent variable. We will use <span class="math inline">\(\underline{X}=(x&#39;_1,\ldots,x&#39;_n)\)</span> to denote the matrix of explanatory variables for all <span class="math inline">\(n\)</span> observations, and <span class="math inline">\(\underline{y}=(y_1,\ldots,y_n)&#39;\)</span> to denote the (column) vector of the values of the dependent variable. </p>
<p>The training dataset is used to develop model <span class="math inline">\(f(\underline{\hat{\theta}}; \underline X)\)</span>, where <span class="math inline">\(\underline{\hat{\theta}}\)</span> denotes the estimated values of the model’s coefficients. Note that could also use here the “penalized” estimates <span class="math inline">\(\underline{\tilde{\theta}}\)</span> (see Section <a href="modelDevelopmentProcess.html#fitting">2.5</a>).
Let <span class="math inline">\(\widehat{y}_i\)</span> indicate the model’s prediction corresponding to <span class="math inline">\(y_i.\)</span> <!--In what follows we will ignore the fact that, in practice, one uses the estimated form of the model, and we will use $f()$ to denote it as well. --></p>
<p>The model performance analysis is often based on an independent dataset called a testing set. In some cases, model-performance mesures are based on a leave-one-out approach. We will denote by <span class="math inline">\(\underline{X}_{-i}\)</span> the matrix of explanatory variables when excluding the <span class="math inline">\(i\)</span>-th observation and by <span class="math inline">\(f(\underline{\hat{\theta}}_{-i}; \underline{X}_{-i})\)</span> the model developed for the reduced data. It is worth noting here that the leave-one-out model <span class="math inline">\(f(\underline{\hat{\theta}}_{-i}; \underline{X}_{-i})\)</span> is different from the full-data model <span class="math inline">\(f(\underline{\hat{\theta}}; \underline X)\)</span>. But often they are close to each other and conclusions obtained from one can be transferred to the other. We will use <span class="math inline">\(\widehat{y}_{i(-i)}\)</span> to denote the prediction for <span class="math inline">\(y_i\)</span> obtained from model <span class="math inline">\(f(\underline{\hat{\theta}}_{-i}; \underline{X}_{-i})\)</span>.</p>
<p>In the subsequent sections, we present various model-performance measures. <!-- by assuming that they are computed based on a training dataset--> The measures are applied in essentially the same way if a training or a testing dataset is used. If there is any difference in the interpretation or properties of the measures between the two situations, we will explicitly mention them. Note that, in what follows, we will ignore in the notation the fact that we consider the estimated model <span class="math inline">\(f(\underline{\hat{\theta}}; \underline X)\)</span> and we will use <span class="math inline">\(f()\)</span> as a generic notation for it.</p>
<div id="modelPerformanceMethodCont" class="section level3" number="15.3.1">
<h3><span class="header-section-number">15.3.1</span> Continuous dependent variable</h3>
<div id="modelPerformanceMethodContGOF" class="section level4" number="15.3.1.1">
<h4><span class="header-section-number">15.3.1.1</span> Goodness-of-fit</h4>
<p>The most popular GoF measure for models for a continuous dependent variable is the mean squared-error, defined as</p>
<p><span class="math display" id="eq:MSE">\[\begin{equation}
MSE(f,\underline{X},\underline{y}) = \frac{1}{n} \sum_{i}^{n} (\widehat{y}_i - y_i)^2 = \frac{1}{n} \sum_{i}^{n} r_i^2,
\tag{15.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(r_i\)</span> is the residual for the <span class="math inline">\(i\)</span>-th observation (see also Section <a href="modelDevelopmentProcess.html#notation">2.3</a>). Thus, MSE can be seen as a sum of squared residuals. MSE is a convex differentiable function, which is important from an optimization point of view (see Section <a href="modelDevelopmentProcess.html#fitting">2.5</a>). As the measure weighs all differences equally, large residuals have got a high impact on MSE. Thus, the measure is sensitive to outliers. For a “perfect” model, which predicts (fits) all <span class="math inline">\(y_i\)</span> exactly, <span class="math inline">\(MSE = 0\)</span>.</p>
<p>Note that MSE is constructed on a different scale from the dependent variable. Thus, a more interpretable variant of this measure is the root-mean-squared-error (RMSE), defined as</p>
<p><span class="math display" id="eq:RMSE">\[\begin{equation}
RMSE(f, \underline{X}, \underline{y}) = \sqrt{MSE(f, \underline{X}, \underline{y})}.
\tag{15.2}
\end{equation}\]</span></p>
<!---

Box plot for the absolute values of residuals for the linear regression and random forest models for the apartment-prices data. The red dot indicates the RMSE. The distribution of the residuals in the Random Forest model for the Titanic data. The red dot indicates RMSE.

<div class="figure" style="text-align: center">
<img src="ema_files/figure-html/prepareMPBoxplot-1.png" alt="Box plot for the absolute values of residuals for the linear regression and random forest models for the apartment-prices data. The red dot indicates the RMSE." width="80%" />
<p class="caption">(\#fig:prepareMPBoxplot)Box plot for the absolute values of residuals for the linear regression and random forest models for the apartment-prices data. The red dot indicates the RMSE.</p>
</div>
--->
<p>A popular variant of RMSE is its normalized version, <span class="math inline">\(R^2\)</span>, defined as</p>
<p><span class="math display" id="eq:R2">\[\begin{equation}
R^2(f, \underline{X}, \underline{y}) = 1 - \frac{MSE(f, \underline{X}, \underline{y})}{MSE(f_0, \underline{X},\underline{y})}.
\tag{15.3}
\end{equation}\]</span></p>
<p>In <a href="modelPerformance.html#eq:R2">(15.3)</a>, <span class="math inline">\(f_0()\)</span> denotes a “baseline” model. For instance, in the case of the classical linear regression, <span class="math inline">\(f_0()\)</span> is the model that includes only the intercept, which implies the use of the mean value of <span class="math inline">\(Y\)</span> as a prediction for all observations. <span class="math inline">\(R^2\)</span> is normalized in the sense that the “perfectly” fitting model leads to <span class="math inline">\(R^2 = 1\)</span>, while <span class="math inline">\(R^2 = 0\)</span> means that we are not doing better than the baseline model. In the context of the classical linear regression, <span class="math inline">\(R^2\)</span> is the familiar coefficient of determination and can be interpreted as the fraction of the total variance of <span class="math inline">\(Y\)</span> “explained” by model <span class="math inline">\(f()\)</span>.</p>
<p>Given sensitivity of MSE to outliers, sometimes the median absolute-deviation (MAD) is considered:</p>
<p><span class="math display" id="eq:MAD">\[\begin{equation}
MAD(f, \underline{X} ,\underline{y}) = median( |r_1|, ..., |r_n| ).
\tag{15.4}
\end{equation}\]</span></p>
<p>MAD is more robust to outliers than MSE. A disadvantage of MAD are its less favourable mathematical properties.</p>
<p>Section <a href="modelPerformance.html#modelPerformanceApartments">15.4.1</a> illustrates the use of measures for the linear regression model and the random forest model for the apartment-prices data.</p>
</div>
<div id="modelPerformanceMethodContGOP" class="section level4" number="15.3.1.2">
<h4><span class="header-section-number">15.3.1.2</span> Goodness-of-prediction</h4>
<p>Assume that a testing dataset is available. In that case, we can use model <span class="math inline">\(f()\)</span>, obtained by fitting the model to training data, to predict the values of the dependent variable observed in the testing dataset. Subsequently, we can compute MSE as in <a href="modelPerformance.html#eq:MSE">(15.1)</a> to obtain the mean squared-prediction-error (MSPE) as a GoP measure <span class="citation">(Kutner et al. <a href="#ref-Kutner2005" role="doc-biblioref">2005</a>)</span>. By taking the square root of MSPE, we get the root-mean-squared-prediction-error (RMSPE). </p>
<p>In the absence of testing data, one of the most known GoP measures for models for a continuous dependent variable is the predicted sum-of-squares (PRESS), defined as</p>
<p><span class="math display" id="eq:PRESS">\[\begin{equation}
PRESS(f,\underline{X},\underline{y}) = \sum_{i=1}^{n} (\widehat{y}_{i(-i)} - y_i)^2.
\tag{15.5}
\end{equation}\]</span></p>
<p>Thus, PRESS can be seen as a result of the application of the leave-one-out strategy to the evaluation of GoP of a model using the training data. Note that, for the classical linear regression model, there is no need to re-fit the model <span class="math inline">\(n\)</span> times to compute PRESS <span class="citation">(Kutner et al. <a href="#ref-Kutner2005" role="doc-biblioref">2005</a>)</span>.</p>
<p>Based on PRESS, one can define the predictive squared-error <span class="math inline">\(PSE=PRESS/n\)</span> and the standard deviation error in prediction <span class="math inline">\(SEP=\sqrt{PSE}=\sqrt{PRESS/n}\)</span> <span class="citation">(Todeschini <a href="#ref-SummariesTutorial" role="doc-biblioref">2010</a>)</span>. Another measure gaining in popularity is </p>
<p><span class="math display" id="eq:Q2">\[\begin{equation}
Q^2(f,\underline{X},\underline{y}) = 1- \frac{ PRESS(f,\underline{X},\underline{y})}{\sum_{i=1}^{n} ({y}_{i} - \bar{y})^2}.
\tag{15.6}
\end{equation}\]</span></p>
<p>It is sometimes called the cross-validated <span class="math inline">\(R^2\)</span> or the coefficient of prediction <span class="citation">(Landram, Abdullat, and Shah <a href="#ref-Landram2005" role="doc-biblioref">2005</a>)</span>. It appears that <span class="math inline">\(Q^2 \leq R^2\)</span>, i.e., the expected accuracy of out-of-sample predictions measured by <span class="math inline">\(Q^2\)</span> cannot exceed the accuracy of in-sample estimates <span class="citation">(Landram, Abdullat, and Shah <a href="#ref-Landram2005" role="doc-biblioref">2005</a>)</span>. For a “perfect” predictive model, <span class="math inline">\(Q^2=1\)</span>. It is worth noting that, while <span class="math inline">\(R^2\)</span> always increases if an explanatory variable is added to a model, <span class="math inline">\(Q^2\)</span> decreases when “noisy” variables are added to the model <span class="citation">(Todeschini <a href="#ref-SummariesTutorial" role="doc-biblioref">2010</a>)</span>.</p>
<p>The aforementioned measures capture the overall predictive performance of a model. A measure aimed at evaluating discrimination is the <em>concordance index</em> (c-index)\index{c-index| see{Concordance index} <span class="citation">(Harrell, Lee, and Mark <a href="#ref-Harrell1996" role="doc-biblioref">1996</a>; Brentnall and Cuzick <a href="#ref-Brentnall2018" role="doc-biblioref">2018</a>)</span>. It is computed by considering all pairs of observations and computing the fraction of the pairs in which the ordering of the predictions corresponds to the ordering of the true values <span class="citation">(Brentnall and Cuzick <a href="#ref-Brentnall2018" role="doc-biblioref">2018</a>)</span>. The index assumes the value of 1 in case of perfect discrimination and 0.25 for random discrimination.</p>
<p>Calibration can be assessed by a scatter plot of the predicted values of <span class="math inline">\(Y\)</span> in function of the true ones <span class="citation">(Harrell, Lee, and Mark <a href="#ref-Harrell1996" role="doc-biblioref">1996</a>; van Houwelingen, H.C. <a href="#ref-vanHouwelingen2000" role="doc-biblioref">2000</a>; Steyerberg et al. <a href="#ref-Steyerberg2010" role="doc-biblioref">2010</a>)</span>. The plot can be characterized by its intercept and slope. In case of perfect prediction, the plot should assume the form of a straight line with intercept 0 and slope 1. A deviation of the intercept from 0 indicates overall bias in predictions (“calibration-in-the-large”), while the value of the slope smaller than 1 suggests overfitting of the model <span class="citation">(van Houwelingen, H.C. <a href="#ref-vanHouwelingen2000" role="doc-biblioref">2000</a>; Steyerberg et al. <a href="#ref-Steyerberg2010" role="doc-biblioref">2010</a>)</span>. The estimated values of the coefficients can be used to re-calibrate the model <span class="citation">(van Houwelingen, H.C. <a href="#ref-vanHouwelingen2000" role="doc-biblioref">2000</a>)</span>.</p>
</div>
</div>
<div id="modelPerformanceMethodBin" class="section level3" number="15.3.2">
<h3><span class="header-section-number">15.3.2</span> Binary dependent variable</h3>
<p>To introduce model-performance measures, we, somewhat arbitrarily, label the two possible values of the dependent variable as “success” and “failure”. Of course, in a particular application, the meaning of the “success” outcome does not have to be positive nor optimistic; for a diagnostic test, “success” often means detection of disease. We also assume that model prediction <span class="math inline">\(\widehat{y}_i\)</span> takes the form of the predicted probability of success. </p>
<div id="modelPerformanceMethodBinGOF" class="section level4" number="15.3.2.1">
<h4><span class="header-section-number">15.3.2.1</span> Goodness-of-fit</h4>
<p>If we assign the value of 1 to success and 0 to failure, it is possible to use MSE, RMSE, and MAD, as defined in Equations <a href="modelPerformance.html#eq:MSE">(15.1)</a>, <a href="modelPerformance.html#eq:RMSE">(15.2)</a>, <a href="modelPerformance.html#eq:MAD">(15.4)</a>, respectively, as a GoF measure. In fact, the MSE obtained in that way is equivalent to the Brier score, which can be also expressed as
<span class="math display">\[
\sum_{i=1}^{n} \{y_i(1-\widehat{y}_i)^2+(1-y_i)(\widehat{y}_i)^2\}/n.
\]</span>
Its minimum value is 0 for a “perfect” model and 0.25 for an “uninformative” model that yields the predicted probability of 0.5 for all observations. The Brier score is often also interpreted as an overall predictive-performance measure for models for a binary dependent variable because it captures both calibration and the concentration of the predictive distribution <span class="citation">(Rufibach <a href="#ref-Rufibach2010" role="doc-biblioref">2010</a>)</span>.</p>
<p>One of the main issues related to the summary measures based on MSE is that they penalize too mildly for wrong predictions. In fact, the maximum penalty for an individual prediction is equal to 1 (if, for instance, the model yields zero probability for an actual success). To address this issue, the log-likelihood function based on the Bernoulli distribution (see also <a href="modelDevelopmentProcess.html#eq:modelTrainingBernoulli">(2.8)</a>) can be considered:</p>
<p><span class="math display" id="eq:bernoulli">\[\begin{equation}
l(f, \underline{X},\underline{y}) =  \sum_{i=1}^{n} \{y_i \ln(\widehat{y}_i)+ (1-y_i)\ln(1-\widehat{y}_i)\}.
\tag{15.7}
\end{equation}\]</span></p>
<p>Note that, in the machine-learning world, function <span class="math inline">\(-l(f, \underline{X} ,\underline{y})/n\)</span> is often considered (sometimes also with <span class="math inline">\(\ln\)</span> replaced by <span class="math inline">\(\log_2\)</span>) and termed “log-loss” or “cross-entropy”. The log-likelihood heavily “penalizes” the cases when the model-predicted probability of success <span class="math inline">\(\widehat{y}_i\)</span> is high for an actual failure (<span class="math inline">\(y_i=0\)</span>) and low for an actual success (<span class="math inline">\(y_i=1\)</span>). </p>
<p>The log-likelihood <a href="modelPerformance.html#eq:bernoulli">(15.7)</a> can be used to define <span class="math inline">\(R^2\)</span>-like measures (for a review, see, for example, <span class="citation">Allison (<a href="#ref-Allison2014" role="doc-biblioref">2014</a>)</span>). One of the variants most often used is the measure proposed by <span class="citation">Nagelkerke (<a href="#ref-Nagelkerke1991" role="doc-biblioref">1991</a>)</span>:</p>
<p><span class="math display" id="eq:R2bin">\[\begin{equation}
R_{bin}^2(f, \underline{X}, \underline{y}) = \frac{1-\exp\left(\frac{2}{n}\{l(f_0, \underline{X},\underline{y})-l(f, \underline{X},\underline{y})\}\right)}
{1-\exp\left(\frac{2}{n}l(f_0, \underline{X},\underline{y})\right)} .
\tag{15.8}
\end{equation}\]</span></p>
<p>It shares properties of the “classical” <span class="math inline">\(R^2\)</span>, defined in <a href="modelPerformance.html#eq:R2">(15.3)</a>. In <a href="modelPerformance.html#eq:R2bin">(15.8)</a>, <span class="math inline">\(f_0()\)</span> denotes the model that includes only the intercept, which implies the use of the observed fraction of successes as the predicted probability of success. If we denote the fraction by <span class="math inline">\(\hat{p}\)</span>, then</p>
<p><span class="math display">\[
l(f_0, \underline{X},\underline{y}) = n \hat{p} \ln{\hat{p}} + n(1-\hat{p}) \ln{(1-\hat{p})}. 
\]</span></p>
</div>
<div id="modelPerformanceMethodBinGOP" class="section level4" number="15.3.2.2">
<h4><span class="header-section-number">15.3.2.2</span> Goodness-of-prediction</h4>
<p>In many situations, consequences of a prediction error depend on the form of the error. For this reason, performance measures based on the (estimated values of) probability of correct/wrong prediction are more often used. </p>
<p>To introduce some of those measures, we assume that, for each observation from the testing dataset, the predicted probability of success <span class="math inline">\(\widehat{y}_i\)</span> is compared to a fixed cut-off threshold, <span class="math inline">\(C\)</span> say. If the probability is larger than <span class="math inline">\(C\)</span>, then we assume that the model predicts success; otherwise, we assume that it predicts failure. As a result of such a procedure, the comparison of the observed and predicted values of the dependent variable for the <span class="math inline">\(n\)</span> observations in a dataset can be summarized in a table similar to Table <a href="modelPerformance.html#tab:confMat">15.1</a>.</p>
<table style="width:100%;">
<caption><span id="tab:confMat">Table 15.1: </span> Confusion table for a classification model with scores <span class="math inline">\(\widehat{y}_i\)</span>.</caption>
<colgroup>
<col width="25%" />
<col width="27%" />
<col width="35%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>True value: <code>success</code></th>
<th>True value: <code>failure</code></th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\widehat{y}_i \geq C\)</span>, predicted: <code>success</code></td>
<td>True Positive: <span class="math inline">\(TP_C\)</span></td>
<td>False Positive (Type I error): <span class="math inline">\(FP_C\)</span></td>
<td><span class="math inline">\(P_C\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\widehat{y}_i &lt; C\)</span>, predicted: <code>failure</code></td>
<td>False Negative (Type II error): <span class="math inline">\(FN_C\)</span></td>
<td>True Negative: <span class="math inline">\(TN_C\)</span></td>
<td><span class="math inline">\(N_C\)</span></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(S\)</span></td>
<td><span class="math inline">\(F\)</span></td>
<td><span class="math inline">\(n\)</span></td>
</tr>
</tbody>
</table>
<p>In the machine-learning world, Table <a href="modelPerformance.html#tab:confMat">15.1</a> is often referred to as the “confusion table” or “confusion matrix”. In statistics, it is often called the “decision table”. The counts <span class="math inline">\(TP_C\)</span> and <span class="math inline">\(TN_C\)</span> on the diagonal of the table correspond to the cases when the predicted and observed value of the dependent variable <span class="math inline">\(Y\)</span> coincide. <span class="math inline">\(FP_C\)</span> is the number of cases in which failure is predicted as a success. These are false-positive, or Type I error, cases. On the other hand, <span class="math inline">\(FN_C\)</span> is the count of false-negative, or Type II error, cases, in which success is predicted as failure. Marginally, there are <span class="math inline">\(P_C\)</span> predicted successes and <span class="math inline">\(N_C\)</span> predicted failures, with <span class="math inline">\(P_C+N_C=n\)</span>. In the testing dataset, there are <span class="math inline">\(S\)</span> observed successes and <span class="math inline">\(F\)</span> observed failures, with <span class="math inline">\(S+N=n\)</span>.</p>
<!---
[TOMASZ: THIS IS A COMPLETELY NEW EXAMPLE. I DO NOT LIKE THAT. THE TABLE INCLUDES MEASURES THAT ARE DEFINED ONLY LATER. TO THE EXTENT POSSIBLE, WE SHOULD KEEP THE EXAMPLES IN A SEPARATE SECTION AND JUST REFER TO THEM.]

Let's illustrate the "confusion table" based on an example of pregnancy detection with a very simple pregnancy test - morning sickness. The table below shows a sample population of 1000 women aged 20-30 years. Information about the sensitivity and specificity of the test is taken from [@pregnancyMarkers].


|                         |True value: `pregnant`    |True value: `not pregnant`            |     Prevalence: 10\%|
|-----------------------|-------------------------|---------------------------------|-----------|
| Morning Sickness         |      39|     150|    Precision: 20.6\%|
| Lack of Morning Sickness |      61|     850|    NPV:       93.3\%|
|                  | Recall, Sensitivity: 39.0\%  |     Specificity: 85.0\%  | Accuracy: 80.8\%, F1: 26.9\%|
--->
<p>The effectiveness of such a test can be described by various measures. Let us present some of the most popular examples.</p>
<p>The simplest measure of model performance is <em>accuracy</em>, defined as</p>
<p><span class="math display">\[
ACC_C = \frac{TP_C+TN_C}{n}.
\]</span></p>
<p>It is the fraction of correct predictions in the entire testing dataset. Accuracy is of interest if true positives and true negatives are more important than their false counterparts. However, accuracy may not be very informative when one of the binary categories is much more prevalent (so called unbalanced labels). For example, if the testing data contain 90% of successes, a model that would always predict a success would reach an accuracy of 0.9, although one could argue that this is not a very useful model. </p>
<p>There may be situations when false positives and/or false negatives may be of more concern. In that case, one might want to keep their number low. Hence, other measures, focused on the false results, might be of interest.</p>
<p>In the machine-learning world, two other measures are often considered: <em>precision</em> and <em>recall</em>. Precision is defined as</p>
<p><span class="math display">\[
Precision_C = \frac{TP_C}{TP_C+FP_C} = \frac{TP_C}{P_C}.
\]</span></p>
<p>Precision is also referred to as the <em>positive predictive value</em>. It is the fraction of correct predictions among the predicted successes. Precision is high if the number of false positives is low. Thus, it is a useful measure when the penalty for committing the Type I error (false positive) is high. For instance, consider the use of a genetic test in cancer diagnostics, with a positive result of the test taken as an indication of an increased risk of developing a cancer. A false-positive result of a genetic test might mean that a person would have to unnecessarily cope with emotions and, possibly, medical procedures related to the fact of being evaluated as having a high risk of developing a cancer. We might want to avoid this situation more than the false-negative case. The latter would mean that the genetic test gives a negative result for a person that, actually, might be at an increased risk of developing a cancer. However, an increased risk does not mean that the person will develop cancer. And even so, we could hope that we could detect it in due time. </p>
<p>Recall is defined as</p>
<p><span class="math display">\[
Recall_C = \frac{TP_C}{TP_C+FN_C} = \frac{TP_C}{S}.
\]</span></p>
<p>Recall is also referred to as <em>sensitivity</em> or the <em>true-positive rate</em>. It is the fraction of correct predictions among the true successes. Recall is high if the number of false negatives is low. Thus, it is a useful measure when the penalty for committing the Type II error (false negative) is high. For instance, consider the use of an algorithm that predicts whether a bank transaction is fraudulent. A false-negative result means that the algorithm accepts a fraudulent transaction as a legitimate one. Such a decision may have immediate and unpleasant consequences for the bank, because it may imply a non-recoverable loss of money. On the other hand, a false-positive result means that a legitimate transaction is considered as a fraudulent one and is blocked. However, upon further checking, the legitimate nature of the transaction can be confirmed with, perhaps, the annoyed client as the only consequence for the bank. </p>
<p>The harmonic mean of these two measures defines the <em>F1 score</em>: </p>
<p><span class="math display">\[
F1\ score_C = \frac{2}{\frac{1}{Precision_C} + \frac{1}{Recall_C}} = 2\cdot\frac{Precision_C \cdot Recall_C}{Precision_C + Recall_C}.
\]</span></p>
<p>F1 score tends to give a low value if either precision or recall is low, and a high value if both precision and recall are high. For instance, if precision is 0, F1 score will also be 0 irrespectively of the value of recall. Thus, it is a useful measure if we have got to seek a balance between precision and recall.</p>
<p>In statistics, and especially in applications in medicine, the popular measures are <em>sensitivity</em> and <em>specificity</em>. Sensitivity is simply another name for recall. Specificity is defined as</p>
<p><span class="math display">\[
Specificity_C = \frac{TN_C}{TN_C + FP_C} = \frac{TN_C}{F}.
\]</span></p>
<p>Specificity is also referred to as the <em>true-negative rate</em>. It is the fraction of correct predictions among the true failures. Specificity is high if the number of false positives is low. Thus, as precision, it is a useful measure when the penalty for committing the Type I error (false positive) is high.</p>
<p>The reason why sensitivity and specificity may be more often used outside the machine-learning world is related to the fact that their values do not depend on the proportion <span class="math inline">\(S/n\)</span> (sometimes termed <em>prevalence</em>) of true successes. This means that, once estimated in a sample obtained from a population, they may be applied to other populations, in which the prevalence may be different. This is not true for precision, because one can write</p>
<p><span class="math display">\[
Precision_C = \frac{Sensitivity_C \cdot \frac{S}{n}}{Sensitivity_C \cdot \frac{S}{n}+Specificity_C \cdot \left(1-\frac{S}{n}\right)}.
\]</span></p>
<p>All the measures depend on the choice of cut-off <span class="math inline">\(C\)</span>. To assess the form and the strength of dependence, a common approach is to construct the Receiver Operating Characteristic (ROC) curve. The curve plots <span class="math inline">\(Sensitivity_C\)</span> in function of <span class="math inline">\(1-Specificity_C\)</span> for all possible, ordered values of <span class="math inline">\(C\)</span>. Figure <a href="modelPerformance.html#fig:exampleROC">15.2</a> presents the ROC curve for the random forest model for the Titanic dataset. Note that the curve indicates an inverse relationship between sensitivity and specificity: by increasing one measure, the other is decreased.</p>
<p>The ROC curve is very informative. For a model that predicts successes and failures at random, the corresponding curve will be equal to the diagonal line. On the other hand, for a model that yields perfect predictions, the ROC curve reduces to two intervals that connect points (0,0), (0,1), and (1,1). </p>
<p>Often, there is a need to summarize the ROC curve with one number, which can be used to compare models. A popular measure that is used toward this aim is the area under the curve (AUC). For a model that predicts successes and failures at random, AUC is the area under the diagonal line, i.e., it is equal to 0.5. For a model that yields perfect predictions, AUC is equal to 1. It appears that, in this case, AUC is equivalent to the c-index (see Section <a href="modelPerformance.html#modelPerformanceMethodContGOP">15.3.1.2</a>).</p>
<p>Another ROC-curve-based measure that is often used is the <em>Gini coefficient</em> <span class="math inline">\(G\)</span>. It is closely related to AUC; in fact, it can be calculated as <span class="math inline">\(G = 2 \times AUC - 1\)</span>. For a model that predicts successes and failures at random, <span class="math inline">\(G=0\)</span>; for a perfect-prediction model, <span class="math inline">\(G = 1\)</span>. Figure <a href="modelPerformance.html#fig:exampleROC">15.2</a> illustrates the calculation of the Gini coefficient for the random forest model for the Titanic dataset (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>).</p>
<p>A variant of ROC curve based on precision and recall is a called a precision-recall curve. Figure <a href="modelPerformance.html#fig:examplePRC">15.3</a> the curve for the random forest model for the Titanic dataset. </p>
<p>The value of the Gini coefficient or, equivalently, of <span class="math inline">\(AUC-0.5\)</span> allows a comparison of the model-based predictions with random guessing. A measure that explicitly compares a prediction model with a baseline (or null) model is the <em>lift</em>. Commonly, random guessing is considered as the baseline model. In that case,</p>
<p><span class="math display">\[
Lift_C  = \frac{\frac{TP_C}{P_C}}{\frac{S}{n}} = n\frac{Precision_C}{S}.
\]</span></p>
<p>Note that <span class="math inline">\(S/n\)</span> can be seen as the estimated probability of a correct prediction of success for random guessing. On the other hand, <span class="math inline">\(TP_C/P_C\)</span> is the estimated probability of a correct prediction of a success given that the model predicts a success. Hence, informally speaking, the lift indicates how many more (or less) times does the model do better in predicting success as compared to random guessing. As other measures, the lift depends on the choice of cut-off <span class="math inline">\(C\)</span>. The plot of the lift as a function of <span class="math inline">\(P_C\)</span> is called the <em>lift chart</em>. Figure <a href="modelPerformance.html#fig:examplePRC">15.3</a> presents the lift chart for the random forest model for the Titanic dataset. </p>
<p>Calibration of predictions can be assessed by a scatter plot of the predicted values of <span class="math inline">\(Y\)</span> in function of the true ones. A complicating issue is a fact that the true values are only equal to 0 or 1. Therefore, smoothing techniques or grouping of observations is needed to obtain a meaningful plot <span class="citation">(Steyerberg et al. <a href="#ref-Steyerberg2010" role="doc-biblioref">2010</a>; Steyerberg <a href="#ref-Steyerberg2019" role="doc-biblioref">2019</a>)</span>.</p>
<p>There are many more measures aimed at measuring the performance of a predictive model for a binary dependent variable. An overview can be found in, e.g., <span class="citation">Berrar (<a href="#ref-Berrar2019" role="doc-biblioref">2019</a>)</span>.</p>
</div>
</div>
<div id="modelPerformanceMethodCateg" class="section level3" number="15.3.3">
<h3><span class="header-section-number">15.3.3</span> Categorical dependent variable</h3>
<p>To introduce model-performance measures for a categorical dependent variable, we assume that <span class="math inline">\(\underline{y}_i\)</span> is now a vector of <span class="math inline">\(K\)</span> elements. Each element <span class="math inline">\(y_{i}^k\)</span> (<span class="math inline">\(k=1,\ldots,K\)</span>) is a binary variable indicating whether the <span class="math inline">\(k\)</span>-th category was observed for the <span class="math inline">\(i\)</span>-th observation. We assume that, for each observation, only one category can be observed. Thus, all elements of <span class="math inline">\(\underline{y}_i\)</span> are equal to 0 except one that is equal to 1. Furthermore, we assume that a model’s prediction takes the form of a vector, <span class="math inline">\(\underline{\widehat{y}}_i\)</span> say, of the predicted probabilities for each of the <span class="math inline">\(K\)</span> categories, with <span class="math inline">\({\widehat{y}}_i^k\)</span> denoting the probability for the <span class="math inline">\(k\)</span>-th category. The predicted category is the one with the highest predicted probability.</p>
<div id="modelPerformanceMethodCatGOF" class="section level4" number="15.3.3.1">
<h4><span class="header-section-number">15.3.3.1</span> Goodness-of-fit</h4>
<p>The log-likelihood function <a href="modelPerformance.html#eq:bernoulli">(15.7)</a> can be adapted to the categorical dependent variable case as follows:</p>
<p><span class="math display" id="eq:multinom">\[\begin{equation}
l(f, \underline{X} ,\underline{y}) =  \sum_{i=1}^{n}\sum_{k=1}^{K} y_{i}^k \ln({\widehat{y}}_i^k).
\tag{15.9}
\end{equation}\]</span></p>
<p>It is essentially the log-likelihood function based on a multinomial distribution. Based on the likelihood, an <span class="math inline">\(R^2\)</span>-like measure can be defined, using an approach similar to the one used in <a href="modelPerformance.html#eq:R2bin">(15.8)</a> for construction of <span class="math inline">\(R_{bin}^2\)</span> <span class="citation">(Harrell <a href="#ref-Harrell2015" role="doc-biblioref">2015</a>)</span>. </p>
</div>
<div id="modelPerformanceMethodCatGOP" class="section level4" number="15.3.3.2">
<h4><span class="header-section-number">15.3.3.2</span> Goodness-of-prediction</h4>
<p>It is possible to extend measures like accuracy, precision, etc., introduced in Section <a href="modelPerformance.html#modelPerformanceMethodBin">15.3.2</a> for a binary dependent variable, to the case of a categorical one. Toward this end, first, a confusion table is created for each category <span class="math inline">\(k\)</span>, treating the category as “success” and all other categories as “failure”. Let us denote the counts in the table by <span class="math inline">\(TP_k\)</span>, <span class="math inline">\(FP_k\)</span>, <span class="math inline">\(TN_k\)</span>, and <span class="math inline">\(FN_k\)</span>. Based on the counts, we can compute the average accuracy across all classes as follows:</p>
<p><span class="math display" id="eq:accmacro">\[\begin{equation}
\overline{ACC_C} = \frac{1}{K}\sum_{k=1}^K\frac{TP_{C,k}+TN_{C,k}}{n}.
\tag{15.10}
\end{equation}\]</span></p>
<p>Similarly, one could compute the average precision, average sensitivity, etc. In the machine-learning world, this approach is often termed “macro-averaging” <span class="citation">(Sokolva and Lapalme <a href="#ref-Sokolova2009" role="doc-biblioref">2009</a>; Tsoumakas, Katakis, and Vlahavas <a href="#ref-Tsoumakas2010" role="doc-biblioref">2010</a>)</span>. The averages computed in that way treat all classes equally. </p>
<p>An alternative approach is to sum the appropriate counts from the confusion tables for all classes, and then form a measure based on the so-computed cumulative counts. For instance, for precision, this would lead to</p>
<p><span class="math display" id="eq:precmicro">\[\begin{equation}
\overline{Precision_C}_{\mu} = \frac{\sum_{k=1}^K TP_{C,k}}{\sum_{k=1}^K (TP_{C,k}+FP_{C,k})}.
\tag{15.11}
\end{equation}\]</span></p>
<p>In the machine-learning world, this approach is often termed “micro-averaging” <span class="citation">(Sokolva and Lapalme <a href="#ref-Sokolova2009" role="doc-biblioref">2009</a>; Tsoumakas, Katakis, and Vlahavas <a href="#ref-Tsoumakas2010" role="doc-biblioref">2010</a>)</span>, hence subscript <span class="math inline">\(\mu\)</span> for “micro” in <a href="modelPerformance.html#eq:precmicro">(15.11)</a>. Note that, for accuracy, this computation still leads to <a href="modelPerformance.html#eq:accmacro">(15.10)</a>. The measures computed in that way favour classes with larger numbers of observations.</p>
</div>
</div>
<div id="modelPerformanceMethodCount" class="section level3" number="15.3.4">
<h3><span class="header-section-number">15.3.4</span> Count dependent variable</h3>
<p>In case of counts, one could consider using MSE or any of the measures for a continuous dependent variable mentioned in Section <a href="modelPerformance.html#modelPerformanceMethodContGOF">15.3.1.1</a>. However, a particular feature of count dependent variables is that their variance depends on the mean value. Consequently, weighing all contributions to MSE equally, as in <a href="modelPerformance.html#eq:MSE">(15.1)</a>, is not appropriate, because the same residual value <span class="math inline">\(r_i\)</span> indicates a larger discrepancy for a smaller count <span class="math inline">\(y_i\)</span> than for a larger one. Therefore, a popular measure of performance of a predictive model for counts is Pearson’s statistic: </p>
<p><span class="math display" id="eq:Pearson">\[\begin{equation}
\chi^2(f,\underline{X},\underline{y}) = \sum_{i=1}^{n} 
\frac{(\widehat{y}_i - y_i)^2}{\widehat{y}_i} = 
\sum_{i=1}^{n} \frac{r_i^2}{\widehat{y}_i}.
\tag{15.12}
\end{equation}\]</span></p>
<p>From <a href="modelPerformance.html#eq:Pearson">(15.12)</a> it is clear that, if the same residual is obtained for two different observed counts, it is assigned a larger weight for the count for which the predicted value is smaller.</p>
<p>Of course, there are more measures of model performance as well as types of model responses (e.g., censored data). A complete list, even if it could be created, would be beyond the scope of this book.</p>
</div>
</div>
<div id="example" class="section level2" number="15.4">
<h2><span class="header-section-number">15.4</span> Example</h2>
<div id="modelPerformanceApartments" class="section level3" number="15.4.1">
<h3><span class="header-section-number">15.4.1</span> Apartment prices</h3>
<p>Let us consider the linear regression model <code>apartments_lm</code> (see Section <a href="dataSetsIntro.html#model-Apartments-lr">4.5.1</a>) and the random forest model <code>apartments_rf</code> (see Section <a href="dataSetsIntro.html#model-Apartments-rf">4.5.2</a>) for the apartment-prices data (see Section <a href="dataSetsIntro.html#ApartmentDataset">4.4</a>). Recall that, for these data, the dependent variable, the price per square meter, is continuous. Hence, we can use the performance measures presented in Section <a href="modelPerformance.html#modelPerformanceMethodCont">15.3.1</a>. In particular, we consider MSE and RMSE.</p>
<p>Figure <a href="modelPerformance.html#fig:prepareMPBoxplotEx">15.1</a> presents a box plot of the absolute values of residuals for the linear regression and random forest models, computed for the testing-data. The computed values of RMSE are also indicated in the plots. The values are very similar for both models; we have already noted that fact in Section <a href="dataSetsIntro.html#predictionsApartments">4.5.4</a>.</p>

<div class="figure" style="text-align: center"><span id="fig:prepareMPBoxplotEx"></span>
<img src="ema_files/figure-html/prepareMPBoxplotEx-1.png" alt="Box plot for the absolute values of residuals for the linear regression and random forest models for the apartment-prices data. The red dot indicates the RMSE." width="80%" />
<p class="caption">
Figure 15.1: Box plot for the absolute values of residuals for the linear regression and random forest models for the apartment-prices data. The red dot indicates the RMSE.
</p>
</div>
<p>In particular, MSE, RMSE, <span class="math inline">\(R^2\)</span>, and MAD values for the linear regression model are equal to 80137, 283.09, 0.901, and 212.7, respectively. For the random forest model, they are equal to 80137, 282.95, 0.901, and 169.1 respectively. The values of the measures suggest that the predicitve performance of the random forest model is slightly better. But is this difference relevant? It should be remembered that development of any random forest model includes a random component. This means that, when a random forest model is fitted to the same dataset several times, but using a different random-number-generation seed, the value of MSE or MAD for the fitted models will fluctuate. Thus, we should consider the values obtained for the linear regression and random forest models for the apartment-prices data as indicating a similar performance of the two models rather than a superiority of one of them.</p>

</div>
<div id="modelPerformanceTitanic" class="section level3" number="15.4.2">
<h3><span class="header-section-number">15.4.2</span> Titanic data</h3>
<p>Let us consider the random forest model <code>titanic_rf</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>) and the logistic regression model <code>titanic_lmr</code> (see Section <a href="dataSetsIntro.html#model-titanic-lmr">4.2.1</a>) for the Titanic data (see Section <a href="dataSetsIntro.html#TitanicDataset">4.1</a>). Recall that, for these data, the dependent variable is binary, with success defined as survival of the passenger. </p>
<p>First, we take a look at the random forest model. We will illustrate the “confusion table” by using threshold <span class="math inline">\(C\)</span> equal to 0.5, i.e., we will classify passengers as “survivors” and “non-survivors” depending on whether their model-predicted probability of survival was larger than 50% or not, respectively. Table <a href="modelPerformance.html#tab:confMatRF">15.2</a> presents the resulting table.</p>
<table>
<caption><span id="tab:confMatRF">Table 15.2: </span> Confusion table for the random forest model for the Titanic data. Predicted survival status is equal to <em>survived</em> if the model-predicted probability of survival <span class="math inline">\(\hat y_i\)</span> is larger than 50%.</caption>
<thead>
<tr class="header">
<th></th>
<th>Actual: survived</th>
<th>Actual: died</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predicted: survived</td>
<td>454</td>
<td>60</td>
<td>514</td>
</tr>
<tr class="even">
<td>Predicted: died</td>
<td>257</td>
<td>1436</td>
<td>1693</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>711</td>
<td>1496</td>
<td>2207</td>
</tr>
</tbody>
</table>
<p>Based on the table, we obtain the value of accuracy equal to (454 + 1436) / 2207 = 0.8564. The values of precision and recall (sensitivity) are equal to <span class="math inline">\(454 / 514 = 0.8833\)</span> and <span class="math inline">\(454 / 711 = 0.6385\)</span>, respectively, with the resulting F1 score equal to 0.7412. Specificity is equal to <span class="math inline">\(1436 / 1496 = 0.9599\)</span>.</p>
<p>Figure <a href="modelPerformance.html#fig:exampleROC">15.2</a> presents the ROC curve for the random forest model. AUC is equal to 0.8595, and the Gini coefficient is equal to 0.719.</p>

<div class="figure" style="text-align: center"><span id="fig:exampleROC"></span>
<img src="ema_files/figure-html/exampleROC-1.png" alt="Receiver Operating Characteristic curve for the random forest model for the Titanic dataset. The Gini coefficient can be calculated as 2\(\times\) area between the ROC curve and the diagonal (this area is highlighted). The AUC coefficient is defined as an area under the ROC curve." width="50%" />
<p class="caption">
Figure 15.2: Receiver Operating Characteristic curve for the random forest model for the Titanic dataset. The Gini coefficient can be calculated as 2<span class="math inline">\(\times\)</span> area between the ROC curve and the diagonal (this area is highlighted). The AUC coefficient is defined as an area under the ROC curve.
</p>
</div>
<p>Figure <a href="modelPerformance.html#fig:examplePRC">15.3</a> presents the precision-recall curve (left-hand-side panel) and lift chart (right-hand-side panel) for the random forest model. </p>

<div class="figure" style="text-align: center"><span id="fig:examplePRC"></span>
<img src="ema_files/figure-html/examplePRC-1.png" alt="Precision-recall curve (left panel) and lift chart (right panel) for the random forest model for the Titanic dataset." width="100%" />
<p class="caption">
Figure 15.3: Precision-recall curve (left panel) and lift chart (right panel) for the random forest model for the Titanic dataset.
</p>
</div>
<!--
Figure \@ref(fig:exampleLift) presents the lift chart for the random forest model. 

(ref:exampleLiftDesc) Lift chart for the random forest model for the Titanic dataset. 

<div class="figure" style="text-align: center">
<img src="ema_files/figure-html/exampleLift-1.png" alt="(ref:exampleLiftDesc)" width="50%" />
<p class="caption">(\#fig:exampleLift)(ref:exampleLiftDesc)</p>
</div>

-->
<p>Table <a href="modelPerformance.html#tab:confMatLR">15.3</a> presents the confusion table for the logistic regression model for threshold <span class="math inline">\(C\)</span> equal to 0.5. The resulting values of accuracy, precision, recall (sensitivity), F1 score, and specificity are equal to 0.8043, 0.7522, 0.5851, 0.6582, and 0.9084. The values are smaller than for the random forest model, suggesting a better performance of the latter.</p>
<table>
<caption><span id="tab:confMatLR">Table 15.3: </span> Confusion table for the logisitic regression model for the Titanic data. Predicted survival status is equal to TRUE if the model-predicted probability of survival is larger than 50%.</caption>
<thead>
<tr class="header">
<th></th>
<th>Actual: survived</th>
<th>Actual: died</th>
<th>Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Predicted: survived</td>
<td>416</td>
<td>137</td>
<td>653</td>
</tr>
<tr class="even">
<td>Predicted: died</td>
<td>295</td>
<td>1359</td>
<td>1654</td>
</tr>
<tr class="odd">
<td>Total</td>
<td>711</td>
<td>1496</td>
<td>2207</td>
</tr>
</tbody>
</table>
<p>Left-hand-side panel in Figure <a href="modelPerformance.html#fig:titanicROC">15.4</a> presents ROC curves for both the logistic regression and the random forest model. The curve for the random forest model lies above the one for the logistic regression model for the majority of the cut-offs <span class="math inline">\(C\)</span>, except for the very high values of the cut-off <span class="math inline">\(C\)</span>. AUC for the logistic regression model is equal to 0.8174 and is smaller than for the random forest model. Right-hand-side panel in Figure <a href="modelPerformance.html#fig:titanicROC">15.4</a> presents lift charts for both models. Also in this case the curve for the random forest suggests a better performance than for the logistic regression model, except for the very high values of cut-off <span class="math inline">\(C\)</span>.</p>
<!--(ref:titanicLiftDesc) Lift charts for the random forest and logistic regression models for the Titanic dataset.-->

<div class="figure" style="text-align: center"><span id="fig:titanicROC"></span>
<img src="ema_files/figure-html/titanicROC-1.png" alt="Receiver Operating Characteristic curves (left panel) and lift charts (right panel) for the random forest and logistic regression models for the Titanic dataset." width="100%" />
<p class="caption">
Figure 15.4: Receiver Operating Characteristic curves (left panel) and lift charts (right panel) for the random forest and logistic regression models for the Titanic dataset.
</p>
</div>
<!--
Figure \@ref(fig:titanicLift) presents lift charts for both models. Also in this case the curve for the random forest suggests a better performance than for the logistic regression model, except for the very high values of cut-off $C$.

(ref:titanicLiftDesc) Lift charts for the random forest and logistic regression models for the Titanic dataset.


-->
</div>
</div>
<div id="modelPerformanceProsCons" class="section level2" number="15.5">
<h2><span class="header-section-number">15.5</span> Pros and cons</h2>
<p>All model-performance measures presented in this chapter are subject to some limitations. For that reason, many measures are available, as the limitations of a particular measure were addressed by developing an alternative one. For instance, RMSE is frequently used and reported for linear regression models. However, as it is sensitive to outliers, MAD has been proposed as an alternative. In case of predictive models for a binary dependent variable, measures like accuracy, F1 score, sensitivity, and specificity are often considered, depending on the consequences of correct/incorrect predictions in a particular application. However, the value of those measures depends on the cut-off value used for creating predictions. For this reason, ROC curve and AUC have been developed and have become very popular. They are not easily extended to the case of a categorical dependent variable, though.</p>
<p>Given the advantages and disadvantages of various measures and the fact that each may reflect a different aspect of the predictive performance of a model, it is customary to report and compare several of them when evaluating a model’s performance.</p>
</div>
<div id="modelPerformanceR" class="section level2" number="15.6">
<h2><span class="header-section-number">15.6</span> Code snippets for R</h2>
<p>In this section, we present model-performance measures as implemented in the <code>DALEX</code> package for R. The package covers the most often used measures and methods presented in this chapter. More advanced measures of performance are available in the <code>auditor</code> package for R <span class="citation">(Gosiewska and Biecek <a href="#ref-R-auditor" role="doc-biblioref">2018</a>)</span>. Note that there are also other R packages that offer similar functionality. These include, for instance, packages <code>mlr</code> <span class="citation">(Bischl et al. <a href="#ref-mlr" role="doc-biblioref">2016</a>)</span>, <code>caret</code> <span class="citation">(Kuhn <a href="#ref-caret" role="doc-biblioref">2008</a>)</span>, <code>tidymodels</code> <span class="citation">(Max and Wickham <a href="#ref-tidymodels" role="doc-biblioref">2018</a>)</span>, and <code>ROCR</code> <span class="citation">(Sing et al. <a href="#ref-ROCR" role="doc-biblioref">2005</a>)</span>.</p>
<p>For illustration purposes, we use the random forest model <code>titanic_rf</code> (see Section <a href="dataSetsIntro.html#model-titanic-rf">4.2.2</a>) and the logistic regression model <code>titanic_lmr</code> (see Section <a href="dataSetsIntro.html#model-titanic-lmr">4.2.1</a>) for the Titanic data (see Section <a href="dataSetsIntro.html#TitanicDataset">4.1</a>). Consequently, the <code>DALEX</code> functions are applied in the context of a binary classification problem. However, the same functions can be used for, for instance, linear regression models.</p>
<p>To illustrate the use of the functions, we first retrieve the <code>titanic_lmr</code> and <code>titanic_rf</code> model-objects via the <code>archivist</code> hooks, as listed in Section <a href="dataSetsIntro.html#ListOfModelsTitanic">4.2.7</a>. We also retrieve the version of the <code>titanic</code> data with imputed missing values.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="modelPerformance.html#cb170-1"></a>titanic_imputed &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/27e5c&quot;</span>)</span>
<span id="cb170-2"><a href="modelPerformance.html#cb170-2"></a>titanic_lmr &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/58b24&quot;</span>)</span>
<span id="cb170-3"><a href="modelPerformance.html#cb170-3"></a>titanic_rf &lt;-<span class="st"> </span>archivist<span class="op">::</span><span class="kw">aread</span>(<span class="st">&quot;pbiecek/models/4e0fc&quot;</span>)</span></code></pre></div>
<p>Then we construct the explainers for the models by using function <code>explain()</code> from the <code>DALEX</code> package (see Section <a href="dataSetsIntro.html#ExplainersTitanicRCode">4.2.6</a>). We also load the <code>rms</code> and <code>randomForest</code> packages, as the models were fitted by using functions from those packages and it is important to have the corresponding <code>predict()</code> functions available.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="modelPerformance.html#cb171-1"></a><span class="kw">library</span>(<span class="st">&quot;rms&quot;</span>)</span>
<span id="cb171-2"><a href="modelPerformance.html#cb171-2"></a><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</span>
<span id="cb171-3"><a href="modelPerformance.html#cb171-3"></a>explain_lmr &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_lmr, </span>
<span id="cb171-4"><a href="modelPerformance.html#cb171-4"></a>                       <span class="dt">data =</span> titanic_imputed[, <span class="dv">-9</span>],</span>
<span id="cb171-5"><a href="modelPerformance.html#cb171-5"></a>                       <span class="dt">y =</span> titanic_imputed<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, </span>
<span id="cb171-6"><a href="modelPerformance.html#cb171-6"></a>                       <span class="dt">type =</span> <span class="st">&quot;classification&quot;</span>,</span>
<span id="cb171-7"><a href="modelPerformance.html#cb171-7"></a>                       <span class="dt">label =</span> <span class="st">&quot;Logistic Regression&quot;</span>)</span>
<span id="cb171-8"><a href="modelPerformance.html#cb171-8"></a></span>
<span id="cb171-9"><a href="modelPerformance.html#cb171-9"></a><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</span>
<span id="cb171-10"><a href="modelPerformance.html#cb171-10"></a>explain_rf &lt;-<span class="st"> </span><span class="kw">explain</span>(<span class="dt">model =</span> titanic_rf,  </span>
<span id="cb171-11"><a href="modelPerformance.html#cb171-11"></a>                      <span class="dt">data =</span> titanic_imputed[, <span class="dv">-9</span>],</span>
<span id="cb171-12"><a href="modelPerformance.html#cb171-12"></a>                      <span class="dt">y =</span> titanic_imputed<span class="op">$</span>survived <span class="op">==</span><span class="st"> &quot;yes&quot;</span>, </span>
<span id="cb171-13"><a href="modelPerformance.html#cb171-13"></a>                      <span class="dt">label =</span> <span class="st">&quot;Random Forest&quot;</span>)</span></code></pre></div>
<p>Function <code>model_performance()</code> calculates, by default, a set of selected model-performance measures. These include MSE, RMSE, <span class="math inline">\(R^2\)</span>, and MAD for linear regression models, and recall, precision, F1, accuracy, and AUC for models for a binary dependent variable. The function includes the <code>cutoff</code> argument that allows specifying the cut-off value for the measures that require it, i.e., recall, precision, F1 score, and accuracy. By default, the cut-off value is set at 0.5. Note that, by default, all measures are computed for the data that are extracted from the explainer object; these can be training or testing data.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="modelPerformance.html#cb172-1"></a>(eva_rf &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">model_performance</span>(explain_rf))</span></code></pre></div>
<pre><code>## Measures for:  classification
## recall     : 0.6385373 
## precision  : 0.8832685 
## f1         : 0.7412245 
## accuracy   : 0.8563661 
## auc        : 0.8595467
## 
## Residuals:
##      0%     10%     20%     30%     40%     50%     60%     70% 
## -0.8920 -0.1140 -0.0240 -0.0080 -0.0040  0.0000  0.0000  0.0100 
##     80%     90%    100% 
##  0.1400  0.5892  1.0000</code></pre>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="modelPerformance.html#cb174-1"></a>(eva_lr &lt;-<span class="st"> </span>DALEX<span class="op">::</span><span class="kw">model_performance</span>(explain_lmr))</span></code></pre></div>
<pre><code>## Measures for:  classification
## recall     : 0.5850914 
## precision  : 0.7522604 
## f1         : 0.6582278 
## accuracy   : 0.8042592 
## auc        : 0.81741
## 
## Residuals:
##          0%         10%         20%         30%         40% 
## -0.98457244 -0.31904861 -0.23408037 -0.20311483 -0.15200813 
##         50%         60%         70%         80%         90% 
## -0.10318060 -0.06933478  0.05858024  0.29306442  0.73666519 
##        100% 
##  0.97151255</code></pre>
<p>Application of the <code>DALEX::model_performance()</code> function returns an object of class “model_performance”, which includes estimated values of several model-performance measures, as well as a data frame containing the observed and predicted values of the dependent variable together with their difference, i.e., residuals. An ROC curve or lift chart can be constructed by applying the generic <code>plot()</code> function to the object. The type of the required plot is indicated by using argument <code>geom</code>. In particular, the argument allows values <code>geom = "lift"</code> for lift charts, <code>geom = "roc"</code> for ROC curves, <code>geom = "histogram"</code> for histograms of residuals, and <code>geom = "boxplot"</code> for box-and-whisker plots of residuals. The <code>plot()</code> function returns a <code>ggplot2</code> object. It is possible to apply the function to more than one object. In that case, the plots for the models corresponding to each object are combined in one graph. In the code below, we create two <code>ggplot2</code> objects: one for a graph containing precision-recall curves for both models, and one for a histogram of residuals. Subsequently, we use the <code>patchwork</code> package to combine the graphs in one display.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="modelPerformance.html#cb176-1"></a>p1 &lt;-<span class="st"> </span><span class="kw">plot</span>(eva_rf, eva_lr, <span class="dt">geom =</span> <span class="st">&quot;histogram&quot;</span>) </span>
<span id="cb176-2"><a href="modelPerformance.html#cb176-2"></a>p2 &lt;-<span class="st"> </span><span class="kw">plot</span>(eva_rf, eva_lr, <span class="dt">geom =</span> <span class="st">&quot;prc&quot;</span>) </span></code></pre></div>

<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="modelPerformance.html#cb177-1"></a><span class="kw">library</span>(<span class="st">&quot;patchwork&quot;</span>)</span>
<span id="cb177-2"><a href="modelPerformance.html#cb177-2"></a>p1 <span class="op">+</span><span class="st"> </span>p2</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:titanicMEexamples"></span>
<img src="ema_files/figure-html/titanicMEexamples-1.png" alt="Precision-recall curves and histograms for residuals obtained by the generic plot() function in R for the logistic regression model titanic_lmr and the random forest model titanic_rf for the Titanic dataset." width="864" />
<p class="caption">
Figure 15.5: Precision-recall curves and histograms for residuals obtained by the generic <code>plot()</code> function in R for the logistic regression model <code>titanic_lmr</code> and the random forest model <code>titanic_rf</code> for the Titanic dataset.
</p>
</div>
<p>The resulting graph is shown in Figure <a href="modelPerformance.html#fig:titanicMEexamples">15.5</a>. Combined with the plot of ROC curves and the lift charts presented in both panels of Figure <a href="modelPerformance.html#fig:titanicROC">15.4</a>, it provides additional insight into the comparison of performance of the two models.</p>
<!---
Both plots can be supplemented with boxplots for residuals. Toward this end, the residuals have got to be computed and added to the explainer object with the help of the `model_performance()` function. Subsequently, the `plot()` can be applied to the resulting object.   


```r
plot(eva_rf, eva_lr, geom = "boxplot")
```
---->
</div>
<div id="modelPerformancePython" class="section level2" number="15.7">
<h2><span class="header-section-number">15.7</span> Code snippets for Python</h2>
<p>In this section, we use the <code>dalex</code> library for Python. A collection of numerous metrics and performance charts is also available in the popular <code>sklearn.metrics</code> library.</p>
<p>For illustration purposes, we use the <code>titanic_rf</code> random forest model for the Titanic data developed in Section <a href="dataSetsIntro.html#model-titanic-python-rf">4.3.2</a>. Recall that the model is developed to predict the probability of survival for passengers of Titanic.</p>
<p>In the first step, we create an explainer-object that will provide a uniform interface for the predictive model. We use the <code>Explainer()</code> constructor for this purpose.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb178-1"><a href="modelPerformance.html#cb178-1"></a><span class="im">import</span> dalex <span class="im">as</span> dx</span>
<span id="cb178-2"><a href="modelPerformance.html#cb178-2"></a>titanic_rf_exp <span class="op">=</span> dx.Explainer(titanic_rf, X, y, </span>
<span id="cb178-3"><a href="modelPerformance.html#cb178-3"></a>                  label <span class="op">=</span> <span class="st">&quot;Titanic RF Pipeline&quot;</span>)</span></code></pre></div>
<p>To calculate selected measures of the overall performance, we use the <code>model_performance()</code> method. In the syntax below, we apply the <code>model_type</code> argument to indicate that we deal with a classification problem, and the <code>cutoff</code> argument to specify the cutoff value equal to 0.5. It is worth noting that we get different results than in R. In both cases, the models may differ slightly in implementation and are also trained with a different random seed.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb179-1"><a href="modelPerformance.html#cb179-1"></a>mp_rf <span class="op">=</span> titanic_rf_exp.model_performance(model_type <span class="op">=</span> <span class="st">&quot;classification&quot;</span>, </span>
<span id="cb179-2"><a href="modelPerformance.html#cb179-2"></a>          cutoff <span class="op">=</span> <span class="fl">0.5</span>)</span>
<span id="cb179-3"><a href="modelPerformance.html#cb179-3"></a>mp_rf.result</span></code></pre></div>
<p><img src="figure/python_model_performance_2.png" width="60%" /></p>
<p>The resulting object can be visualised in many different ways. The code below constructs an ROC curve with AUC measure. Figure <a href="modelPerformance.html#fig:examplePythonMP4">15.6</a> presents the created plot.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb180-1"><a href="modelPerformance.html#cb180-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb180-2"><a href="modelPerformance.html#cb180-2"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve, auc</span>
<span id="cb180-3"><a href="modelPerformance.html#cb180-3"></a>y_score <span class="op">=</span> titanic_rf_exp.predict(X)</span>
<span id="cb180-4"><a href="modelPerformance.html#cb180-4"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y, y_score)</span>
<span id="cb180-5"><a href="modelPerformance.html#cb180-5"></a>fig <span class="op">=</span> px.area(x<span class="op">=</span>fpr, y<span class="op">=</span>tpr,</span>
<span id="cb180-6"><a href="modelPerformance.html#cb180-6"></a>    title<span class="op">=</span><span class="ss">f&#39;ROC Curve (AUC=</span><span class="sc">{</span>auc(fpr, tpr)<span class="sc">:.4f}</span><span class="ss">)&#39;</span>,</span>
<span id="cb180-7"><a href="modelPerformance.html#cb180-7"></a>    labels<span class="op">=</span><span class="bu">dict</span>(x<span class="op">=</span><span class="st">&#39;False Positive Rate&#39;</span>, y<span class="op">=</span><span class="st">&#39;True Positive Rate&#39;</span>),</span>
<span id="cb180-8"><a href="modelPerformance.html#cb180-8"></a>    width<span class="op">=</span><span class="dv">700</span>, height<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb180-9"><a href="modelPerformance.html#cb180-9"></a>fig.add_shape(</span>
<span id="cb180-10"><a href="modelPerformance.html#cb180-10"></a>    <span class="bu">type</span><span class="op">=</span><span class="st">&#39;line&#39;</span>, line<span class="op">=</span><span class="bu">dict</span>(dash<span class="op">=</span><span class="st">&#39;dash&#39;</span>),</span>
<span id="cb180-11"><a href="modelPerformance.html#cb180-11"></a>    x0<span class="op">=</span><span class="dv">0</span>, x1<span class="op">=</span><span class="dv">1</span>, y0<span class="op">=</span><span class="dv">0</span>, y1<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb180-12"><a href="modelPerformance.html#cb180-12"></a>fig.update_yaxes(scaleanchor<span class="op">=</span><span class="st">&quot;x&quot;</span>, scaleratio<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb180-13"><a href="modelPerformance.html#cb180-13"></a>fig.update_xaxes(constrain<span class="op">=</span><span class="st">&#39;domain&#39;</span>)</span>
<span id="cb180-14"><a href="modelPerformance.html#cb180-14"></a>fig.show()</span></code></pre></div>

<div class="figure" style="text-align: center"><span id="fig:examplePythonMP4"></span>
<img src="figure/python_model_performance_4.png" alt="The ROC curve for the random forest model for the Titanic dataset." width="60%" />
<p class="caption">
Figure 15.6: The ROC curve for the random forest model for the Titanic dataset.
</p>
</div>
<p>The code below constructs a plot of FP and TP rates as a function of different thresholds. Figure <a href="modelPerformance.html#fig:examplePythonMP3">15.7</a> presents the created plot.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="modelPerformance.html#cb181-1"></a>df <span class="op">=</span> pd.DataFrame({<span class="st">&#39;False Positive Rate&#39;</span>: fpr,</span>
<span id="cb181-2"><a href="modelPerformance.html#cb181-2"></a>        <span class="st">&#39;True Positive Rate&#39;</span>: tpr }, index<span class="op">=</span>thresholds)</span>
<span id="cb181-3"><a href="modelPerformance.html#cb181-3"></a>df.index.name <span class="op">=</span> <span class="st">&quot;Thresholds&quot;</span></span>
<span id="cb181-4"><a href="modelPerformance.html#cb181-4"></a>df.columns.name <span class="op">=</span> <span class="st">&quot;Rate&quot;</span></span>
<span id="cb181-5"><a href="modelPerformance.html#cb181-5"></a>fig_thresh <span class="op">=</span> px.line(df, </span>
<span id="cb181-6"><a href="modelPerformance.html#cb181-6"></a>    title<span class="op">=</span><span class="st">&#39;TPR and FPR at every threshold&#39;</span>, width<span class="op">=</span><span class="dv">700</span>, height<span class="op">=</span><span class="dv">500</span>)</span>
<span id="cb181-7"><a href="modelPerformance.html#cb181-7"></a>fig_thresh.update_yaxes(scaleanchor<span class="op">=</span><span class="st">&quot;x&quot;</span>, scaleratio<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb181-8"><a href="modelPerformance.html#cb181-8"></a>fig_thresh.update_xaxes(<span class="bu">range</span><span class="op">=</span>[<span class="dv">0</span>, <span class="dv">1</span>], constrain<span class="op">=</span><span class="st">&#39;domain&#39;</span>)</span>
<span id="cb181-9"><a href="modelPerformance.html#cb181-9"></a>fig_thresh.show()</span></code></pre></div>

<div class="figure" style="text-align: center"><span id="fig:examplePythonMP3"></span>
<img src="figure/python_model_performance_3.png" alt="False-positive and true-positive rates as a function of threshold for the random forest model for the Titanic dataset." width="80%" />
<p class="caption">
Figure 15.7: False-positive and true-positive rates as a function of threshold for the random forest model for the Titanic dataset.
</p>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Allison2014">
<p>Allison, P. 2014. “Measures of fit for logistic regression.” In <em>Proceedings of the Sas Global Forum 2014 Conference</em>. Cary, NC: SAS Institute Inc. <a href="http://support.sas.com/resources/papers/proceedings14/1485-2014.pdf">http://support.sas.com/resources/papers/proceedings14/1485-2014.pdf</a>.</p>
</div>
<div id="ref-Berrar2019">
<p>Berrar, D. 2019. “Performance measures for binary classification.” In <em>Encyclopedia of Bioinformatics and Computational Biology Volume 1</em>, 546–60. Elsevier. <a href="https://www.sciencedirect.com/science/article/pii/B9780128096338203518">https://www.sciencedirect.com/science/article/pii/B9780128096338203518</a>.</p>
</div>
<div id="ref-mlr">
<p>Bischl, Bernd, Michel Lang, Lars Kotthoff, Julia Schiffner, Jakob Richter, Erich Studerus, Giuseppe Casalicchio, and Zachary M. Jones. 2016. “mlr: Machine Learning in R.” <em>Journal of Machine Learning Research</em> 17 (170): 1–5. <a href="http://jmlr.org/papers/v17/15-066.html">http://jmlr.org/papers/v17/15-066.html</a>.</p>
</div>
<div id="ref-twoCultures">
<p>Breiman, Leo. 2001b. “Statistical modeling: The two cultures.” <em>Statistical Science</em> 16 (3): 199–231. <a href="https://doi.org/10.1214/ss/1009213726">https://doi.org/10.1214/ss/1009213726</a>.</p>
</div>
<div id="ref-Brentnall2018">
<p>Brentnall, A. R., and J. Cuzick. 2018. “Use of the concordance index for predictors of censored survival data.” <em>Statistical Methods in Medical Research</em> 27: 2359–73.</p>
</div>
<div id="ref-R-auditor">
<p>Gosiewska, Alicja, and Przemyslaw Biecek. 2018. <em>auditor: Model Audit - Verification, Validation, and Error Analysis</em>. <a href="https://CRAN.R-project.org/package=auditor">https://CRAN.R-project.org/package=auditor</a>.</p>
</div>
<div id="ref-Harrell2015">
<p>Harrell, F. E. Jr. 2015. <em>Regression Modeling Strategies (2nd Ed.)</em>. Cham, Switzerland: Springer.</p>
</div>
<div id="ref-Harrell1996">
<p>Harrell, F. E. Jr., K. L. Lee, and D. B. Mark. 1996. “Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors.” <em>Statistics in Medicine</em> 15: 361–87.</p>
</div>
<div id="ref-caret">
<p>Kuhn, Max. 2008. “Building Predictive Models in R Using the Caret Package.” <em>Journal of Statistical Software</em> 28 (5): 1–26. <a href="https://doi.org/10.18637/jss.v028.i05">https://doi.org/10.18637/jss.v028.i05</a>.</p>
</div>
<div id="ref-Kuhn2013">
<p>Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. New York, NY: Springer. <a href="http://appliedpredictivemodeling.com/">http://appliedpredictivemodeling.com/</a>.</p>
</div>
<div id="ref-Kutner2005">
<p>Kutner, M. H., C. J. Nachtsheim, J. Neter, and W. Li. 2005. <em>Applied Linear Statistical Models</em>. New York: McGraw-Hill/Irwin.</p>
</div>
<div id="ref-Landram2005">
<p>Landram, F., A. Abdullat, and V. Shah. 2005. “The coefficient of prediction for model specification.” <em>Southwestern Economic Review</em> 32: 149–56.</p>
</div>
<div id="ref-tidymodels">
<p>Max, Kuhn, and Hadley Wickham. 2018. <em>Tidymodels: Easily Install and Load the ’Tidymodels’ Packages</em>. <a href="https://CRAN.R-project.org/package=tidymodels">https://CRAN.R-project.org/package=tidymodels</a>.</p>
</div>
<div id="ref-Nagelkerke1991">
<p>Nagelkerke, N. J. D. 1991. “A note on a general definition of the coefficient of determination.” <em>Biometrika</em> 78: 691–92.</p>
</div>
<div id="ref-Rufibach2010">
<p>Rufibach, K. 2010. “Use of Brier score to assess binary predictions.” <em>Journal of Clinical Epidemiology</em> 63: 938–39.</p>
</div>
<div id="ref-ROCR">
<p>Sing, T., O. Sander, N. Beerenwinkel, and T. Lengauer. 2005. “ROCR: visualizing classifier performance in R.” <em>Bioinformatics</em> 21 (20): 7881. <a href="http://rocr.bioinf.mpi-sb.mpg.de">http://rocr.bioinf.mpi-sb.mpg.de</a>.</p>
</div>
<div id="ref-Sokolova2009">
<p>Sokolva, M., and G. Lapalme. 2009. “A systematic analysis of performance measures for classification tasks.” <em>Information Processing and Management</em> 45: 427–37.</p>
</div>
<div id="ref-Steyerberg2019">
<p>Steyerberg, E. W. 2019. <em>Clinical Prediction Models. A Practical Approach to Development, Validation, and Updating (2nd Ed.)</em>. Cham, Switzerland: Springer.</p>
</div>
<div id="ref-Steyerberg2010">
<p>Steyerberg, E. W., A. J. Vickers, N. R. Cook, T. Gerds, M. Gonen, N. Obuchowski, M. J. Pencina, and M. W. Kattan. 2010. “Assessing the performance of prediction models: a framework for traditional and novel measures.” <em>Epidemiology</em> 21: 128–38.</p>
</div>
<div id="ref-SummariesTutorial">
<p>Todeschini, Roberto. 2010. <em>Useful and unuseful summaries of regression models</em>. <a href="http://www.iamc-online.org/tutorials/T5_moleculardescriptors_models.pdf">http://www.iamc-online.org/tutorials/T5_moleculardescriptors_models.pdf</a>.</p>
</div>
<div id="ref-Tsoumakas2010">
<p>Tsoumakas, G., I. Katakis, and I. Vlahavas. 2010. “Mining multi-label data.” In <em>Data Mining and Knowledge Discovery Handbook</em>, 667–85. Springer, Boston, MA. <a href="https://doi.org/10.1007/978-0-387-09823-4_34">https://doi.org/10.1007/978-0-387-09823-4_34</a>.</p>
</div>
<div id="ref-vanHouwelingen2000">
<p>van Houwelingen, H.C. 2000. “Validation, calibration, revision and combination of prognostic survival models.” <em>Statistics in Medicine</em> 19: 3401–15.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelLevelExploration.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="featureImportance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ema.pdf", "ema.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
