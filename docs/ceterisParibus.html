<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visualisation, Exploration and Explanation</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2018-09-23">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="LIME.html">
<link rel="next" href="model-level-explanations.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#model-lifecycle"><i class="fa fa-check"></i><b>1.1</b> Model Lifecycle</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#why-do-we-need-model-explainers"><i class="fa fa-check"></i><b>1.2</b> Why do we need model explainers?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-model-exploration-is-different-from-data-exploration"><i class="fa fa-check"></i><b>1.3</b> How model exploration is different from data exploration?</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#black-box-models-vs-white-box-models"><i class="fa fa-check"></i><b>1.4</b> Black-box models vs White-box models</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#model-agnostic-vs-model-specific"><i class="fa fa-check"></i><b>1.5</b> Model agnostic vs Model specific</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#glossary-notation"><i class="fa fa-check"></i><b>1.6</b> Glossary / Notation</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.7</b> Thanks to</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="prediction-level-explanations.html"><a href="prediction-level-explanations.html"><i class="fa fa-check"></i>Prediction level explanations</a></li>
<li class="chapter" data-level="2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#variable-attribution-vs-what-if-analysis"><i class="fa fa-check"></i><b>2.1</b> Variable attribution vs What-if analysis</a></li>
<li class="chapter" data-level="2.2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#when-to-use"><i class="fa fa-check"></i><b>2.2</b> When to use?</a></li>
<li class="chapter" data-level="2.3" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#three-single-laws"><i class="fa fa-check"></i><b>2.3</b> A bit of philosophy: Three Laws for Prediction Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-variable-attribution-methods.html"><a href="introduction-to-variable-attribution-methods.html"><i class="fa fa-check"></i><b>3</b> Introduction to variable attribution methods</a><ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-variable-attribution-methods.html"><a href="introduction-to-variable-attribution-methods.html#VAlinMod"><i class="fa fa-check"></i><b>3.1</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-variable-attribution-methods.html"><a href="introduction-to-variable-attribution-methods.html#wine-quality-example"><i class="fa fa-check"></i><b>3.1.1</b> Wine quality example</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-variable-attribution-methods.html"><a href="introduction-to-variable-attribution-methods.html#modelAgnosticAttribution"><i class="fa fa-check"></i><b>3.2</b> Model agnostic approaches</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>4</b> Break Down Attributions</a><ul>
<li class="chapter" data-level="4.1" data-path="breakDown.html"><a href="breakDown.html#the-algorithm"><i class="fa fa-check"></i><b>4.1</b> The Algorithm</a></li>
<li class="chapter" data-level="4.2" data-path="breakDown.html"><a href="breakDown.html#hr-dataset-hire-or-fire"><i class="fa fa-check"></i><b>4.2</b> HR dataset: Hire or Fire?</a></li>
<li class="chapter" data-level="4.3" data-path="breakDown.html"><a href="breakDown.html#break-down-plots"><i class="fa fa-check"></i><b>4.3</b> Break Down Plots</a></li>
<li class="chapter" data-level="4.4" data-path="breakDown.html"><a href="breakDown.html#pros-and-cons"><i class="fa fa-check"></i><b>4.4</b> Pros and cons</a></li>
<li class="chapter" data-level="4.5" data-path="breakDown.html"><a href="breakDown.html#code-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="break-down-for-interactions.html"><a href="break-down-for-interactions.html"><i class="fa fa-check"></i><b>5</b> Break Down for Interactions</a><ul>
<li class="chapter" data-level="5.1" data-path="break-down-for-interactions.html"><a href="break-down-for-interactions.html#the-algorithm-1"><i class="fa fa-check"></i><b>5.1</b> The Algorithm</a></li>
<li class="chapter" data-level="5.2" data-path="break-down-for-interactions.html"><a href="break-down-for-interactions.html#hr-dataset-hire-or-fire-1"><i class="fa fa-check"></i><b>5.2</b> HR dataset: Hire or Fire?</a></li>
<li class="chapter" data-level="5.3" data-path="break-down-for-interactions.html"><a href="break-down-for-interactions.html#break-down-plots-1"><i class="fa fa-check"></i><b>5.3</b> Break Down Plots</a></li>
<li class="chapter" data-level="5.4" data-path="break-down-for-interactions.html"><a href="break-down-for-interactions.html#pros-and-cons-1"><i class="fa fa-check"></i><b>5.4</b> Pros and cons</a></li>
<li class="chapter" data-level="5.5" data-path="break-down-for-interactions.html"><a href="break-down-for-interactions.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>5.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>6</b> Shapley Attributions</a><ul>
<li class="chapter" data-level="6.1" data-path="shapley.html"><a href="shapley.html#the-algorithm-2"><i class="fa fa-check"></i><b>6.1</b> The Algorithm</a></li>
<li class="chapter" data-level="6.2" data-path="shapley.html"><a href="shapley.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>6.2</b> Code snippets for R</a></li>
<li class="chapter" data-level="6.3" data-path="shapley.html"><a href="shapley.html#pros-and-cons-2"><i class="fa fa-check"></i><b>6.3</b> Pros and cons</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>7</b> Local approximations with white-box model</a><ul>
<li class="chapter" data-level="7.1" data-path="LIME.html"><a href="LIME.html#the-algorithm-3"><i class="fa fa-check"></i><b>7.1</b> The Algorithm</a></li>
<li class="chapter" data-level="7.2" data-path="LIME.html"><a href="LIME.html#hr-dataset-hire-or-fire-2"><i class="fa fa-check"></i><b>7.2</b> HR dataset: Hire or Fire?</a></li>
<li class="chapter" data-level="7.3" data-path="LIME.html"><a href="LIME.html#pros-and-cons-3"><i class="fa fa-check"></i><b>7.3</b> Pros and cons</a></li>
<li class="chapter" data-level="7.4" data-path="LIME.html"><a href="LIME.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>7.4</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.4.1" data-path="LIME.html"><a href="LIME.html#the-lime-pacakge"><i class="fa fa-check"></i><b>7.4.1</b> <strong>The lime pacakge</strong></a></li>
<li class="chapter" data-level="7.4.2" data-path="LIME.html"><a href="LIME.html#the-live-package"><i class="fa fa-check"></i><b>7.4.2</b> <strong>The live package</strong></a></li>
<li class="chapter" data-level="7.4.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>7.4.3</b> <strong>The iml package</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>8</b> Ceteris Paribus Principle</a><ul>
<li class="chapter" data-level="8.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#ceterisParibus1d"><i class="fa fa-check"></i><b>8.2</b> 1D profiles</a></li>
<li class="chapter" data-level="8.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#oscillations"><i class="fa fa-check"></i><b>8.3</b> Profile oscillations</a></li>
<li class="chapter" data-level="8.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#d-profiles"><i class="fa fa-check"></i><b>8.4</b> 2D profiles</a></li>
<li class="chapter" data-level="8.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#local-model-fidelity"><i class="fa fa-check"></i><b>8.5</b> Local model fidelity</a></li>
<li class="chapter" data-level="8.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons-4"><i class="fa fa-check"></i><b>8.6</b> Pros and cons</a></li>
<li class="chapter" data-level="8.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>8.7</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="9" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>9</b> Introduction</a><ul>
<li class="chapter" data-level="9.1" data-path="introduction-2.html"><a href="introduction-2.html#a-bit-of-philosophy"><i class="fa fa-check"></i><b>9.1</b> A bit of philosophy</a></li>
<li class="chapter" data-level="9.2" data-path="introduction-2.html"><a href="introduction-2.html#example-price-prediction"><i class="fa fa-check"></i><b>9.2</b> Example: Price prediction</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>10</b> Variable Importance</a></li>
<li class="chapter" data-level="11" data-path="marginal-response.html"><a href="marginal-response.html"><i class="fa fa-check"></i><b>11</b> Marginal Response</a><ul>
<li class="chapter" data-level="11.1" data-path="marginal-response.html"><a href="marginal-response.html#partial-dependency-plots"><i class="fa fa-check"></i><b>11.1</b> Partial Dependency Plots</a></li>
<li class="chapter" data-level="11.2" data-path="marginal-response.html"><a href="marginal-response.html#merging-path-plots"><i class="fa fa-check"></i><b>11.2</b> Merging Path Plots</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="performance-diagnostic.html"><a href="performance-diagnostic.html"><i class="fa fa-check"></i><b>12</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="13" data-path="residual-diagnostic.html"><a href="residual-diagnostic.html"><i class="fa fa-check"></i><b>13</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="14" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>14</b> Other topics</a></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="15" data-path="DataSets.html"><a href="DataSets.html"><i class="fa fa-check"></i><b>15</b> Data Sets</a><ul>
<li class="chapter" data-level="15.1" data-path="DataSets.html"><a href="DataSets.html#HRdataset"><i class="fa fa-check"></i><b>15.1</b> Hire or Fire? HR in Call Center</a></li>
<li class="chapter" data-level="15.2" data-path="DataSets.html"><a href="DataSets.html#apartmentsDataset"><i class="fa fa-check"></i><b>15.2</b> How much does it cost? Price prediction for a square meter</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visualisation, Exploration and Explanation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ceterisParibus" class="section level1">
<h1><span class="header-section-number">Chapter 8</span> Ceteris Paribus Principle</h1>
<p>In this section we introduce tools based on Ceteris Paribus principle. The main goal for these tools is to help understand how changes in model input affect changes in model output.</p>
<p>Presented explainers are linked with the second law introduced in Section <a href="PredictionExplainers.html#three-single-laws">2.3</a>, i.e. law for prediction’s speculations. This is why these explainers are also known as <em>What-If model analysis</em> or <em>Individual Conditional EXpectations</em> <span class="citation">(Goldstein et al. <a href="#ref-ICEbox">2015</a>)</span>. It turns out that it is easier to understand how blacx-box model is working if we can play with it by changing variable by variable.</p>
<p>Think of following usecases:</p>
<ul>
<li>Think about a model for hart attack. How the model response would change if a patient cuts the number of smoked cigarettes by half or increase physical activity.</li>
<li>Think about a model for credit scoring. A customer gets a low score and is asking what he needs to change to increase this score to a certain level, to pass the bank criteria.</li>
<li>Think about a model for apartment prices. An investor wants to know how much the price may increase if apartment standard is upgraded.</li>
</ul>
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">8.1</span> Introduction</h2>
<p><em>Ceteris paribus</em> is a Latin phrase meaning “other things held constant” or “all else unchanged”. Using this principle we examine input variable per variable separatly, asumming that effects of all other variables are unchanged. See Figure <a href="ceterisParibus.html#fig:modelResponseCurveLine">8.1</a></p>
<div class="figure" style="text-align: center"><span id="fig:modelResponseCurveLine"></span>
<img src="figure/model_response_line.png" alt="(fig:modelResponseCurveLine) A) Model response surface. Ceteris Paribus profiles marked with black curves helps to understand the curvature of the model response by updating only a single variable. B) CP profiles are individual conditional model responses" width="70%" />
<p class="caption">
Figure 8.1: (fig:modelResponseCurveLine) A) Model response surface. Ceteris Paribus profiles marked with black curves helps to understand the curvature of the model response by updating only a single variable. B) CP profiles are individual conditional model responses
</p>
</div>
<p>Similar to the LIME method introduced in the section <a href="LIME.html#LIME">7</a>, Ceteris Paribus profiles examine curvature of a model response function. The difference between these two methods that LIME approximates the model curvature with a simpler white-box model that is easier to present. Usually the LIME model is sparse, thus our attention may be limited to smaller number of dimensions. In contrary, the CP plots show conditional model response for every variable. In the last subsection we discuss pros and cons of this approach.</p>
</div>
<div id="ceterisParibus1d" class="section level2">
<h2><span class="header-section-number">8.2</span> 1D profiles</h2>
<p>Let <span class="math inline">\(f_{M}(x): \mathcal R^{d} \rightarrow \mathcal R\)</span> denote a predictive model, i.e. function that takes <span class="math inline">\(d\)</span> dimensional vector and calculate numerical score.
Symbol <span class="math inline">\(x \in \mathcal R^d\)</span> refers to a point in the feature space. We use subscript <span class="math inline">\(x_i\)</span> to refer to a different data points and superscript <span class="math inline">\(x^j\)</span> to refer to specific dimensions. Additionally, let <span class="math inline">\(x^{-j}\)</span> denote all coordinates except <span class="math inline">\(j\)</span>-th and let <span class="math inline">\(x|^j=z\)</span> denote a data point <span class="math inline">\(x^*\)</span> with all coordinates equal to <span class="math inline">\(x\)</span> except coordinate <span class="math inline">\(j\)</span> equal to value <span class="math inline">\(z\)</span>. I.e. <span class="math inline">\(\forall_{i \neq {j}} x^i = x^{*,i}\)</span> and <span class="math inline">\(x^j = z\)</span>. In other words <span class="math inline">\(x|^j=z\)</span> denote a <span class="math inline">\(x\)</span> with <span class="math inline">\(j\)</span>th coordinate changed to <span class="math inline">\(z\)</span>.</p>
<p>Now we can define uni-dimensional Ceteris Paribus Profile for model <span class="math inline">\(f\)</span>, variable <span class="math inline">\(j\)</span> and point <span class="math inline">\(x\)</span> as</p>
<p><span class="math display">\[
CP^{f, j, x}(z) := f(x|^j = z).
\]</span>
I.e. CP profile is a model response obtained for observations created based on <span class="math inline">\(x\)</span> with coordinate <span class="math inline">\(j\)</span> changed and all other coordinates kept unchanged.</p>
<p>A natural way to visualise CP profiles is to use a profile plot as in Figure <a href="ceterisParibus.html#fig:HRCPFiredHours">8.2</a>.</p>
<p>Figure <a href="ceterisParibus.html#fig:HRCPFiredHours">8.2</a> shows an example of Ceteris Paribus profile. The black dot stands for prediction for a single observation. Grey line show how the model response would change if in this single observation coordinate <code>hours</code> will be changed to selected value. One thing that we can read is that the model response is not smooth and there is some variability along the profile. Second thing is that for this particular observation the model response would drop significantly if the variable <code>hours</code> will be higher than 45.</p>
<div class="figure" style="text-align: center"><span id="fig:HRCPFiredHours"></span>
<img src="figure/HR_cp_fired_hours.png" alt="(fig:HRCPHiredHours) Ceteris Paribus profile for Random Forest model that assess the probability of being fired in call center as a function of average number of working hours" width="50%" />
<p class="caption">
Figure 8.2: (fig:HRCPHiredHours) Ceteris Paribus profile for Random Forest model that assess the probability of being fired in call center as a function of average number of working hours
</p>
</div>
<p>Since in the example dataset we are struggling with model for three classes, one can plot CP profiles for each class in the same panel. See an example in the Figure <a href="ceterisParibus.html#fig:HRCPAllHours">8.3</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:HRCPAllHours"></span>
<img src="figure/HR_cp_all_hours.png" alt="(fig:HRCPAllHours) Ceteris Paribus profiles for three classess predicted by the Random Forest model as a function of average number of working hours" width="60%" />
<p class="caption">
Figure 8.3: (fig:HRCPAllHours) Ceteris Paribus profiles for three classess predicted by the Random Forest model as a function of average number of working hours
</p>
</div>
<p>Usually model input consist many variables, then it is beneficial to show more variables at the same time. The easiest way to do so is to plot consecutive variables on separate panels. See an example in Figure <a href="ceterisParibus.html#fig:HRCPFiredAll">8.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:HRCPFiredAll"></span>
<img src="figure/HR_cp_fired_all.png" alt="(fig:HRCPFiredAll) Ceteris Paribus profiles for all continuous variables" width="70%" />
<p class="caption">
Figure 8.4: (fig:HRCPFiredAll) Ceteris Paribus profiles for all continuous variables
</p>
</div>
</div>
<div id="oscillations" class="section level2">
<h2><span class="header-section-number">8.3</span> Profile oscillations</h2>
<p>Visual examination of variables is insightful, but for large number of variables we end up with large number of panels, most of which are flat.
This is why we want to asses variable importance and show only profiles for important variables. The advantage of CP profiles is that they lead to a very natural and intuitive way of assessing the variable importance for a single prediction. The intuition is: the more important variable the larger are changes along the CP profile. If variable is not important then model response will barely change. If variable is important the CP profile change a lot for different values of a variable.</p>
<p>Let’s write it down in a more formal way.</p>
<p>Let <span class="math inline">\(vip^{CP}_j(x)\)</span> denotes variable importance calculated based on CP profiles in point <span class="math inline">\(x\)</span> for variable <span class="math inline">\(j\)</span>.</p>
<p><span class="math display">\[
vip^{CP}_j(x) = \int_{-\inf}^{inf} |CP^{f,j,x}(z) - f(x)| dz
\]</span></p>
<p>So it’s an absolute deviation from <span class="math inline">\(f(x)\)</span>. Note that one can consider different modification of this coefficient:</p>
<ol style="list-style-type: decimal">
<li>Deviations can be calculated not as a distance from <span class="math inline">\(f(x)\)</span> but from average <span class="math inline">\(\bar CP^{f,j,x}(z)\)</span>.</li>
<li>The integral may be weighted based on the density of variable <span class="math inline">\(x^j\)</span>.</li>
<li>Instead of absolute deviations one may use root from average squares.</li>
</ol>
<p>TODO: we need to verify which approach is better. Anna Kozak is working on this</p>
<p>The straightforward estimator for <span class="math inline">\(vip^{CP}_j(x)\)</span> is</p>
<p><span class="math display">\[
\widehat{ vip^{CP}_j(x)} = \frac 1n \sum_{i=1}^n |CP^{f,j,x}(x_i) - f(x)|.
\]</span></p>
<p>Figure <a href="ceterisParibus.html#fig:CPVIPprofiles">8.5</a> shows the idea behind measuring oscillations. The larger the highlighted area the more important is the variable.</p>
<div class="figure" style="text-align: center"><span id="fig:CPVIPprofiles"></span>
<img src="figure/CP_VIP_profiles.png" alt="(fig:CPVIPprofiles) CP oscillations are average deviations between CP profiles and the model response" width="50%" />
<p class="caption">
Figure 8.5: (fig:CPVIPprofiles) CP oscillations are average deviations between CP profiles and the model response
</p>
</div>
<p>Figure <a href="ceterisParibus.html#fig:CPVIP1">8.6</a> summarizes variable oscillations. Such visuals help to quickly grasp how large are model oscillations around a specific point.</p>
<div class="figure" style="text-align: center"><span id="fig:CPVIP1"></span>
<img src="figure/cp_vip_1.png" alt="(fig:CPVIP1) Variable importance plots calculated for Ceteris Paribus profiles for observation ID: 1001" width="40%" />
<p class="caption">
Figure 8.6: (fig:CPVIP1) Variable importance plots calculated for Ceteris Paribus profiles for observation ID: 1001
</p>
</div>
<p><strong>NOTE</strong></p>
<p>Variable importance for single prediction may be very different than variable importance for the full model.</p>
<p>For example, consider a model
<span class="math display">\[
f(x_1, x_2) = x_1 * x_2
\]</span>
where variables <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> takes values in <span class="math inline">\([0,1]\)</span>.</p>
<p>From the global perspective both variables are equally important.</p>
<p>But local variable importance is very different. Around point <span class="math inline">\(x = (0, 1)\)</span> the importance of <span class="math inline">\(x_1\)</span> is much larger than <span class="math inline">\(x_2\)</span>. This is because profile for <span class="math inline">\(f(z, 1)\)</span> have larger oscillations than <span class="math inline">\(f(0, z)\)</span>.</p>
</div>
<div id="d-profiles" class="section level2">
<h2><span class="header-section-number">8.4</span> 2D profiles</h2>
<p>The definition of ceteris paribus profiles given in section <a href="ceterisParibus.html#ceterisParibus1d">8.2</a> may be easily extended to two and more variables. Also definition of CP oscillations <a href="ceterisParibus.html#oscillations">8.3</a> have straight forward generalization for larger number of dimensions. Such generalisations are usefull when model is non additive. Presence of pairwise interactions may be detected with 2D Ceteris Paribus plots.</p>
<p>Let’s define two-dimensional Ceteris Paribus Profile for model <span class="math inline">\(f\)</span>, variables <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span> and point <span class="math inline">\(x\)</span> as</p>
<p><span class="math display">\[
CP^{f, (j,k), x}(z_1, z_2) := f(x|^{(j,k)} = (z_1,z_2)).
\]</span>
I.e. CP profile is a model response obtained for observations created based on <span class="math inline">\(x\)</span> with <span class="math inline">\(j\)</span> and <span class="math inline">\(k\)</span> coordinates changed to <span class="math inline">\((z_1, z_2)\)</span> and all other coordinates kept unchanged.</p>
<p>A natural way to visualise 2D CP profiles is to use a level plot as in Figure <a href="ceterisParibus.html#fig:CP2Dsurflor">8.7</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:CP2Dsurflor"></span>
<img src="figure/cp_2d_surf_floor.png" alt="(fig:CP2Dsurflor) Ceteris Paribus plot for a pair of variales. Black cross marks coordinated for the observation of interest. Presented model estimates price of an appartment" width="60%" />
<p class="caption">
Figure 8.7: (fig:CP2Dsurflor) Ceteris Paribus plot for a pair of variales. Black cross marks coordinated for the observation of interest. Presented model estimates price of an appartment
</p>
</div>
<p>If number of variables is small or moderate thein it is possible to present all pairs of variables. See an example in Figure <a href="ceterisParibus.html#fig:CP2Dall">8.8</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:CP2Dall"></span>
<img src="figure/cp_2d_all.png" alt="(fig:CP2Dall) Ceteris Paribus plot for all pairs of variales." width="90%" />
<p class="caption">
Figure 8.8: (fig:CP2Dall) Ceteris Paribus plot for all pairs of variales.
</p>
</div>
</div>
<div id="local-model-fidelity" class="section level2">
<h2><span class="header-section-number">8.5</span> Local model fidelity</h2>
<p>Ceteris Paribus profiles are also a useful tool to validate local model fidelity.
It may happen that global performance of the model is good, while for some points the local fit is very bad. Local fidelity helps to understand how good is the model fit around point of interest.</p>
<p>How does it work?</p>
<p>The idea behind fidelity plots is to select some number of points from the validation dataset that are closes to the point of interest.
It’s a similar approach as in k nearest neighbours. Then for these neighbours we may plot Ceteris Paribus Profiles and check how stable they are.</p>
<p>Also, if we know true taget values for points from the validation dataset we may plot residuals to show how large are residuals.</p>
<p>An example fidelity plot is presented in Figure <a href="ceterisParibus.html#fig:CPfidelity1">8.9</a>.
Black line shows the CP profiles for the point of interest, while grey lines show CP profiles for neihgbors. Red intervals stand for residuals and in this example it looks like residuals for neighbours are all negative. Thus maybe model is biased around the point of interest.</p>
<div class="figure" style="text-align: center"><span id="fig:CPfidelity1"></span>
<img src="figure/cp_fidelity_1.png" alt="(fig:CPfidelity1) Local fidelity plots. Black line shows the CP profile for the point of interest. Grey lines show CP profiles for nearest neighbors. Red intervals correspond to residuals. Each red interval starts in a model prediction for a selected neighbor and ends in its true value of target variable." width="70%" />
<p class="caption">
Figure 8.9: (fig:CPfidelity1) Local fidelity plots. Black line shows the CP profile for the point of interest. Grey lines show CP profiles for nearest neighbors. Red intervals correspond to residuals. Each red interval starts in a model prediction for a selected neighbor and ends in its true value of target variable.
</p>
</div>
<p>This observation may be confirmed by plots that compare distribution of all residuals against distribution of residuals for neighbors.</p>
<p>See Figure <a href="#CPfidelityBoxplot"><strong>??</strong></a> for an example. Here residuals for neighbors are shifted towards highest values. This suggests that the model response is biased around the observation of interest.</p>
<div class="figure" style="text-align: center"><span id="fig:CPfidelityBoxplot"></span>
<img src="figure/cp_fidelity_boxplot.png" alt="(fig:CPfidelityBoxplot) Distribution of residuals for whole validation data (grey boxplot) and for selected closes 15 neighbors (red boxplot)." width="70%" />
<p class="caption">
Figure 8.10: (fig:CPfidelityBoxplot) Distribution of residuals for whole validation data (grey boxplot) and for selected closes 15 neighbors (red boxplot).
</p>
</div>
</div>
<div id="pros-and-cons-4" class="section level2">
<h2><span class="header-section-number">8.6</span> Pros and cons</h2>
<p>Ceteris Paribus principle gives a uniform and extendable approach to model exploration. Below we summarize key strengths and weaknesses of this approach.</p>
<p><strong>Pros</strong></p>
<ul>
<li>Graphical representation of Ceteris Paribus profile is easy to understand.</li>
<li>Ceteris Paribus profiles are compact and it is easy to fit many models or many variables in a small space.</li>
<li>Ceteris Paribus profiles helps to understand how model response would change and how stable it is</li>
<li>Oscillations calculated for CP profiles helps to select the most important variables.</li>
<li>2D Ceteris Paribus profiles help to identify pairwise interactions between variables.</li>
</ul>
<p><strong>Cons</strong></p>
<ul>
<li>If variables are correlated (like surface and number of rooms) then the ‘<em>everything else kept unchanged</em>’ approach leads to unrealistic settings.</li>
<li>Interactions between variables are not visible in 1D plots.</li>
<li>This tool is not suited for very wide data, like hundreds or thousands of variables.</li>
<li>Visualization of categorical variables is non trivial.</li>
</ul>
</div>
<div id="code-snippets-for-r-4" class="section level2">
<h2><span class="header-section-number">8.7</span> Code snippets for R</h2>
<p>In this section we present key features of the <code>ceterisParibus</code> package for R <span class="citation">(P. Biecek <a href="#ref-R-ceterisParibus">2018</a><a href="#ref-R-ceterisParibus">b</a>)</span>. This package covers all features presented in this chapter. It is available on CRAN and GitHub. Find more examples at the website of this package <code>https://pbiecek.github.io/ceterisParibus/</code>.</p>
<p><strong>Model preparation</strong></p>
<p>In this section we will present examples based on the <code>apartments</code> dataset. See section TODO for more details.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb39-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb39-2" data-line-number="2"><span class="kw">head</span>(apartments)</a></code></pre></div>
<pre><code>##   m2.price construction.year surface floor no.rooms    district
## 1     5897              1953      25     3        1 Srodmiescie
## 2     1818              1992     143     9        5     Bielany
## 3     3643              1937      56     1        2       Praga
## 4     3517              1995      93     7        3      Ochota
## 5     3013              1992     144     6        5     Mokotow
## 6     5795              1926      61     6        2 Srodmiescie</code></pre>
<p>The problem here is to predict average price for square meter for an apartment. Let’s build a random forest model with <code>randomForest</code> package <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span>.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb41-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb41-2" data-line-number="2">rf_model &lt;-<span class="st"> </span><span class="kw">randomForest</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span></a>
<a class="sourceLine" id="cb41-3" data-line-number="3"><span class="st">      </span>no.rooms, <span class="dt">data =</span> apartments)</a>
<a class="sourceLine" id="cb41-4" data-line-number="4">rf_model</a></code></pre></div>
<pre><code>## 
## Call:
##  randomForest(formula = m2.price ~ construction.year + surface +      floor + no.rooms, data = apartments) 
##                Type of random forest: regression
##                      Number of trees: 500
## No. of variables tried at each split: 1
## 
##           Mean of squared residuals: 486308.1
##                     % Var explained: 40.79</code></pre>
<p>Model exploration with <code>ceterisParibus</code> package is performed in four steps.</p>
<p><strong>1. Create an explainer - wrapper around model and validation data.</strong></p>
<p>Since all other functions work in a model agnostic fashion, first we need to define a wrapper around the model. Here we are using the <code>explain()</code> function from <code>DALEX</code> package <span class="citation">(P. Biecek <a href="#ref-R-DALEX">2018</a><a href="#ref-R-DALEX">c</a>)</span>.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb43-2" data-line-number="2">explainer_rf &lt;-<span class="st"> </span><span class="kw">explain</span>(rf_model,</a>
<a class="sourceLine" id="cb43-3" data-line-number="3">      <span class="dt">data =</span> apartmentsTest, <span class="dt">y =</span> apartmentsTest<span class="op">$</span>m2.price)</a>
<a class="sourceLine" id="cb43-4" data-line-number="4">explainer_rf</a></code></pre></div>
<pre><code>## Model label:  randomForest 
## Model class:  randomForest.formula,randomForest 
## Data head  :
##      m2.price construction.year surface floor no.rooms    district
## 1001     4644              1976     131     3        5 Srodmiescie
## 1002     3082              1978     112     9        4     Mokotow</code></pre>
<p><strong>2. Define point of interest.</strong></p>
<p>Certeris Paribus profiles explore model around a single point.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1">new_apartment &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">construction.year =</span> <span class="dv">1965</span>, <span class="dt">no.rooms =</span> <span class="dv">5</span>, <span class="dt">surface =</span> <span class="dv">142</span>, <span class="dt">floor =</span> <span class="dv">8</span>)</a>
<a class="sourceLine" id="cb45-2" data-line-number="2">new_apartment</a></code></pre></div>
<pre><code>##   construction.year no.rooms surface floor
## 1              1965        5     142     8</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="kw">predict</span>(rf_model, new_apartment)</a></code></pre></div>
<pre><code>##        1 
## 2300.061</code></pre>
<p><strong>3. Calculate CP profiles</strong></p>
<p>The <code>ceteris_paribus()</code> function calculates CP profiles for selected model around selected observation.</p>
<p>By default CP profiles are calculated for all numerical variables. Use the <code>variables</code> argument to select subset of interesting variables.
The result from <code>ceteris_paribus()</code>function is a data frame with model predictions for modified points around the point of interest.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb49-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;ceterisParibus&quot;</span>)</a>
<a class="sourceLine" id="cb49-2" data-line-number="2">cp_rf &lt;-<span class="st"> </span><span class="kw">ceteris_paribus</span>(explainer_rf, new_apartment, </a>
<a class="sourceLine" id="cb49-3" data-line-number="3">                            <span class="dt">variables =</span> <span class="kw">c</span>(<span class="st">&quot;construction.year&quot;</span>, <span class="st">&quot;floor&quot;</span>))</a>
<a class="sourceLine" id="cb49-4" data-line-number="4">cp_rf</a></code></pre></div>
<pre><code>## Top profiles    : 
##     construction.year no.rooms surface floor   _yhat_           _vname_
## 1                1920        5     142     8 3096.582 construction.year
## 1.1              1921        5     142     8 3113.184 construction.year
## 1.2              1922        5     142     8 3107.749 construction.year
## 1.3              1923        5     142     8 3076.540 construction.year
## 1.4              1923        5     142     8 3076.540 construction.year
## 1.5              1924        5     142     8 3084.706 construction.year
##     _ids_      _label_
## 1       1 randomForest
## 1.1     1 randomForest
## 1.2     1 randomForest
## 1.3     1 randomForest
## 1.4     1 randomForest
## 1.5     1 randomForest
## 
## 
## Top observations:
##   construction.year no.rooms surface floor   _yhat_      _label_
## 1              1965        5     142     8 2300.061 randomForest</code></pre>
<p><strong>4. Plot CP profiles.</strong></p>
<p>Generic <code>plot()</code> function plot CP profiles. It returns a <code>ggplot2</code> object that can be polished if needed. Use additional arguments of this function to select colors and sizes for elements visible in the plot.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb51-1" data-line-number="1"><span class="kw">plot</span>(cp_rf) </a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>One of very useful features of <code>ceterisParibus</code> explainers is that profiles for two or more models may be superimposed in a single plot. This helps in model comparisons.</p>
<p>Let’s create a linear model for this dataset and repeat steps 1-3 for the lm model.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb52-1" data-line-number="1">lm_model &lt;-<span class="st"> </span><span class="kw">lm</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span></a>
<a class="sourceLine" id="cb52-2" data-line-number="2"><span class="st">      </span>no.rooms, <span class="dt">data =</span> apartments)</a>
<a class="sourceLine" id="cb52-3" data-line-number="3">explainer_lm &lt;-<span class="st"> </span><span class="kw">explain</span>(lm_model,</a>
<a class="sourceLine" id="cb52-4" data-line-number="4">      <span class="dt">data =</span> apartmentsTest, <span class="dt">y =</span> apartmentsTest<span class="op">$</span>m2.price)</a>
<a class="sourceLine" id="cb52-5" data-line-number="5">cp_lm &lt;-<span class="st"> </span><span class="kw">ceteris_paribus</span>(explainer_lm, new_apartment, </a>
<a class="sourceLine" id="cb52-6" data-line-number="6">                            <span class="dt">variables =</span> <span class="kw">c</span>(<span class="st">&quot;construction.year&quot;</span>, <span class="st">&quot;floor&quot;</span>))</a></code></pre></div>
<p>Now we can use function <code>plot()</code> to compare both models in a single chart. Additional argument <code>color = &quot;_label_&quot;</code> set color as a key for model.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb53-1" data-line-number="1"><span class="kw">plot</span>(cp_rf, cp_lm, <span class="dt">color =</span> <span class="st">&quot;_label_&quot;</span>)</a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
<p><strong>Oscillations</strong></p>
<p>The <code>calculate_oscillations()</code> function calculates oscillations for CP profiles.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb54-1" data-line-number="1">cp_rf_all &lt;-<span class="st"> </span><span class="kw">ceteris_paribus</span>(explainer_rf, new_apartment)</a>
<a class="sourceLine" id="cb54-2" data-line-number="2">co_rf_all &lt;-<span class="st"> </span><span class="kw">calculate_oscillations</span>(cp_rf_all)</a>
<a class="sourceLine" id="cb54-3" data-line-number="3">co_rf_all</a></code></pre></div>
<pre><code>##             _vname_ _ids_ oscillations
## 2           surface     1     652.6892
## 4          no.rooms     1     452.8753
## 3             floor     1     357.4222
## 1 construction.year     1     254.1506</code></pre>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb56-1" data-line-number="1"><span class="kw">plot</span>(co_rf_all)</a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p><strong>2D Ceteris Paribus profiles</strong></p>
<p>And the <code>what_if_2d()</code> function calculates 2D CP profiles.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb57-1" data-line-number="1">wi_rf_2d &lt;-<span class="st"> </span><span class="kw">what_if_2d</span>(explainer_rf, <span class="dt">observation =</span> new_apartment, </a>
<a class="sourceLine" id="cb57-2" data-line-number="2">                 <span class="dt">selected_variables =</span> <span class="kw">c</span>(<span class="st">&quot;surface&quot;</span>,<span class="st">&quot;floor&quot;</span>, <span class="st">&quot;construction.year&quot;</span>))</a>
<a class="sourceLine" id="cb57-3" data-line-number="3"><span class="kw">plot</span>(wi_rf_2d, <span class="dt">split_ncol =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-36-1.png" width="672" /></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ICEbox">
<p>Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015. “Peeking Inside the Black Box: Visualizing Statistical Learning with Plots of Individual Conditional Expectation.” <em>Journal of Computational and Graphical Statistics</em> 24 (1):44–65. <a href="https://doi.org/10.1080/10618600.2014.907095" class="uri">https://doi.org/10.1080/10618600.2014.907095</a>.</p>
</div>
<div id="ref-R-ceterisParibus">
<p>Biecek, Przemyslaw. 2018b. <em>CeterisParibus: Ceteris Paribus Profiles</em>. <a href="https://pbiecek.github.io/ceterisParibus/" class="uri">https://pbiecek.github.io/ceterisParibus/</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest" class="uri">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-R-DALEX">
<p>Biecek, Przemyslaw. 2018c. <em>DALEX: Descriptive mAchine Learning Explanations</em>. <a href="https://pbiecek.github.io/DALEX/" class="uri">https://pbiecek.github.io/DALEX/</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="LIME.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="model-level-explanations.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
