<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visualisation, Exploration and Explanation</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2019-02-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="introduction-2.html">
<link rel="next" href="variableEngeneering.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.1</b> The aim of the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#white-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.2</b> White-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#how-model-exploration-is-different-from-data-exploration"><i class="fa fa-check"></i><b>1.3</b> How model exploration is different from data exploration?</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.4</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#why-do-we-need-model-explainers"><i class="fa fa-check"></i><b>1.5</b> Why do we need model explainers?</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#model-lifecycle"><i class="fa fa-check"></i><b>1.6</b> Model lifecycle</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#code-snippets"><i class="fa fa-check"></i><b>1.7</b> Code snippets</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#glossary-notation"><i class="fa fa-check"></i><b>1.8</b> Glossary / Notation</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#the-structure-of-the-book"><i class="fa fa-check"></i><b>1.9</b> The structure of the book</a></li>
<li class="chapter" data-level="1.10" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.10</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.11" data-path="index.html"><a href="index.html#model-lifecycle-1"><i class="fa fa-check"></i><b>1.11</b> Model lifecycle</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="prediction-level-explanations.html"><a href="prediction-level-explanations.html"><i class="fa fa-check"></i>Prediction level explanations</a></li>
<li class="chapter" data-level="2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#approaches-to-prediction-explanations"><i class="fa fa-check"></i><b>2.1</b> Approaches to prediction explanations</a></li>
<li class="chapter" data-level="2.2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#three-single-laws"><i class="fa fa-check"></i><b>2.2</b> A bit of philosophy: Three Laws for Prediction Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html"><i class="fa fa-check"></i><b>3</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="3.1" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#intuition"><i class="fa fa-check"></i><b>3.1</b> Intuition</a></li>
<li class="chapter" data-level="3.2" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#method"><i class="fa fa-check"></i><b>3.2</b> Method</a></li>
<li class="chapter" data-level="3.3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#example-wine-quality"><i class="fa fa-check"></i><b>3.3</b> Example: Wine quality</a></li>
<li class="chapter" data-level="3.4" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#pros-and-cons"><i class="fa fa-check"></i><b>3.4</b> Pros and Cons</a></li>
<li class="chapter" data-level="3.5" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#code-snippets-1"><i class="fa fa-check"></i><b>3.5</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>4</b> Variable attributions</a><ul>
<li class="chapter" data-level="4.1" data-path="breakDown.html"><a href="breakDown.html#intuition-1"><i class="fa fa-check"></i><b>4.1</b> Intuition</a></li>
<li class="chapter" data-level="4.2" data-path="breakDown.html"><a href="breakDown.html#method-1"><i class="fa fa-check"></i><b>4.2</b> Method</a></li>
<li class="chapter" data-level="4.3" data-path="breakDown.html"><a href="breakDown.html#example-hire-or-fire"><i class="fa fa-check"></i><b>4.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="4.4" data-path="breakDown.html"><a href="breakDown.html#pros-and-cons-1"><i class="fa fa-check"></i><b>4.4</b> Pros and cons</a></li>
<li class="chapter" data-level="4.5" data-path="breakDown.html"><a href="breakDown.html#code-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html"><i class="fa fa-check"></i><b>5</b> Variable attribution with interactions</a><ul>
<li class="chapter" data-level="5.1" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#intuition-2"><i class="fa fa-check"></i><b>5.1</b> Intuition</a></li>
<li class="chapter" data-level="5.2" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#method-2"><i class="fa fa-check"></i><b>5.2</b> Method</a></li>
<li class="chapter" data-level="5.3" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#example-hire-or-fire-1"><i class="fa fa-check"></i><b>5.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="5.4" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#break-down-plots"><i class="fa fa-check"></i><b>5.4</b> Break Down Plots</a></li>
<li class="chapter" data-level="5.5" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#pros-and-cons-2"><i class="fa fa-check"></i><b>5.5</b> Pros and cons</a></li>
<li class="chapter" data-level="5.6" data-path="variable-attribution-with-interactions.html"><a href="variable-attribution-with-interactions.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>5.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>6</b> Average variable attributions</a><ul>
<li class="chapter" data-level="6.1" data-path="shapley.html"><a href="shapley.html#intuition-3"><i class="fa fa-check"></i><b>6.1</b> Intuition</a></li>
<li class="chapter" data-level="6.2" data-path="shapley.html"><a href="shapley.html#method-3"><i class="fa fa-check"></i><b>6.2</b> Method</a></li>
<li class="chapter" data-level="6.3" data-path="shapley.html"><a href="shapley.html#example-hire-or-fire-2"><i class="fa fa-check"></i><b>6.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="6.4" data-path="shapley.html"><a href="shapley.html#pros-and-cons-3"><i class="fa fa-check"></i><b>6.4</b> Pros and cons</a></li>
<li class="chapter" data-level="6.5" data-path="shapley.html"><a href="shapley.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>6.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>7</b> Local approximations with white-box model</a><ul>
<li class="chapter" data-level="7.1" data-path="LIME.html"><a href="LIME.html#intuition-4"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="LIME.html"><a href="LIME.html#method-4"><i class="fa fa-check"></i><b>7.2</b> Method</a></li>
<li class="chapter" data-level="7.3" data-path="LIME.html"><a href="LIME.html#example-hire-or-fire-3"><i class="fa fa-check"></i><b>7.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="7.4" data-path="LIME.html"><a href="LIME.html#pros-and-cons-4"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="LIME.html"><a href="LIME.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="LIME.html"><a href="LIME.html#the-lime-pacakge"><i class="fa fa-check"></i><b>7.5.1</b> <strong>The lime pacakge</strong></a></li>
<li class="chapter" data-level="7.5.2" data-path="LIME.html"><a href="LIME.html#the-live-package"><i class="fa fa-check"></i><b>7.5.2</b> <strong>The live package</strong></a></li>
<li class="chapter" data-level="7.5.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>7.5.3</b> <strong>The iml package</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>8</b> What-If analysis with the Ceteris Paribus Principle</a><ul>
<li class="chapter" data-level="8.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#intuition-5"><i class="fa fa-check"></i><b>8.2</b> Intuition</a></li>
<li class="chapter" data-level="8.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#method-5"><i class="fa fa-check"></i><b>8.3</b> Method</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#ceterisParibus1d"><i class="fa fa-check"></i><b>8.3.1</b> 1D profiles</a></li>
<li class="chapter" data-level="8.3.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#oscillations"><i class="fa fa-check"></i><b>8.3.2</b> Profile oscillations</a></li>
<li class="chapter" data-level="8.3.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#d-profiles"><i class="fa fa-check"></i><b>8.3.3</b> 2D profiles</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#local-model-fidelity"><i class="fa fa-check"></i><b>8.4</b> Local model fidelity</a></li>
<li class="chapter" data-level="8.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#example"><i class="fa fa-check"></i><b>8.5</b> Example</a></li>
<li class="chapter" data-level="8.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons-5"><i class="fa fa-check"></i><b>8.6</b> Pros and cons</a></li>
<li class="chapter" data-level="8.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>8.7</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html"><i class="fa fa-check"></i><b>9</b> Comparision of prediction level explainers</a><ul>
<li class="chapter" data-level="9.1" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html#when-to-use"><i class="fa fa-check"></i><b>9.1</b> When to use?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="10" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>10</b> Introduction</a><ul>
<li class="chapter" data-level="10.1" data-path="introduction-2.html"><a href="introduction-2.html#approaches-to-model-explanations"><i class="fa fa-check"></i><b>10.1</b> Approaches to model explanations</a></li>
<li class="chapter" data-level="10.2" data-path="introduction-2.html"><a href="introduction-2.html#a-bit-of-philosophy-three-laws-for-model-level-explanations"><i class="fa fa-check"></i><b>10.2</b> A bit of philosophy: Three Laws for Model Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variableImportance.html"><a href="variableImportance.html"><i class="fa fa-check"></i><b>11</b> Feature Importance</a><ul>
<li class="chapter" data-level="11.1" data-path="variableImportance.html"><a href="variableImportance.html#the-algorithm-for-model-agnostic-variable-importance-assessment"><i class="fa fa-check"></i><b>11.1</b> The Algorithm for Model Agnostic Variable Importance Assessment</a></li>
<li class="chapter" data-level="11.2" data-path="variableImportance.html"><a href="variableImportance.html#example-price-prediction"><i class="fa fa-check"></i><b>11.2</b> Example: Price prediction</a></li>
<li class="chapter" data-level="11.3" data-path="variableImportance.html"><a href="variableImportance.html#more-models"><i class="fa fa-check"></i><b>11.3</b> More models</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="variableEngeneering.html"><a href="variableEngeneering.html"><i class="fa fa-check"></i><b>12</b> Feature effects</a><ul>
<li class="chapter" data-level="12.1" data-path="variableEngeneering.html"><a href="variableEngeneering.html#partialDependence"><i class="fa fa-check"></i><b>12.1</b> Partial Dependency Plots</a><ul>
<li class="chapter" data-level="12.1.1" data-path="variableEngeneering.html"><a href="variableEngeneering.html#interactions-and-partial-dependency-profiles"><i class="fa fa-check"></i><b>12.1.1</b> Interactions and Partial Dependency profiles</a></li>
<li class="chapter" data-level="12.1.2" data-path="variableEngeneering.html"><a href="variableEngeneering.html#groups-of-partial-dependency-profiles"><i class="fa fa-check"></i><b>12.1.2</b> Groups of Partial Dependency profiles</a></li>
<li class="chapter" data-level="12.1.3" data-path="variableEngeneering.html"><a href="variableEngeneering.html#model-comparisons-with-partial-dependency-plots"><i class="fa fa-check"></i><b>12.1.3</b> Model comparisons with Partial Dependency Plots</a></li>
<li class="chapter" data-level="12.1.4" data-path="variableEngeneering.html"><a href="variableEngeneering.html#correlation-between-features"><i class="fa fa-check"></i><b>12.1.4</b> Correlation between features</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="variableEngeneering.html"><a href="variableEngeneering.html#merging-path-plots"><i class="fa fa-check"></i><b>12.2</b> Merging Path Plots</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>13</b> Other topics</a></li>
<li class="chapter" data-level="14" data-path="modelComparisons.html"><a href="modelComparisons.html"><i class="fa fa-check"></i><b>14</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="15" data-path="modelAuditing.html"><a href="modelAuditing.html"><i class="fa fa-check"></i><b>15</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="16" data-path="concept-drift.html"><a href="concept-drift.html"><i class="fa fa-check"></i><b>16</b> Concept Drift</a><ul>
<li class="chapter" data-level="16.1" data-path="concept-drift.html"><a href="concept-drift.html#introduction-3"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="concept-drift.html"><a href="concept-drift.html#covariate-drift"><i class="fa fa-check"></i><b>16.2</b> Covariate Drift</a></li>
<li class="chapter" data-level="16.3" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-2"><i class="fa fa-check"></i><b>16.3</b> Code snippets</a></li>
<li class="chapter" data-level="16.4" data-path="concept-drift.html"><a href="concept-drift.html#residual-drift"><i class="fa fa-check"></i><b>16.4</b> Residual Drift</a></li>
<li class="chapter" data-level="16.5" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-3"><i class="fa fa-check"></i><b>16.5</b> Code snippets</a></li>
<li class="chapter" data-level="16.6" data-path="concept-drift.html"><a href="concept-drift.html#model-drift"><i class="fa fa-check"></i><b>16.6</b> Model Drift</a></li>
<li class="chapter" data-level="16.7" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-4"><i class="fa fa-check"></i><b>16.7</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="17" data-path="DataSets.html"><a href="DataSets.html"><i class="fa fa-check"></i><b>17</b> Data Sets</a><ul>
<li class="chapter" data-level="17.1" data-path="DataSets.html"><a href="DataSets.html#HRdataset"><i class="fa fa-check"></i><b>17.1</b> Hire or Fire? HR in Call Center</a></li>
<li class="chapter" data-level="17.2" data-path="DataSets.html"><a href="DataSets.html#apartmentsDataset"><i class="fa fa-check"></i><b>17.2</b> How much does it cost? Price prediction for a square meter</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="Packages.html"><a href="Packages.html"><i class="fa fa-check"></i><b>18</b> Packages</a><ul>
<li class="chapter" data-level="18.1" data-path="Packages.html"><a href="Packages.html#arguments"><i class="fa fa-check"></i><b>18.1</b> Arguments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visualisation, Exploration and Explanation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variableImportance" class="section level1">
<h1><span class="header-section-number">Chapter 11</span> Feature Importance</h1>
<p>Methods presented in this chapter are useful for estimation of feature importance. There are many possible applications of such methods, for example:</p>
<ul>
<li>Feature importance may be used for filtering. Features that were not important may be removed from the data before next iteration of model training. Removal of the noise shall lead to a better model.</li>
<li>Identification of the most important features may be used as a validation of a model against domain knowledge. Just to make sure that it’s not like a single random feature dominates model predictions.</li>
<li>Identification of the most important features may increase the domain knowledge.</li>
<li>Comparison of feature importance between different models helps to understand how different models handle particular features.</li>
<li>Ranking of feature importance helps to decide in what order we shall perform further model exploration, in what order we shall examine particular feature effects.</li>
</ul>
<p>There are many methods for assessment of feature importance. In general we may divide them into two groups, methods that are model specific and methods that are model agnostic.</p>
<p>Some models like random forest, extreme gradient boosting, linear models and many others have their own ways to assess feature importance. Such method are linked with the particular structure of the model. In terms of linear models such specific measures are linked with normalized regression coefficients of p-values. For tree based ensembles such measures may be based on utilization of particular features in particular trees, see <span class="citation">(Paluszynska and Biecek <a href="#ref-randomForestExplainer">2017</a><a href="#ref-randomForestExplainer">a</a>)</span> or <span class="citation">(Foster <a href="#ref-xgboostExplainer">2017</a>)</span>.</p>
<p>But in this book we are focused on methods that are model agnostic. The may reason for that is</p>
<ul>
<li>First, be able to apply this method to any predictive model,</li>
<li>Second, (which is maybe even more important) to be able to compare methods between models of different structure.</li>
</ul>
<p>Model agnostic methods cannot assume anything about the model structure and we do not want to refit a model. The method that is presented below is described in details in the <span class="citation">(Fisher, Rudin, and Dominici <a href="#ref-variableImportancePermutations">2018</a>)</span>.
The main idea is to measure how much the model fit will decrease if a selected feature or group of features will be cancelled out. Here cancellation means perturbations like resampling from empirical distribution of just permutation.</p>
<p>The method can be used to measure importance of single features, pairs or larger subsets. For the simplicity below we describe algorithm for single features, but it is straight forward to use it for larger subsets of features.</p>
<div id="the-algorithm-for-model-agnostic-variable-importance-assessment" class="section level2">
<h2><span class="header-section-number">11.1</span> The Algorithm for Model Agnostic Variable Importance Assessment</h2>
<p>Let <span class="math inline">\(\mathcal L(M(X), y)\)</span> be a loss function that calculates goodness of fit of a model predictions calculated for data <span class="math inline">\(X\)</span> and target <span class="math inline">\(y\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Let <span class="math inline">\(\mathcal F\)</span> be a set of features, for each feature <span class="math inline">\(f \in \mathcal F\)</span> do steps 2-5</li>
<li>Create a new data <span class="math inline">\(X^{-f}\)</span> with feature <span class="math inline">\(f\)</span> resampled.</li>
<li>Calculate model predictions for the new data <span class="math inline">\(X^{f*}\)</span>, they will be denoted as <span class="math inline">\(M(X^{-f})\)</span>.</li>
<li>Calculate loss function for models predictions on perturbed data
<span class="math display">\[
L^{-f} = \mathcal L(M(X^{-f}), y)
\]</span></li>
<li>Feature importance may be calculated as difference or ration of the original loss and loss on perturbed data, i.e. <span class="math inline">\(fip(f) = L^f - L\)</span> or <span class="math inline">\(fip(f) = L^f/L\)</span>.</li>
</ol>
<p>Note that ranking of feature importance will be the same for the difference and the ratio since the loss <span class="math inline">\(L\)</span> is the same.</p>
<p>As we will see below, on diagnostic plot it may be more useful to present loss functions for perturbed data rather than direct feature importance.</p>
</div>
<div id="example-price-prediction" class="section level2">
<h2><span class="header-section-number">11.2</span> Example: Price prediction</h2>
<p>Let’s create a regression model for prediction of apartment prices.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb67-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb67-2" data-line-number="2"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb67-3" data-line-number="3"><span class="kw">set.seed</span>(<span class="dv">59</span>)</a>
<a class="sourceLine" id="cb67-4" data-line-number="4">model_rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb67-5" data-line-number="5"><span class="st">                           </span>no.rooms <span class="op">+</span><span class="st"> </span>district, <span class="dt">data =</span> apartments)</a></code></pre></div>
<p>A popular loss function for regression model is the root mean square loss
<span class="math display">\[
  L(x, y) = \sqrt{\frac1n \sum_{i=1}^n (x_i - y_i)^2}
\]</span></p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb68-1" data-line-number="1"><span class="kw">loss_root_mean_square</span>(</a>
<a class="sourceLine" id="cb68-2" data-line-number="2"><span class="kw">predict</span>(model_rf, apartments), </a>
<a class="sourceLine" id="cb68-3" data-line-number="3">apartments<span class="op">$</span>m2.price</a>
<a class="sourceLine" id="cb68-4" data-line-number="4">)</a></code></pre></div>
<pre><code>## [1] 193.8477</code></pre>
<p>Let’s calculate feature importance</p>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb70-1" data-line-number="1">explainer_rf &lt;-<span class="st"> </span><span class="kw">explain</span>(model_rf, </a>
<a class="sourceLine" id="cb70-2" data-line-number="2">            <span class="dt">data =</span> apartmentsTest[,<span class="dv">2</span><span class="op">:</span><span class="dv">6</span>], <span class="dt">y =</span> apartmentsTest<span class="op">$</span>m2.price)</a>
<a class="sourceLine" id="cb70-3" data-line-number="3">vip &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_rf, </a>
<a class="sourceLine" id="cb70-4" data-line-number="4">            <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb70-5" data-line-number="5">vip</a></code></pre></div>
<pre><code>##            variable dropout_loss        label
## 1      _full_model_     285.1355 randomForest
## 2          no.rooms     391.0710 randomForest
## 3 construction.year     410.5866 randomForest
## 4             floor     445.2164 randomForest
## 5           surface     480.1431 randomForest
## 6          district     843.6519 randomForest
## 7        _baseline_    1081.3710 randomForest</code></pre>
<p>On a diagnostic plot is useful to present feature importance as an interval that start in a loss and ends in a loss of perturbed data.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb72-1" data-line-number="1"><span class="kw">plot</span>(vip)</a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
</div>
<div id="more-models" class="section level2">
<h2><span class="header-section-number">11.3</span> More models</h2>
<p>Much more can be read from feature importance plots if we compare models of a different structure.
Let’s train three predictive models trained on <code>apartments</code> dataset from the <code>DALEX</code> package. Random Forest model <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span> (elastic but biased), Support Vector Machines model <span class="citation">(Meyer et al. <a href="#ref-R-e1071">2017</a>)</span> (large variance on boundaries) and Linear Model (stable but not very elastic).
Presented examples are for regression (prediction of square meter price), but the CP profiles may be used in the same way for classification.</p>
<p>Let’s fit these three models.</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb73-1" data-line-number="1"><span class="kw">library</span>(<span class="st">&quot;DALEX&quot;</span>)</a>
<a class="sourceLine" id="cb73-2" data-line-number="2">model_lm &lt;-<span class="st"> </span><span class="kw">lm</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb73-3" data-line-number="3"><span class="st">                      </span>no.rooms <span class="op">+</span><span class="st"> </span>district, <span class="dt">data =</span> apartments)</a>
<a class="sourceLine" id="cb73-4" data-line-number="4"></a>
<a class="sourceLine" id="cb73-5" data-line-number="5"><span class="kw">library</span>(<span class="st">&quot;randomForest&quot;</span>)</a>
<a class="sourceLine" id="cb73-6" data-line-number="6"><span class="kw">set.seed</span>(<span class="dv">59</span>)</a>
<a class="sourceLine" id="cb73-7" data-line-number="7">model_rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb73-8" data-line-number="8"><span class="st">                      </span>no.rooms <span class="op">+</span><span class="st"> </span>district, <span class="dt">data =</span> apartments)</a>
<a class="sourceLine" id="cb73-9" data-line-number="9"></a>
<a class="sourceLine" id="cb73-10" data-line-number="10"><span class="kw">library</span>(<span class="st">&quot;e1071&quot;</span>)</a>
<a class="sourceLine" id="cb73-11" data-line-number="11">model_svm &lt;-<span class="st"> </span><span class="kw">svm</span>(m2.price <span class="op">~</span><span class="st"> </span>construction.year <span class="op">+</span><span class="st"> </span>surface <span class="op">+</span><span class="st"> </span>floor <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb73-12" data-line-number="12"><span class="st">                         </span>no.rooms <span class="op">+</span><span class="st"> </span>district, <span class="dt">data =</span> apartments)</a></code></pre></div>
<p>For these models we use <code>DALEX</code> explainers created with <code>explain()</code> function. These explainers wrap models, predict functions and validation data.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb74-1" data-line-number="1">explainer_lm &lt;-<span class="st"> </span><span class="kw">explain</span>(model_lm, </a>
<a class="sourceLine" id="cb74-2" data-line-number="2">                       <span class="dt">data =</span> apartmentsTest[,<span class="dv">2</span><span class="op">:</span><span class="dv">6</span>], <span class="dt">y =</span> apartmentsTest<span class="op">$</span>m2.price)</a>
<a class="sourceLine" id="cb74-3" data-line-number="3">vip_lm &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_lm, </a>
<a class="sourceLine" id="cb74-4" data-line-number="4">            <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb74-5" data-line-number="5">vip_lm</a></code></pre></div>
<pre><code>##            variable dropout_loss label
## 1      _full_model_     282.0062    lm
## 2 construction.year     281.9007    lm
## 3          no.rooms     292.8398    lm
## 4             floor     492.0857    lm
## 5           surface     614.9198    lm
## 6          district    1002.3487    lm
## 7        _baseline_    1193.6209    lm</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb76-1" data-line-number="1">explainer_rf &lt;-<span class="st"> </span><span class="kw">explain</span>(model_rf, </a>
<a class="sourceLine" id="cb76-2" data-line-number="2">                       <span class="dt">data =</span> apartmentsTest[,<span class="dv">2</span><span class="op">:</span><span class="dv">6</span>], <span class="dt">y =</span> apartmentsTest<span class="op">$</span>m2.price)</a>
<a class="sourceLine" id="cb76-3" data-line-number="3">vip_rf &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_rf, </a>
<a class="sourceLine" id="cb76-4" data-line-number="4">            <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb76-5" data-line-number="5">vip_rf</a></code></pre></div>
<pre><code>##            variable dropout_loss        label
## 1      _full_model_     293.2729 randomForest
## 2          no.rooms     389.4526 randomForest
## 3 construction.year     416.1154 randomForest
## 4             floor     453.9195 randomForest
## 5           surface     480.4062 randomForest
## 6          district     867.7050 randomForest
## 7        _baseline_    1116.2616 randomForest</code></pre>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb78-1" data-line-number="1">explainer_svm &lt;-<span class="st"> </span><span class="kw">explain</span>(model_svm, </a>
<a class="sourceLine" id="cb78-2" data-line-number="2">                       <span class="dt">data =</span> apartmentsTest[,<span class="dv">2</span><span class="op">:</span><span class="dv">6</span>], <span class="dt">y =</span> apartmentsTest<span class="op">$</span>m2.price)</a>
<a class="sourceLine" id="cb78-3" data-line-number="3">vip_svm &lt;-<span class="st"> </span><span class="kw">variable_importance</span>(explainer_svm, </a>
<a class="sourceLine" id="cb78-4" data-line-number="4">            <span class="dt">loss_function =</span> loss_root_mean_square)</a>
<a class="sourceLine" id="cb78-5" data-line-number="5">vip_svm</a></code></pre></div>
<pre><code>##            variable dropout_loss label
## 1      _full_model_     157.7938   svm
## 2          no.rooms     221.4595   svm
## 3 construction.year     365.2600   svm
## 4             floor     439.8724   svm
## 5           surface     527.2598   svm
## 6          district     942.8512   svm
## 7        _baseline_    1203.7571   svm</code></pre>
<p>Let’s plot feature importance for all three models on a single plot.</p>
<p>Intervals start in a different values, thus we can read that loss for SVM model is the lowest.</p>
<p>When we compare other features it looks like in all models the <code>district</code> is the most important feature followed by <code>surface</code> and <code>floor</code>.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb80-1" data-line-number="1"><span class="kw">plot</span>(vip_rf, vip_svm, vip_lm)</a></code></pre></div>
<p><img src="PM_VEE_files/figure-html/unnamed-chunk-46-1.png" width="672" /></p>
<p>There is interesting difference between linear model and others in the way how important is the <code>construction.year</code>. For linear model this variable is not importance, while for remaining two models there is some importance.</p>
<p>In the next chapter we will see how this is possible.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-randomForestExplainer">
<p>Paluszynska, Aleksandra, and Przemyslaw Biecek. 2017a. <em>RandomForestExplainer: A Set of Tools to Understand What Is Happening Inside a Random Forest</em>. <a href="https://github.com/MI2DataLab/randomForestExplainer">https://github.com/MI2DataLab/randomForestExplainer</a>.</p>
</div>
<div id="ref-xgboostExplainer">
<p>Foster, David. 2017. <em>XgboostExplainer: An R Package That Makes Xgboost Models Fully Interpretable</em>. <a href="https://github.com/AppliedDataSciencePartners/xgboostExplainer/">https://github.com/AppliedDataSciencePartners/xgboostExplainer/</a>.</p>
</div>
<div id="ref-variableImportancePermutations">
<p>Fisher, Aaron, Cynthia Rudin, and Francesca Dominici. 2018. “Model Class Reliance: Variable Importance Measures for Any Machine Learning Model Class, from the ’Rashomon’ Perspective.” <em>Journal of Computational and Graphical Statistics</em>. <a href="http://arxiv.org/abs/1801.01489">http://arxiv.org/abs/1801.01489</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-R-e1071">
<p>Meyer, David, Evgenia Dimitriadou, Kurt Hornik, Andreas Weingessel, and Friedrich Leisch. 2017. <em>E1071: Misc Functions of the Department of Statistics, Probability Theory Group (Formerly: E1071), Tu Wien</em>. <a href="https://CRAN.R-project.org/package=e1071">https://CRAN.R-project.org/package=e1071</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-2.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="variableEngeneering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
