<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visualisation, Exploration and Explanation</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visualisation, Exploration and Explanation" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2018-09-29">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  

<link rel="next" href="prediction-level-explanations.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#white-box-models-vs-black-box-models"><i class="fa fa-check"></i><b>1.1</b> White-box models vs Black-box models</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#model-agnostic-vs-model-specific"><i class="fa fa-check"></i><b>1.2</b> Model agnostic vs Model specific</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#why-do-we-need-model-explainers"><i class="fa fa-check"></i><b>1.3</b> Why do we need model explainers?</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#how-model-exploration-is-different-from-data-exploration"><i class="fa fa-check"></i><b>1.4</b> How model exploration is different from data exploration?</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#code-snippets"><i class="fa fa-check"></i><b>1.5</b> Code snippets</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#glossary-notation"><i class="fa fa-check"></i><b>1.6</b> Glossary / Notation</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.7</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="prediction-level-explanations.html"><a href="prediction-level-explanations.html"><i class="fa fa-check"></i>Prediction level explanations</a></li>
<li class="chapter" data-level="2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#approaches-to-prediction-explanations"><i class="fa fa-check"></i><b>2.1</b> Approaches to prediction explanations</a></li>
<li class="chapter" data-level="2.2" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html#three-single-laws"><i class="fa fa-check"></i><b>2.2</b> A bit of philosophy: Three Laws for Prediction Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html"><i class="fa fa-check"></i><b>3</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="3.1" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#intuition"><i class="fa fa-check"></i><b>3.1</b> Intuition</a></li>
<li class="chapter" data-level="3.2" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#method"><i class="fa fa-check"></i><b>3.2</b> Method</a></li>
<li class="chapter" data-level="3.3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#example-wine-quality"><i class="fa fa-check"></i><b>3.3</b> Example: Wine quality</a></li>
<li class="chapter" data-level="3.4" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#pros-and-cons"><i class="fa fa-check"></i><b>3.4</b> Pros and Cons</a></li>
<li class="chapter" data-level="3.5" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#code-snippets-1"><i class="fa fa-check"></i><b>3.5</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>4</b> Sequential variable attributions</a><ul>
<li class="chapter" data-level="4.1" data-path="breakDown.html"><a href="breakDown.html#intuition-1"><i class="fa fa-check"></i><b>4.1</b> Intuition</a></li>
<li class="chapter" data-level="4.2" data-path="breakDown.html"><a href="breakDown.html#method-1"><i class="fa fa-check"></i><b>4.2</b> Method</a></li>
<li class="chapter" data-level="4.3" data-path="breakDown.html"><a href="breakDown.html#example-hire-or-fire"><i class="fa fa-check"></i><b>4.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="4.4" data-path="breakDown.html"><a href="breakDown.html#pros-and-cons-1"><i class="fa fa-check"></i><b>4.4</b> Pros and cons</a></li>
<li class="chapter" data-level="4.5" data-path="breakDown.html"><a href="breakDown.html#code-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html"><i class="fa fa-check"></i><b>5</b> Sequential variable attribution with interactions</a><ul>
<li class="chapter" data-level="5.1" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html#intuition-2"><i class="fa fa-check"></i><b>5.1</b> Intuition</a></li>
<li class="chapter" data-level="5.2" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html#method-2"><i class="fa fa-check"></i><b>5.2</b> Method</a></li>
<li class="chapter" data-level="5.3" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html#example-hire-or-fire-1"><i class="fa fa-check"></i><b>5.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="5.4" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html#break-down-plots"><i class="fa fa-check"></i><b>5.4</b> Break Down Plots</a></li>
<li class="chapter" data-level="5.5" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html#pros-and-cons-2"><i class="fa fa-check"></i><b>5.5</b> Pros and cons</a></li>
<li class="chapter" data-level="5.6" data-path="sequential-variable-attribution-with-interactions.html"><a href="sequential-variable-attribution-with-interactions.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>5.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>6</b> Average variable attributions</a><ul>
<li class="chapter" data-level="6.1" data-path="shapley.html"><a href="shapley.html#intuition-3"><i class="fa fa-check"></i><b>6.1</b> Intuition</a></li>
<li class="chapter" data-level="6.2" data-path="shapley.html"><a href="shapley.html#method-3"><i class="fa fa-check"></i><b>6.2</b> Method</a></li>
<li class="chapter" data-level="6.3" data-path="shapley.html"><a href="shapley.html#example-hire-or-fire-2"><i class="fa fa-check"></i><b>6.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="6.4" data-path="shapley.html"><a href="shapley.html#pros-and-cons-3"><i class="fa fa-check"></i><b>6.4</b> Pros and cons</a></li>
<li class="chapter" data-level="6.5" data-path="shapley.html"><a href="shapley.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>6.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>7</b> Local approximations with white-box model</a><ul>
<li class="chapter" data-level="7.1" data-path="LIME.html"><a href="LIME.html#intuition-4"><i class="fa fa-check"></i><b>7.1</b> Intuition</a></li>
<li class="chapter" data-level="7.2" data-path="LIME.html"><a href="LIME.html#method-4"><i class="fa fa-check"></i><b>7.2</b> Method</a></li>
<li class="chapter" data-level="7.3" data-path="LIME.html"><a href="LIME.html#example-hire-or-fire-3"><i class="fa fa-check"></i><b>7.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="7.4" data-path="LIME.html"><a href="LIME.html#pros-and-cons-4"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="LIME.html"><a href="LIME.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="LIME.html"><a href="LIME.html#the-lime-pacakge"><i class="fa fa-check"></i><b>7.5.1</b> <strong>The lime pacakge</strong></a></li>
<li class="chapter" data-level="7.5.2" data-path="LIME.html"><a href="LIME.html#the-live-package"><i class="fa fa-check"></i><b>7.5.2</b> <strong>The live package</strong></a></li>
<li class="chapter" data-level="7.5.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>7.5.3</b> <strong>The iml package</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>8</b> What-If analysis with the Ceteris Paribus Principle</a><ul>
<li class="chapter" data-level="8.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-1"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#intuition-5"><i class="fa fa-check"></i><b>8.2</b> Intuition</a></li>
<li class="chapter" data-level="8.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#method-5"><i class="fa fa-check"></i><b>8.3</b> Method</a><ul>
<li class="chapter" data-level="8.3.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#ceterisParibus1d"><i class="fa fa-check"></i><b>8.3.1</b> 1D profiles</a></li>
<li class="chapter" data-level="8.3.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#oscillations"><i class="fa fa-check"></i><b>8.3.2</b> Profile oscillations</a></li>
<li class="chapter" data-level="8.3.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#d-profiles"><i class="fa fa-check"></i><b>8.3.3</b> 2D profiles</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#local-model-fidelity"><i class="fa fa-check"></i><b>8.4</b> Local model fidelity</a></li>
<li class="chapter" data-level="8.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#example"><i class="fa fa-check"></i><b>8.5</b> Example</a></li>
<li class="chapter" data-level="8.6" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons-5"><i class="fa fa-check"></i><b>8.6</b> Pros and cons</a></li>
<li class="chapter" data-level="8.7" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>8.7</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html"><i class="fa fa-check"></i><b>9</b> Comparision of prediction level explainers</a><ul>
<li class="chapter" data-level="9.1" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html#when-to-use"><i class="fa fa-check"></i><b>9.1</b> When to use?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="10" data-path="introduction-2.html"><a href="introduction-2.html"><i class="fa fa-check"></i><b>10</b> Introduction</a><ul>
<li class="chapter" data-level="10.1" data-path="introduction-2.html"><a href="introduction-2.html#a-bit-of-philosophy"><i class="fa fa-check"></i><b>10.1</b> A bit of philosophy</a></li>
<li class="chapter" data-level="10.2" data-path="introduction-2.html"><a href="introduction-2.html#example-price-prediction"><i class="fa fa-check"></i><b>10.2</b> Example: Price prediction</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="variable-importance.html"><a href="variable-importance.html"><i class="fa fa-check"></i><b>11</b> Variable Importance</a></li>
<li class="chapter" data-level="12" data-path="marginal-response.html"><a href="marginal-response.html"><i class="fa fa-check"></i><b>12</b> Marginal Response</a><ul>
<li class="chapter" data-level="12.1" data-path="marginal-response.html"><a href="marginal-response.html#partialDependence"><i class="fa fa-check"></i><b>12.1</b> Partial Dependency Plots</a></li>
<li class="chapter" data-level="12.2" data-path="marginal-response.html"><a href="marginal-response.html#merging-path-plots"><i class="fa fa-check"></i><b>12.2</b> Merging Path Plots</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="modelComparisons.html"><a href="modelComparisons.html"><i class="fa fa-check"></i><b>13</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="14" data-path="modelAuditing.html"><a href="modelAuditing.html"><i class="fa fa-check"></i><b>14</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="15" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>15</b> Other topics</a></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="16" data-path="DataSets.html"><a href="DataSets.html"><i class="fa fa-check"></i><b>16</b> Data Sets</a><ul>
<li class="chapter" data-level="16.1" data-path="DataSets.html"><a href="DataSets.html#HRdataset"><i class="fa fa-check"></i><b>16.1</b> Hire or Fire? HR in Call Center</a></li>
<li class="chapter" data-level="16.2" data-path="DataSets.html"><a href="DataSets.html#apartmentsDataset"><i class="fa fa-check"></i><b>16.2</b> How much does it cost? Price prediction for a square meter</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visualisation, Exploration and Explanation</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Predictive Models: Visualisation, Exploration and Explanation</h1>
<h3 class="subtitle"><em>With examples in R and Python</em></h3>
<h4 class="author"><em>Przemyslaw Biecek and Tomasz Burzykowski</em></h4>
<h4 class="date"><em>2018-09-29</em></h4>
</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<p>Predictive models are used to automatically guess (statisticians would say: estimate) one interesting variable based on other variables. Think about prediction of sales based on historical data, prediction of risk of heart disease based on patient characteristics, prediction of political attitudes based on facebook comments.</p>
<p>Predictive models were constructed through the whole human history. Think about Flooding of the Nile for example. More rigorous approach to model construction may be attributed to the method of least squares, published by Legendre in 1805, and by Gauss in 1809, more than two centuries ago. Number of applications in economy, medicine, biology, agriculture was growing. The term <em>regression</em> was coined by Francis Galton
in 1886, initially was referring to biological applications, today is used for various models that predict continues variable. Prediction of nominal variables is called <em>classification</em>, and its beginning may be attributed to works of Ronald Fisher in 1936.</p>
<p>During the last century we observed lot of developments in predictive models like linear models, generalized models, regression and classification trees, rule based models and many others. Developments in mathematical foundations of predictive models were boosted by increasing computational power of personal computers and availability of large datasets. So called the era of big data.</p>
<p>Increasing demand on predictive models favour models that are elastic, able to perform internally some feature engineering and leads to high precision of predictions.
Robust models are now created with ensembles of models. Techniques like bagging, boosting or model stacking gather hundreds or thousands of small model into a one super model. Large deep neural models have over bilion of parameters.</p>
<p>There is a cost of this progress. Large models are opaque, obscure, they act like black boxes. On one hand, human is unable to understand how thousands of coefficients affect the model response, one the another hand the model itself may be threated as a trade secret. And the worst part of this is that these models are not as good as we wish them to be.</p>
<p>Decieved by model performance, big names of model producer we tend to believe that these black boxes are unerring oracles. The thruth is that they are not. And we have more and more examples that model performance deteriorate with time or is biased in some sense.</p>
<p>An overview of real problems with large black box models may be found in an excellent book of Cathy O’Neil <span class="citation">(O’Neil <a href="#ref-ONeil">2016</a>)</span> on in her TED Talk ,,<em>The era of blind faith
in big data must end</em>’‘. Variouse examples show how models that are opaque and unregulated lead to higher discrimination of inequality. And there is more examples of such problems, see ,,<em>Google and the flu: how big data will help us make gigantic mistakes</em>’‘, ,,<em>Report: IBM Watson delivered ’unsafe and inaccurate’ cancer recommendations</em>’’.</p>
<p>Today the true bottleneck for predictive modelling is not the lack of data, nor lack of computational power, nor lack of elastic models. It’s lack of tools for model validation, explorations and explanations of model decisions.</p>
<p>In this book we present collection of methods that may be used for this purpose. It is a very active area of research and for sure more methods will be developed in this area. However here we present the mind-set, key problems and methods that are used in model exploration.</p>
<p><strong>This book is about</strong></p>
<ul>
<li>We show how to determine features that affect model response for a selected observation. In this book you will find theory and examples that explains prediction level methods like break down plots, ceteris paribus profiles, Local model approximations or Shapley values.</li>
<li>We present techniques to examine fully trained Machine Learning models as a whole. In this book you will find theory and examples that explains model globally like Partial Dependency Plots, Variable Importance Plots and others.</li>
<li>We present charts that are used to present key information in a quick way.</li>
<li>We present tools and methods for model comparison.</li>
<li>We present example code snippets for R and python that show how to use described methods.</li>
</ul>
<p><strong>This book is NOT about.</strong></p>
<ul>
<li>We do not focus on any specific model. Presented techniques are model agnostic and do not have any assumptions related to model structure.</li>
<li>We do not focus on the data exploration. There are very good books and techniques related to this, like R for Data Science <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a> or TODO</li>
<li>We do not focus on the process of model building. There are also very good books about this, see An Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a> or TODO</li>
<li>We do not focus on particular tools for model building, see Applied Predictive Modeling By Max Kuhn and Kjell Johnson <a href="http://appliedpredictivemodeling.com/" class="uri">http://appliedpredictivemodeling.com/</a></li>
</ul>
<p><strong>This book has following structure</strong></p>
<ul>
<li>In the Section 1 we introduce notation and vocabulary that will be used in this book. Same concepts have often different names in statistics and different in machine learning, thus show how to translate between these two worlds. In this section we also set expectations.</li>
<li>In the part <em>Prediction level explainers</em> we present techniques for exploration and explanations single model predictions.</li>
<li>In the part <em>Model level explainers</em> we present techniques for exploration and explanations model as a whole.</li>
</ul>
<p>Every method for model exploration is described in a separate section. In each such section you will find.</p>
<ul>
<li>Subsection <em>Introduction</em>, that explains the goal of the method and the general idea behind this method.</li>
<li>Subsection <em>The Algorithm</em>, that shows mathematical or computational details related to this methods. You can skip this section if you are not interested in details.</li>
<li>Subsection <em>Example</em>, that show an example application of this method with discussion of results.</li>
<li>Subsection <em>Pros and Cons</em>, that summarize pros and cons of this method and also give some guides when to use this method.</li>
<li>Subsection <em>Code snippets</em>, that show how to use this method in R and python. You can skip this section if you are not interested in implementation.</li>
</ul>
<div id="white-box-models-vs-black-box-models" class="section level2">
<h2><span class="header-section-number">1.1</span> White-box models vs Black-box models</h2>
<p>In this book we focus on black box models, i.e. models with complex structure, high number of coefficients that are hard to trace and understand by humans.</p>
<p>The opposite are white box models, that have structure easy to understand even for non specialist. Two most common classess of white box models are decision or regression trees (see an example in Figure <a href="index.html#fig:BILLCD8">1.1</a>) or models with additive structure, like this model for relative risk.</p>
<p><span class="math display">\[
RelativeRisk = 1 + 3.6 * [Breslow &gt; 2] - 2 * [TILs &gt; 0] 
\]</span></p>
<p>For white box models it is easy to understand how they are working from the model structure. It may be complicated to build the model, collect necessary data, do model validation, but once the model is derived the understanding is easy.</p>
<p>Understanding of the model structure gives us few benefits</p>
<ul>
<li>For any model prediction we can easily link model prediction with variables</li>
<li>We see which variables are used in the model and which are not, thus we may question the model, which variable X is not included.</li>
<li>We may challenge the model against the domain knowledge. As wee see how each variable influence the model prediction we may verify if it’s along domain knowledge.</li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:BILLCD8"></span>
<img src="figure/wbBILL8model.png" alt="(fig:BILLCD8) Example tree model for melanoma risk" width="50%" />
<p class="caption">
Figure 1.1: (fig:BILLCD8) Example tree model for melanoma risk
</p>
</div>
<p>Note, that being a white box model is not only about the structure, but also about the number of parameters. A classification tree with 100s of nodes is hard to understand, linear model with 100s of parameters is hard to understand.</p>
<p>Things that are natural for white box models are hard for black box models. For complex models we may not understand how and which features influence the model decision, is the model consistent with the domain knowledge. Tools presented in this book help to extract such information even from complex models.</p>
</div>
<div id="model-agnostic-vs-model-specific" class="section level2">
<h2><span class="header-section-number">1.2</span> Model agnostic vs Model specific</h2>
<p>Some classes of models attract higher interest than others or are developed for longer period of time. Thus some classes of models are quipped with very good tools for model exploration or visualisation.
Just to mention some of them:</p>
<ul>
<li>Linear models have lots of tools for model diagnostic and validation of model assumptions. Assumptions are defined in a strict way (normality, linear structure, homogenous variance) and can be validated with normality tests or plots (qq plot), diagnostic plots, tests for model structure (RESET test), tools for identification of outliers etc.</li>
<li>More complex models with additive structure, like proportional hazards models have tools that verifies model assumptions.</li>
<li>Random Forest model is equipped with out of bag method of evaluation of performance and few tools for measuring variable importance <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span>. Some tools were developed to extract information about possible interactions from the model structure <span class="citation">(Paluszynska and Biecek <a href="#ref-R-randomForestExplainer">2017</a>)</span>. Similar tools are developed to other ensembles of trees, like xgboost models <span class="citation">(Foster <a href="#ref-R-xgboostExplainer">2018</a>)</span>.</li>
<li>Neural Networks have large collection of dedicated explainers that use Layer-wise Relevance Propagation technique <span class="citation">(Bach et al. <a href="#ref-BachLWRP">2015</a>)</span> or Saliency Maps technique <span class="citation">(Simonyan, Vedaldi, and Zisserman <a href="#ref-SaliencyMaps">2013</a>)</span> or a mixed approach.</li>
</ul>
<p>List of model classes is much longer, and for every class there is a collection of tools to use.
But this variety of approaches leads to problems. (1) One cannot easily compare explanations for two models with different structures.
(2) Every time when a new architecture of new ensemble of models is proposed, we need to look for new methods of model exploration. (3) For some new models we may not have yet any tool for model explanation.</p>
<p>This book is focused on model agnostic techniques. Thus we do not assume anything about model structure. The model will be threated as a black box and the only operation that we will be able to perform is evaluation of a model in a selected point.</p>
<p>Hoever, even if we do not assume anything about the model, we have some assumptions about data. We assume that the model is a function of a form
<span class="math display">\[
f: R^p \rightarrow R
\]</span>
i.e. operates on a vector of <span class="math inline">\(p\)</span> values. This assumption is most suited with tabular data, is held for images, text data video and so on. It may not be suited to models with states, or models with memory as there the model output depends not only on model inputs.</p>
<p>Note also that if <span class="math inline">\(p\)</span> is high dimensional then techniques described here may not be enough to fully understand models with such large number of degrees of freedom.</p>
</div>
<div id="why-do-we-need-model-explainers" class="section level2">
<h2><span class="header-section-number">1.3</span> Why do we need model explainers?</h2>
<p>Machine Learning models have a wide range of applications in classification or regression problems. Due to the increasing computational power of computers and complexity of data sources, ML models are becoming more and more sophisticated. Models created with the use of techniques such as boosting or bagging of neural networks are parametrized by thousands of coefficients. They are obscure; it is hard to trace the link between input variables and model outcomes - in fact they are treated as black boxes. They are used because of their elasticity and high performance, but their deficiency in interpretability is one of their weakest sides.</p>
<p>In many applications we need to know, understand or prove how the input variables are used in the model. We need to know the impact of particular variables on the final model predictions. Thus we need tools that extract useful information from thousands of model parameters.</p>
<p>Tools for model exploration and model understanding have many applications. They may be useful during every phase of a model lifecycle.</p>
<p>Below we summaries how such tools will be useful during the model development, model deployment or model maintenance.</p>
<div class="figure" style="text-align: center"><span id="fig:modelLifetime"></span>
<img src="figure/modelLifetime.png" alt="(fig:modelLifetime) Example applications of explainers in different phases of model lifetime" width="90%" />
<p class="caption">
Figure 1.2: (fig:modelLifetime) Example applications of explainers in different phases of model lifetime
</p>
</div>
<p><strong>Model development</strong></p>
<p>Model building or model development is a phase in which one is looking for best available model.</p>
<p>In the Section <a href="marginal-response.html#partialDependence">12.1</a> we present tools for extraction of relations between features and target variable. Such methods may be used for feature engineering (assisted learning in which elastic black box model is used to learn features for the white box model). Learning from ML models may lead to model improvment.</p>
<p>In the Section <a href="modelComparisons.html#modelComparisons">13</a> we present tools that helps to compare models.</p>
<p>In the Section <a href="modelAuditing.html#modelAuditing">14</a> we present tools that help to validate model, audit model residuals, identify potential strange behaviors.</p>
<p>If for some observations we observe lack of fit, then through tools introduced in the Section <a href="variableAttributionMethods.html#variableAttributionMethods">3</a> we may verify which variables do and which do not influence model decisions. This may help to identify some problem in the model fit and in the end will help to correct the model.</p>
<p>Since the AutoML methods are being more and more popular, model explainers may actually help to understand how the model identified by AutoML method is working.</p>
<p>If we identify cases on which model is not working properly, then model explainers will help in model debugging. See an examples in the Section TODO.</p>
<p><strong>Model deployment</strong></p>
<p>Model deployment is a phase in which one wants final use trust in model decisions, understand these decisions and act accordingly. In some areas complex models are not being adopted because people do not understand nor trust them. Model explainers can change this and increase rate of aquisition of new models</p>
<p>Since most people would not trust in recommendations, that they do not understand, the key element here is to increase understanding related to features that affect model decisions.</p>
<p>In the Section <a href="variableAttributionMethods.html#variableAttributionMethods">3</a> we introduce tools that identify key features that drive model decisions.</p>
<p>In the Section <a href="ceterisParibus.html#ceterisParibus">8</a> we introduce tools for what-if analysis of model decisions.</p>
<p>In some areas there may be leagal expectations or regulations that requires that model predictions are explainable (see the right to explanation). See <span class="citation">(Lipton, Chouldechova, and McAuley <a href="#ref-2017arXiv171107076L">2017</a>)</span> or <span class="citation">(Tan et al. <a href="#ref-2017arXiv171006169T">2017</a>)</span> for example methods that identify bias in the data.</p>
<p><strong>Model maintenance</strong></p>
<p>Model maintenance is a phase in which one wants to make sure that model is still valid and suited to the new data. Due to concept drift or similar problems that may happen after some time, we need to monitor the model performance.</p>
<p>In the section <a href="marginal-response.html#partialDependence">12.1</a> we present tools that may compare how thw model response behaves on the new dataset. This helps to detect flaws in model assumptions and biases in the data.</p>
</div>
<div id="how-model-exploration-is-different-from-data-exploration" class="section level2">
<h2><span class="header-section-number">1.4</span> How model exploration is different from data exploration?</h2>
<p>Exploration and visualization of models is not that known as exploration and visualization of data.
As we will see in following chapters in both cases we may use similar charts and similar way to express ideas. This is because many people are already familiar with techniques for data visualization and when we do model visualization we want to take advantage of this knowledge.</p>
<p>Both in data visualization and in model visualization we use graphical representation to deliver some messages quicker in a form that is easier to digest.
Despite all similarites we need to keep in mind few key differences between these two wrods.</p>
<ul>
<li>Data is generated by some unknown phenomena and with data exploration and visualization we want to understand this phenomena. Models are created based on the data but in most cases we do not know how close are these models to unknown phenomena. So we do model exploration to validate if the model is correct. If the model is valid. In most cases we do not validate data if they are correct. So we are more skeptical about models than about data.</li>
<li>Data comes from some population; we treat data as a random sample, and there is some inherited randomness related to the sampling. On the opposite, models are just functions. Most models are not stochastic (or at least some models are not stochastic) and the randomness (if any) come from the fitting procedure not from the sampling.</li>
<li>Models may be inaccurate or biased. When we ask question like ,,How the model is working?’‘we also ask ,,Is the model accurate, can I trust it, does it behave well, how much I can trust it?’’. Similar question related to data do not question the data but question our understating of the data.</li>
</ul>
<p>To summaries. We may use similar techniques. But they are used to answer different questions.</p>
</div>
<div id="code-snippets" class="section level2">
<h2><span class="header-section-number">1.5</span> Code snippets</h2>
<p>TODO: Here we should tell why we present examples for DALEX.
And mention that there are also other functions that can be used.</p>
</div>
<div id="glossary-notation" class="section level2">
<h2><span class="header-section-number">1.6</span> Glossary / Notation</h2>
<p>Let <span class="math inline">\(f_{M}(x): \mathcal R^{d} \rightarrow \mathcal R\)</span> denote a predictive model, i.e. function that takes <span class="math inline">\(d\)</span> dimensional vector and calculate numerical score.
Dimenstions of the vector <span class="math inline">\(x\)</span> refer to different variables (aka features).</p>
<p>In sections in which we work with larger number of models we use subscript <span class="math inline">\(M\)</span> to index models. But to simplify notation, this subscript is omitted if profiles for only one model are considered.</p>
<p>Symbol <span class="math inline">\(x \in \mathcal R^d\)</span> refers to a point in the feature space. We use subscript <span class="math inline">\(x_i\)</span> to refer to a different data points and superscript <span class="math inline">\(x^j\)</span> to refer to specific dimensions. Additionally, let <span class="math inline">\(x^{-j}\)</span> denote all coordinates except <span class="math inline">\(j\)</span>-th and let <span class="math inline">\(x|^j=z\)</span> denote a data point <span class="math inline">\(x^*\)</span> with all coordinates equal to <span class="math inline">\(x\)</span> except coordinate <span class="math inline">\(j\)</span> equal to value <span class="math inline">\(z\)</span>. I.e. <span class="math inline">\(\forall_{i \neq {j}} x^i = x^{*,i}\)</span> and <span class="math inline">\(x^j = z\)</span>. In other words <span class="math inline">\(x|^j=z\)</span> denote a <span class="math inline">\(x\)</span> with <span class="math inline">\(j\)</span>th coordinate changed to <span class="math inline">\(z\)</span>.</p>
<ul>
<li><em>Black-box model</em> is a model with structure that is hard to understand for humans. Usually it refers to the number of model parameters. As different humans may be better in understanding more or less complex models, there is no strict threshold that makes model a black-box. But in practice for most humans this threshold is closed to 10 rather than 100.</li>
<li><em>White-box model</em>, opposite to Black-box model, is a model that is easy to understand to human. Maybe not for every human. Consider small linear models and small CAR trees as white box models.</li>
<li><em>Feature</em> or <em>Variable</em>, part of the model input space. Without large loss of generality we can assume that one feature is a single dimension in the input space. There are exceptions (among them: polynomials, interactions between variables, nominal variables), but they do not change the intuition.</li>
<li><em>Continuous variable</em>, a variable that can be presented as a number and the ordering makes some sense (zip codes or phone numbers are not considered as continuous variables). It does not need to be continuous in a mathematical sense. Counting variables (number of floors, steps) counts here as well.</li>
<li><em>Nominal variable</em>, opposite to <em>Continuous variables</em>, finite set of values that will not the threaded as a numeric</li>
</ul>
</div>
<div id="thanksto" class="section level2">
<h2><span class="header-section-number">1.7</span> Acknowledgements</h2>
<p>My work on interpretability has started during research trips within the RENOIR project (691152 - H2020/2016-2019). So I would like to thank prof. Janusz Holyst for the chance to take part in this project.</p>
<p>I would thank prof. Chris Drake for her hospitality. This book will never been created without perfect conditions that I found at your house in Woodland.</p>
<p>Also I would like to thank our editor John Kimmel. It is amazing, than when only I mention his name to authors, I always hear that he is the best editor they ever had.</p>
<p>This book is prepared with the <strong>bookdown</strong> package <span class="citation">(Xie <a href="#ref-R-bookdown">2018</a>)</span>, thanks to amazing work of Yihui Xie.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ONeil">
<p>O’Neil, Cathy. 2016. <em>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</em>. New York, NY, USA: Crown Publishing Group.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest" class="uri">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-R-randomForestExplainer">
<p>Paluszynska, Aleksandra, and Przemyslaw Biecek. 2017. <em>RandomForestExplainer: Explaining and Visualizing Random Forests in Terms of Variable Importance</em>. <a href="https://CRAN.R-project.org/package=randomForestExplainer" class="uri">https://CRAN.R-project.org/package=randomForestExplainer</a>.</p>
</div>
<div id="ref-R-xgboostExplainer">
<p>Foster, David. 2018. <em>XgboostExplainer: XGBoost Model Explainer</em>.</p>
</div>
<div id="ref-BachLWRP">
<p>Bach, Sebastian, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. “On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation.” Edited by Oscar Deniz Suarez. <em>PLOS ONE</em> 10 (7):e0130140. <a href="https://doi.org/10.1371/journal.pone.0130140" class="uri">https://doi.org/10.1371/journal.pone.0130140</a>.</p>
</div>
<div id="ref-SaliencyMaps">
<p>Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. 2013. “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps.” <em>CoRR</em> abs/1312.6034. <a href="http://arxiv.org/abs/1312.6034" class="uri">http://arxiv.org/abs/1312.6034</a>.</p>
</div>
<div id="ref-2017arXiv171107076L">
<p>Lipton, Z. C., A. Chouldechova, and J. McAuley. 2017. “Does mitigating ML’s impact disparity require treatment disparity?” <em>ArXiv E-Prints</em>, November.</p>
</div>
<div id="ref-2017arXiv171006169T">
<p>Tan, S., R. Caruana, G. Hooker, and Y. Lou. 2017. “Auditing Black-Box Models Using Transparent Model Distillation with Side Information.” <em>ArXiv E-Prints</em>, October.</p>
</div>
<div id="ref-R-bookdown">
<p>Xie, Yihui. 2018. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown" class="uri">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="prediction-level-explanations.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
