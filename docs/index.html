<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Models: Visual Exploration, Explanation and Debugging</title>
  <meta name="description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Models: Visual Exploration, Explanation and Debugging" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  <meta name="github-repo" content="pbiecek/PM_VEE" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Models: Visual Exploration, Explanation and Debugging" />
  
  <meta name="twitter:description" content="This book introduces key concepts for exploration, explanation and visualization of complex predictive models." />
  

<meta name="author" content="Przemyslaw Biecek and Tomasz Burzykowski">


<meta name="date" content="2019-04-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  

<link rel="next" href="DataSetsIntro.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global site tag (gtag.js) - Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-5650686-15', 'https://pbiecek.github.io/PM_VEE/', {
  'anonymizeIp': true
  , 'storage': 'none'
  , 'clientId': window.localStorage.getItem('ga_clientId')
});
ga(function(tracker) {
  window.localStorage.setItem('ga_clientId', tracker.get('clientId'));
});
ga('send', 'pageview');
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Models:<br/> Visualisation, Exploration and Explanation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#the-aim-of-the-book"><i class="fa fa-check"></i><b>1.1</b> The aim of the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#three-single-laws"><i class="fa fa-check"></i><b>1.2</b> A bit of philosophy: three laws of model explanation</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#terminology"><i class="fa fa-check"></i><b>1.3</b> Terminology</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#white-box-models-vs.black-box-models"><i class="fa fa-check"></i><b>1.4</b> White-box models vs. black-box models</a></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#model-visualization-exploration-and-explanation"><i class="fa fa-check"></i><b>1.5</b> Model visualization, exploration, and explanation</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#model-agnostic-vs.model-specific-approach"><i class="fa fa-check"></i><b>1.6</b> Model-agnostic vs. model-specific approach</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#code-snippets"><i class="fa fa-check"></i><b>1.7</b> Code snippets</a></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#the-structure-of-the-book"><i class="fa fa-check"></i><b>1.8</b> The structure of the book</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#thanksto"><i class="fa fa-check"></i><b>1.9</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html"><i class="fa fa-check"></i><b>2</b> Data Sets</a><ul>
<li class="chapter" data-level="2.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#TitanicDataset"><i class="fa fa-check"></i><b>2.1</b> Sinking of the RMS Titanic</a><ul>
<li class="chapter" data-level="2.1.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#data-exploration"><i class="fa fa-check"></i><b>2.1.1</b> Data exploration</a></li>
<li class="chapter" data-level="2.1.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_titanic_lmr"><i class="fa fa-check"></i><b>2.1.2</b> Logistic regression</a></li>
<li class="chapter" data-level="2.1.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_titanic_rf"><i class="fa fa-check"></i><b>2.1.3</b> Random forest</a></li>
<li class="chapter" data-level="2.1.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#gradient-boosting"><i class="fa fa-check"></i><b>2.1.4</b> Gradient boosting</a></li>
<li class="chapter" data-level="2.1.5" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#predictions_titanic"><i class="fa fa-check"></i><b>2.1.5</b> Model predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ApartmentDataset"><i class="fa fa-check"></i><b>2.2</b> Apartment prices</a><ul>
<li class="chapter" data-level="2.2.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#data-exploration-1"><i class="fa fa-check"></i><b>2.2.1</b> Data exploration</a></li>
<li class="chapter" data-level="2.2.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_apartments_lr"><i class="fa fa-check"></i><b>2.2.2</b> Linear regression</a></li>
<li class="chapter" data-level="2.2.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_apartments_rf"><i class="fa fa-check"></i><b>2.2.3</b> Random forest</a></li>
<li class="chapter" data-level="2.2.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#predictions_apartments"><i class="fa fa-check"></i><b>2.2.4</b> Model predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#HFDataset"><i class="fa fa-check"></i><b>2.3</b> Hire or fire</a><ul>
<li class="chapter" data-level="2.3.1" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_HR_mr"><i class="fa fa-check"></i><b>2.3.1</b> Multinomial logistic regression</a></li>
<li class="chapter" data-level="2.3.2" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#model_HR_rf"><i class="fa fa-check"></i><b>2.3.2</b> Random forest</a></li>
<li class="chapter" data-level="2.3.3" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#predictions_HR"><i class="fa fa-check"></i><b>2.3.3</b> Model predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="DataSetsIntro.html"><a href="DataSetsIntro.html#ListOfModels"><i class="fa fa-check"></i><b>2.4</b> List of models</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="instance-level-explanation.html"><a href="instance-level-explanation.html"><i class="fa fa-check"></i>Instance-level explanation</a></li>
<li class="chapter" data-level="3" data-path="PredictionExplainers.html"><a href="PredictionExplainers.html"><i class="fa fa-check"></i><b>3</b> Introduction</a></li>
<li class="chapter" data-level="4" data-path="ceterisParibus.html"><a href="ceterisParibus.html"><i class="fa fa-check"></i><b>4</b> Ceteris Paribus Profiles - a tool for What-If analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="ceterisParibus.html"><a href="ceterisParibus.html#introduction-1"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="ceterisParibus.html"><a href="ceterisParibus.html#intuition"><i class="fa fa-check"></i><b>4.2</b> Intuition</a></li>
<li class="chapter" data-level="4.3" data-path="ceterisParibus.html"><a href="ceterisParibus.html#method"><i class="fa fa-check"></i><b>4.3</b> Method</a></li>
<li class="chapter" data-level="4.4" data-path="ceterisParibus.html"><a href="ceterisParibus.html#pros-and-cons"><i class="fa fa-check"></i><b>4.4</b> Pros and cons</a></li>
<li class="chapter" data-level="4.5" data-path="ceterisParibus.html"><a href="ceterisParibus.html#code-snippets-for-r"><i class="fa fa-check"></i><b>4.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html"><i class="fa fa-check"></i><b>5</b> Ceteris Paribus Oscillations - a tool for local variable importance</a><ul>
<li class="chapter" data-level="5.1" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#introduction-2"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#intuition-1"><i class="fa fa-check"></i><b>5.2</b> Intuition</a></li>
<li class="chapter" data-level="5.3" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#method-1"><i class="fa fa-check"></i><b>5.3</b> Method</a></li>
<li class="chapter" data-level="5.4" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#pros-and-cons-1"><i class="fa fa-check"></i><b>5.4</b> Pros and cons</a></li>
<li class="chapter" data-level="5.5" data-path="ceterisParibusOscillations.html"><a href="ceterisParibusOscillations.html#code-snippets-for-r-1"><i class="fa fa-check"></i><b>5.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html"><i class="fa fa-check"></i><b>6</b> Ceteris-Paribus 2D Profiles - a tool for pairwise interactions</a><ul>
<li class="chapter" data-level="6.1" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#introduction-3"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#intuition-2"><i class="fa fa-check"></i><b>6.2</b> Intuition</a></li>
<li class="chapter" data-level="6.3" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#method-2"><i class="fa fa-check"></i><b>6.3</b> Method</a></li>
<li class="chapter" data-level="6.4" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#pros-and-cons-2"><i class="fa fa-check"></i><b>6.4</b> Pros and cons</a></li>
<li class="chapter" data-level="6.5" data-path="ceterisParibus2d.html"><a href="ceterisParibus2d.html#code-snippets-for-r-2"><i class="fa fa-check"></i><b>6.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html"><i class="fa fa-check"></i><b>7</b> Local diagnostic with Ceteris-Paribus profiles</a><ul>
<li class="chapter" data-level="7.1" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#introduction-4"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#intuition-3"><i class="fa fa-check"></i><b>7.2</b> Intuition</a></li>
<li class="chapter" data-level="7.3" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#method-3"><i class="fa fa-check"></i><b>7.3</b> Method</a><ul>
<li class="chapter" data-level="7.3.1" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#nearest-neighbors"><i class="fa fa-check"></i><b>7.3.1</b> Nearest neighbors</a></li>
<li class="chapter" data-level="7.3.2" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#profiles-for-neighbors"><i class="fa fa-check"></i><b>7.3.2</b> Profiles for neighbors</a></li>
<li class="chapter" data-level="7.3.3" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#residuals"><i class="fa fa-check"></i><b>7.3.3</b> Residuals</a></li>
<li class="chapter" data-level="7.3.4" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#local-fidelity-plot"><i class="fa fa-check"></i><b>7.3.4</b> Local Fidelity Plot</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#pros-and-cons-3"><i class="fa fa-check"></i><b>7.4</b> Pros and cons</a></li>
<li class="chapter" data-level="7.5" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#code-snippets-for-r-3"><i class="fa fa-check"></i><b>7.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="7.5.1" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#start-with-ceteris-paribus-profile"><i class="fa fa-check"></i><b>7.5.1</b> Start with Ceteris Paribus Profile</a></li>
<li class="chapter" data-level="7.5.2" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#add-profiles-for-neighbors"><i class="fa fa-check"></i><b>7.5.2</b> Add profiles for neighbors</a></li>
<li class="chapter" data-level="7.5.3" data-path="ceterisParibusWankardu.html"><a href="ceterisParibusWankardu.html#add-residuals-for-neighbors"><i class="fa fa-check"></i><b>7.5.3</b> Add residuals for neighbors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html"><i class="fa fa-check"></i><b>8</b> Variable attribution for linear models</a><ul>
<li class="chapter" data-level="8.1" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#introduction-5"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#intuition-4"><i class="fa fa-check"></i><b>8.2</b> Intuition</a></li>
<li class="chapter" data-level="8.3" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#method-4"><i class="fa fa-check"></i><b>8.3</b> Method</a></li>
<li class="chapter" data-level="8.4" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#example-wine-quality"><i class="fa fa-check"></i><b>8.4</b> Example: Wine quality</a></li>
<li class="chapter" data-level="8.5" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#pros-and-cons-4"><i class="fa fa-check"></i><b>8.5</b> Pros and Cons</a></li>
<li class="chapter" data-level="8.6" data-path="variableAttributionMethods.html"><a href="variableAttributionMethods.html#code-snippets-1"><i class="fa fa-check"></i><b>8.6</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="breakDown.html"><a href="breakDown.html"><i class="fa fa-check"></i><b>9</b> Variable attributions</a><ul>
<li class="chapter" data-level="9.1" data-path="breakDown.html"><a href="breakDown.html#intuition-5"><i class="fa fa-check"></i><b>9.1</b> Intuition</a></li>
<li class="chapter" data-level="9.2" data-path="breakDown.html"><a href="breakDown.html#method-5"><i class="fa fa-check"></i><b>9.2</b> Method</a></li>
<li class="chapter" data-level="9.3" data-path="breakDown.html"><a href="breakDown.html#example-hire-or-fire"><i class="fa fa-check"></i><b>9.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="9.4" data-path="breakDown.html"><a href="breakDown.html#pros-and-cons-5"><i class="fa fa-check"></i><b>9.4</b> Pros and cons</a></li>
<li class="chapter" data-level="9.5" data-path="breakDown.html"><a href="breakDown.html#code-snippets-for-r-4"><i class="fa fa-check"></i><b>9.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="iBreakDown.html"><a href="iBreakDown.html"><i class="fa fa-check"></i><b>10</b> Variable attribution with interactions</a><ul>
<li class="chapter" data-level="10.1" data-path="iBreakDown.html"><a href="iBreakDown.html#intuition-6"><i class="fa fa-check"></i><b>10.1</b> Intuition</a></li>
<li class="chapter" data-level="10.2" data-path="iBreakDown.html"><a href="iBreakDown.html#method-6"><i class="fa fa-check"></i><b>10.2</b> Method</a></li>
<li class="chapter" data-level="10.3" data-path="iBreakDown.html"><a href="iBreakDown.html#example-hire-or-fire-1"><i class="fa fa-check"></i><b>10.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="10.4" data-path="iBreakDown.html"><a href="iBreakDown.html#break-down-plots"><i class="fa fa-check"></i><b>10.4</b> Break Down Plots</a></li>
<li class="chapter" data-level="10.5" data-path="iBreakDown.html"><a href="iBreakDown.html#pros-and-cons-6"><i class="fa fa-check"></i><b>10.5</b> Pros and cons</a></li>
<li class="chapter" data-level="10.6" data-path="iBreakDown.html"><a href="iBreakDown.html#code-snippets-for-r-5"><i class="fa fa-check"></i><b>10.6</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="shapley.html"><a href="shapley.html"><i class="fa fa-check"></i><b>11</b> Average variable attributions</a><ul>
<li class="chapter" data-level="11.1" data-path="shapley.html"><a href="shapley.html#intuition-7"><i class="fa fa-check"></i><b>11.1</b> Intuition</a></li>
<li class="chapter" data-level="11.2" data-path="shapley.html"><a href="shapley.html#method-7"><i class="fa fa-check"></i><b>11.2</b> Method</a></li>
<li class="chapter" data-level="11.3" data-path="shapley.html"><a href="shapley.html#example-hire-or-fire-2"><i class="fa fa-check"></i><b>11.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="11.4" data-path="shapley.html"><a href="shapley.html#pros-and-cons-7"><i class="fa fa-check"></i><b>11.4</b> Pros and cons</a></li>
<li class="chapter" data-level="11.5" data-path="shapley.html"><a href="shapley.html#code-snippets-for-r-6"><i class="fa fa-check"></i><b>11.5</b> Code snippets for R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="LIME.html"><a href="LIME.html"><i class="fa fa-check"></i><b>12</b> Local approximations with white-box model</a><ul>
<li class="chapter" data-level="12.1" data-path="LIME.html"><a href="LIME.html#intuition-8"><i class="fa fa-check"></i><b>12.1</b> Intuition</a></li>
<li class="chapter" data-level="12.2" data-path="LIME.html"><a href="LIME.html#method-8"><i class="fa fa-check"></i><b>12.2</b> Method</a></li>
<li class="chapter" data-level="12.3" data-path="LIME.html"><a href="LIME.html#example-hire-or-fire-3"><i class="fa fa-check"></i><b>12.3</b> Example: Hire or Fire?</a></li>
<li class="chapter" data-level="12.4" data-path="LIME.html"><a href="LIME.html#pros-and-cons-8"><i class="fa fa-check"></i><b>12.4</b> Pros and cons</a></li>
<li class="chapter" data-level="12.5" data-path="LIME.html"><a href="LIME.html#code-snippets-for-r-7"><i class="fa fa-check"></i><b>12.5</b> Code snippets for R</a><ul>
<li class="chapter" data-level="12.5.1" data-path="LIME.html"><a href="LIME.html#the-lime-pacakge"><i class="fa fa-check"></i><b>12.5.1</b> <strong>The lime pacakge</strong></a></li>
<li class="chapter" data-level="12.5.2" data-path="LIME.html"><a href="LIME.html#the-live-package"><i class="fa fa-check"></i><b>12.5.2</b> <strong>The live package</strong></a></li>
<li class="chapter" data-level="12.5.3" data-path="LIME.html"><a href="LIME.html#the-iml-package"><i class="fa fa-check"></i><b>12.5.3</b> <strong>The iml package</strong></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html"><i class="fa fa-check"></i><b>13</b> Comparision of prediction level explainers</a><ul>
<li class="chapter" data-level="13.1" data-path="comparision-of-prediction-level-explainers.html"><a href="comparision-of-prediction-level-explainers.html#when-to-use"><i class="fa fa-check"></i><b>13.1</b> When to use?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="model-level-explanations.html"><a href="model-level-explanations.html"><i class="fa fa-check"></i>Model level explanations</a></li>
<li class="chapter" data-level="14" data-path="introduction-6.html"><a href="introduction-6.html"><i class="fa fa-check"></i><b>14</b> Introduction</a><ul>
<li class="chapter" data-level="14.1" data-path="introduction-6.html"><a href="introduction-6.html#approaches-to-model-explanations"><i class="fa fa-check"></i><b>14.1</b> Approaches to model explanations</a></li>
<li class="chapter" data-level="14.2" data-path="introduction-6.html"><a href="introduction-6.html#a-bit-of-philosophy-three-laws-for-model-level-explanations"><i class="fa fa-check"></i><b>14.2</b> A bit of philosophy: Three Laws for Model Level Explanations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="variableImportance.html"><a href="variableImportance.html"><i class="fa fa-check"></i><b>15</b> Feature Importance</a><ul>
<li class="chapter" data-level="15.1" data-path="variableImportance.html"><a href="variableImportance.html#permutation-based-feature-importance"><i class="fa fa-check"></i><b>15.1</b> Permutation Based Feature Importance</a></li>
<li class="chapter" data-level="15.2" data-path="variableImportance.html"><a href="variableImportance.html#example-titanic"><i class="fa fa-check"></i><b>15.2</b> Example: Titanic</a></li>
<li class="chapter" data-level="15.3" data-path="variableImportance.html"><a href="variableImportance.html#example-price-prediction"><i class="fa fa-check"></i><b>15.3</b> Example: Price prediction</a></li>
<li class="chapter" data-level="15.4" data-path="variableImportance.html"><a href="variableImportance.html#more-models"><i class="fa fa-check"></i><b>15.4</b> More models</a></li>
<li class="chapter" data-level="15.5" data-path="variableImportance.html"><a href="variableImportance.html#level-frequency"><i class="fa fa-check"></i><b>15.5</b> Level frequency</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="variableEngeneering.html"><a href="variableEngeneering.html"><i class="fa fa-check"></i><b>16</b> Feature effects</a><ul>
<li class="chapter" data-level="16.1" data-path="variableEngeneering.html"><a href="variableEngeneering.html#global-level-vs-instance-level-explanations"><i class="fa fa-check"></i><b>16.1</b> Global level vs instance level explanations</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html"><i class="fa fa-check"></i><b>17</b> Partial Dependency Profiles</a><ul>
<li class="chapter" data-level="17.1" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#definition"><i class="fa fa-check"></i><b>17.1</b> Definition</a></li>
<li class="chapter" data-level="17.2" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#estimation"><i class="fa fa-check"></i><b>17.2</b> Estimation</a></li>
<li class="chapter" data-level="17.3" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#clustered-partial-dependency-profiles"><i class="fa fa-check"></i><b>17.3</b> Clustered Partial Dependency Profiles</a></li>
<li class="chapter" data-level="17.4" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#grouped-partial-dependency-profiles"><i class="fa fa-check"></i><b>17.4</b> Grouped Partial Dependency Profiles</a></li>
<li class="chapter" data-level="17.5" data-path="partialDependenceProfiles.html"><a href="partialDependenceProfiles.html#contrastive-model-comparisons"><i class="fa fa-check"></i><b>17.5</b> Contrastive Model Comparisons</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html"><i class="fa fa-check"></i><b>18</b> Conditional Dependency Profiles</a><ul>
<li class="chapter" data-level="18.1" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#definition-1"><i class="fa fa-check"></i><b>18.1</b> Definition</a></li>
<li class="chapter" data-level="18.2" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#estimation-1"><i class="fa fa-check"></i><b>18.2</b> Estimation</a></li>
<li class="chapter" data-level="18.3" data-path="conditionalProfiles.html"><a href="conditionalProfiles.html#example"><i class="fa fa-check"></i><b>18.3</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html"><i class="fa fa-check"></i><b>19</b> Accumulated Local Profiles</a><ul>
<li class="chapter" data-level="19.1" data-path="accumulatedLocalProfiles.html"><a href="accumulatedLocalProfiles.html#definition-2"><i class="fa fa-check"></i><b>19.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="how-pd-cd-and-al-profiles-are-different-and-which-to-choose.html"><a href="how-pd-cd-and-al-profiles-are-different-and-which-to-choose.html"><i class="fa fa-check"></i><b>20</b> How PD, CD and AL Profiles are different and which to choose</a></li>
<li class="chapter" data-level="21" data-path="factorMerger.html"><a href="factorMerger.html"><i class="fa fa-check"></i><b>21</b> Merging Path Plots and Others</a></li>
<li class="chapter" data-level="22" data-path="other-topics.html"><a href="other-topics.html"><i class="fa fa-check"></i><b>22</b> Other topics</a></li>
<li class="chapter" data-level="23" data-path="modelComparisons.html"><a href="modelComparisons.html"><i class="fa fa-check"></i><b>23</b> Performance Diagnostic</a></li>
<li class="chapter" data-level="24" data-path="modelAuditing.html"><a href="modelAuditing.html"><i class="fa fa-check"></i><b>24</b> Residual Diagnostic</a></li>
<li class="chapter" data-level="25" data-path="concept-drift.html"><a href="concept-drift.html"><i class="fa fa-check"></i><b>25</b> Concept Drift</a><ul>
<li class="chapter" data-level="25.1" data-path="concept-drift.html"><a href="concept-drift.html#introduction-7"><i class="fa fa-check"></i><b>25.1</b> Introduction</a></li>
<li class="chapter" data-level="25.2" data-path="concept-drift.html"><a href="concept-drift.html#covariate-drift"><i class="fa fa-check"></i><b>25.2</b> Covariate Drift</a></li>
<li class="chapter" data-level="25.3" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-2"><i class="fa fa-check"></i><b>25.3</b> Code snippets</a></li>
<li class="chapter" data-level="25.4" data-path="concept-drift.html"><a href="concept-drift.html#residual-drift"><i class="fa fa-check"></i><b>25.4</b> Residual Drift</a></li>
<li class="chapter" data-level="25.5" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-3"><i class="fa fa-check"></i><b>25.5</b> Code snippets</a></li>
<li class="chapter" data-level="25.6" data-path="concept-drift.html"><a href="concept-drift.html#model-drift"><i class="fa fa-check"></i><b>25.6</b> Model Drift</a></li>
<li class="chapter" data-level="25.7" data-path="concept-drift.html"><a href="concept-drift.html#code-snippets-4"><i class="fa fa-check"></i><b>25.7</b> Code snippets</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendixes.html"><a href="appendixes.html"><i class="fa fa-check"></i>Appendixes</a></li>
<li class="chapter" data-level="26" data-path="DataSets.html"><a href="DataSets.html"><i class="fa fa-check"></i><b>26</b> Data Sets</a><ul>
<li class="chapter" data-level="26.1" data-path="DataSets.html"><a href="DataSets.html#HRdataset"><i class="fa fa-check"></i><b>26.1</b> Hire or Fire? HR in Call Center</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="Packages.html"><a href="Packages.html"><i class="fa fa-check"></i><b>27</b> Packages</a><ul>
<li class="chapter" data-level="27.1" data-path="Packages.html"><a href="Packages.html#arguments"><i class="fa fa-check"></i><b>27.1</b> Arguments</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/pbiecek/DALEX" target="blank">DALEX website</a></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Models: Visual Exploration, Explanation and Debugging</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Predictive Models: Visual Exploration, Explanation and Debugging</h1>
<h3 class="subtitle"><em>With examples in R and Python</em></h3>
<h4 class="author"><em>Przemyslaw Biecek and Tomasz Burzykowski</em></h4>
<h4 class="date"><em>2019-04-18</em></h4>
</div>
<div id="introduction" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Introduction</h1>
<div id="the-aim-of-the-book" class="section level2">
<h2><span class="header-section-number">1.1</span> The aim of the book</h2>
<p>Predictive models are used to guess (statisticians would say: predict) values of a variable of interest based on other variables. As an example, consider prediction of sales based on historical data, prediction of risk of heart disease based on patient’s characteristics, or prediction of political attitudes based on Facebook comments.</p>
<p>Predictive models have been constructed through the whole human history. Ancient Egyptians, for instance, used observations of rising of Sirius to predict flooding of the Nile. A more rigorous approach to model construction may be attributed to the method of least squares, published more than two centuries ago by Legendre in 1805 and by Gauss in 1809. With time, the number of applications in economy, medicine, biology,and agriculture was growing. The term <em>regression</em> was coined by Francis Galton in 1886. Initially, it was referring to biological applications, while today it is used for various models that allow prediction of continuous variables. Prediction of nominal variables is called <em>classification</em>, and its beginning may be attributed to works of Ronald Fisher in 1936.</p>
<p>During the last century, many statistical models that can be used for predictive purposes have been developed. These include linear models, generalized linear models, regression and classification trees, rule-based models, and many others. Developments in mathematical foundations of predictive models were boosted by increasing computational power of personal computers and availability of large datasets in the era of ,,big data’’ that we have entered.</p>
<p>With the increasing demand for predictive models, model features such as flexibility, ability to perform internally some feature engineering, and high precision of predictions are of interest. To obtain robust models, ensembles of models are used. Techniques like bagging, boosting, or model stacking combine hundreds or thousands of small models into a one super-model. Large deep neural models have over a bilion of parameters.</p>
<p>There is a cost of this progress. Complex models may seem to operate like ,,black boxes’‘. It may be difficult, or even impopssible, to understand how thousands of coefficients affect the model prediction. At the same time, complex models may not work as good as we would like them to do. An overview of real problems with large black-box models may be found in an excellent book of Cathy O’Neil <span class="citation">(O’Neil <a href="#ref-ONeil">2016</a>)</span> or in her TED Talk ,,<em>The era of blind faith in big data must end</em>’’. There is a growing number of examples of predictive models with performance that deteriorated over time or became biased in some sense. See, for instance, the issues related to the flu epidemic predictions by the Google Flu Trends model [Lazer et al Science 2014] or the problems with cancer recommndations based on the IBM Watson model [<a href="https://www.statnews.com/2017/09/05/watson-ibm-cancer/" class="uri">https://www.statnews.com/2017/09/05/watson-ibm-cancer/</a>].</p>
<p>Today the true bottleneck in predictive modelling is not the lack of data, nor the lack of computational power, nor the lack of flexible models. It is the lack of tools for model validation, model exploration, and explanation of model decisions. Thus, in this book, we present a collection of methods that may be used for this purpose. As development of such methods is a very active area of research and new methods become available almost on a continuous basis, we do not aim at being exhaustive. Rather, we present the mind-set, key problems, and several examples of methods that can be used in model exploration.</p>
<p>Lack of interpretability often leads to harmful situations. <em>Models are not working properly and are hard to debug.</em> For example, very famous Watson for Oncology was criticized by oncologists for delivering unsafe and inaccurate recommendations <span class="citation">(Ross and Swetliz <a href="#ref-IBMWatson">2018</a>)</span>.
<em>Results are biased in a systematic ways.</em> For example, Amazon (giant in AI) failed with system for CV screening, as it was biased against woman <span class="citation">(Dastin <a href="#ref-AmazonAI">2018</a>)</span>. Or the COMPAS algorithm for predicting recidivism discriminates against race <span class="citation">(Larson et al. <a href="#ref-COMPAS">2016</a>)</span>. These are serious violations of fairness and ethical principles.
<em>Data drift leads to the deterioration in models performance.</em> For example, very popular model Google Flu after two years gave worse predictions than a baseline <span class="citation">(Salzberg <a href="#ref-GoogleFLU">2014</a>)</span>.
The number of such examples grows rapidly. A reaction for some of these these problems are new legal regulations, like the General Data Protection Regulation <span class="citation">(GDPR <a href="#ref-EUGDPR">2018</a>)</span> and the <em>,,Right to Explanation’’</em>, a civic right to be given an explanation for an output of the automated algorithm <span class="citation">(Goodman and Flaxman <a href="#ref-RightToExpl">2016</a>)</span>. Some are already in use while new are being suggested <span class="citation">(Casey, Farhangi, and Vogl <a href="#ref-RightToExpl2">2018</a>)</span>, <span class="citation">(Ruiz <a href="#ref-RightToExpl3">2018</a>)</span>. It is an important topic and surprisingly, we still do not have good enough tools for verification, exploration and explanation of machine learning models.</p>
</div>
<div id="three-single-laws" class="section level2">
<h2><span class="header-section-number">1.2</span> A bit of philosophy: three laws of model explanation</h2>
<p>Seventy-six years ago Isaac Asimov forumlated <a href="https://en.wikipedia.org/wiki/Three_Laws_of_Robotics">Three Laws of Robotics</a>:
1) a robot may not injure a human being,
2) a robot must obey the orders given it by human beings, and
3) a robot must protect its own existence.</p>
<p>Today’s robots, like cleaning robots, robotic pets, or autonomous cars are far from being conscious enough to be under Asimov’s ethics. However, we are more and more surrounded by complex predictive models and algoritmhs used for decision making. Machine learning models are used in health care, politics, education, justice, and many other areas. The models and algorithms have far larger influence on our lives than physical robots. Yet, applications of such models are left unregulated despite examples of their potential harmfulness. See <em>Weapons of Math Destruction</em> by Cathy O’Neil <span class="citation">(O’Neil <a href="#ref-ONeil">2016</a>)</span> for an excellent overview of selected problems.</p>
<p>It’s clear that some we need to control the models and algorithms that may affect us. Thus, Asimov’s laws are referred to in the context of the discussion around <a href="https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence">Ethics of Artifical Intelligence</a>. Initiatives to formulate principles for the AI development have been undertaken, for instance, in the UK [Olhede &amp; Wolfe, Significance 2018, 15: 6-7]. Following Asimov’s approach, we could propose three requirements that any predictive model should fulfill:</p>
<ul>
<li><strong>Prediction’s justification</strong>. For every prediction of a model, one should be able to understand which variables affect the prediction and to which extent.</li>
<li><strong>Prediction’s speculation</strong>. For every prediction of a model, one should be able to understand how the model prediction would change if input variables changed.</li>
<li><strong>Prediction’s validation</strong> For every prediction of a model, one should be able to verify how strong is the evidence that confirms this particular prediction.</li>
</ul>
<p>We see two ways to comply with these requirements. One is to use only models that fulfill these conditions by design. However, a reduction in performance may be the price for transparency. Another is to use tools that allow, perhaps by using approximations, to ,,explain’’ predictions for any model. In our book, we will focus on the latter.</p>
</div>
<div id="terminology" class="section level2">
<h2><span class="header-section-number">1.3</span> Terminology</h2>
<p>It is worth noting that, when it comes to predictive models, the same concepts have often been given different names in statistics and in machine learning. For instance, in the statistical-modelling literature, one refers to ,,explanatory variables,’’ with ,,independent variables,’’ ,,predictors,’’ or ,,covariates’’ as often-used equivalents. Explanatory variables are used in the model as means to explain (predict) the ,,dependent variable,’’ also called ,,predicted’’ variable or ,,response.’’ In the machine-learning language, ,,input variables’’ or ,,features’’ are used to predict the ,,output’’ variable. In statistical modelling, models are fit to the data that contain ,,observations,’’ whereas in the machine-learning world a dataset may contain ,,instances.’’</p>
<p>To the extent possible, in our book we try to consistently use the statistical-modelling terminology. However, the reader may expect references to a ,,feature’’ here and there. Somewhat inconsistently, we also introduce the term ,,instance-level’’ explanation. Instance-level explanation methods are designed to extract information about the behavior of the model related to a specific observation or instance. On the other hand, ,,global’’ explanation techniques allow obtaining information about the behavior of the model for an entire dataset.</p>
<p>We consider models for dependent variables that can be continuous or nominal. The values of a continuous variable can be represented by numbers with an ordering that makes some sense (zip codes or phone numbers are not considered as continuous variables). A continuous variable does not have to be continuous in the mathematical sense; counts (number of floors, steps, etc.) will be treated as continuous variables as well. A nominal variable can assume only a finite set of values that cannot be given numeric values.</p>
<p>In this book we focus on ,,black-box’’ models. We discuss them in a bit more detail in the next section.</p>
</div>
<div id="white-box-models-vs.black-box-models" class="section level2">
<h2><span class="header-section-number">1.4</span> White-box models vs. black-box models</h2>
<p>Black-box models are models with a complex structure that is hard to understand by humans. Usually this refers to a large number of model coefficients. As humans may vary in their capacity of understanding complex models, there is no strict threshold for the number of coefficients that makes a model a black-box. In practice, for most humans this threshold is probably closer to 10 than to 100.</p>
<p>A ,,white-box’’ model, which is opposite to a ,,black-box’’ one, is a model that is easy to understand by a human (though maybe not by every human). It has got a simple structure and a limited number of coefficients. The two most common classess of white-box models are decision or regression trees (see an example in Figure <a href="#fig:BILLCD8"><strong>??</strong></a>) or models with an additive structure, like the following model for mortality risk in melanoma patients:</p>
<p><span class="math display">\[
RelativeRisk = 1 + 3.6 * [Breslow &gt; 2] - 2 * [TILs &gt; 0] 
\]</span></p>
<p>In the model, two explanatory variables are used: an indicator whether the thickness of the lesion according to the Breslow scale is larger than 2 mm and an indicator whether the percentage of tumor-infiltrating lymphocytes (TILs) was larger than 0.</p>
<p>The structure of a white box-model is, in general, easy to understand. It may be difficult to collect the necessary data, build the model, fit it to the data, and/or perform model validation, but once the model has been developed its interpretation and mode of working is straightforward.</p>
<p>Why is it important to understand the model structure? There are several important advantages. If the model structure is clear, we can easily see which variables are included in the model and which are not. Hence, we may be able to, for instance, question the model when a particular explanatory variable was excluded from it. Also, in case of a model with a clear structure and a limited number of coefficients, we can easily link changes in model predictions with changes in particular explanatory variables. This, in turn, may allow us to challenge the model against the domain knowledge if, for instance, the effect of a particular variable on predictions is inconsistent with the previously established results. Note that linking changes in model predictions with changes in particular explanatory variables may be difficult when there are may variables and/or coefficients in the model. For instance, a classification tree with hundreds of nodes is difficult to understand, as is a linear regression model with hundreds of cofficients.</p>
<p>Getting the idea about the performance of a black-box model may be more challenging. The structure of a complex model like, e.g., a neural-network model, mmay be far from transparent. Consequently, we may not understand which features and how influence the model decisions. Consequently, it may be difficult to decide whether the model is consistent with the domain knowledge. In our book we present tools that can help in extracting the information necessary for the model evaluation for complex models.</p>
<p><img src="figure/wbBILL8model.png" width="50%" style="display: block; margin: auto;" /></p>
</div>
<div id="model-visualization-exploration-and-explanation" class="section level2">
<h2><span class="header-section-number">1.5</span> Model visualization, exploration, and explanation</h2>
<p>The lifecycle of a model can be divided, in general, in three different phases: development (or building), deployment, and maintenance.</p>
<p>Model development is the phase in which one is looking for the best available model. During this process, model exploration tools are useful. Exploration involves evaluation of the fit of the model, verification of the assumptions underlying the model (diagnostics), and assessment of the predictive performance of the model (validation). In our book we will focus on the visualization tools that can be useful in model exploration. We will not, however, discuss visualization methods for diagnostic purposes, as they are extensively discussed in many books devoted to statistical modelling.</p>
<p>Model deployment is the phase in which a predictive model is adopted for use. In this phase it is crucial that the users gain confidence in using the model. It is worth noting that the users might not have been involved in the model development. Moreover, they may only have got access to the software implementing the model that may not provide any insight in the details of the model structure. In this situation, model explanation tools can help to understand the factors that influence model predictions and to gain confidence in the model. The tools are one of the main focu point of our book.</p>
<p>Finally, a deployed model requires maintenance. In this phase, one monitors model’s performance by, for instance, checking the validity of predictions for different datasets. If issues are detected, model explanation tools may be used to find the source of the problem and to suggest a modification of the structure of the model.</p>
</div>
<div id="model-agnostic-vs.model-specific-approach" class="section level2">
<h2><span class="header-section-number">1.6</span> Model-agnostic vs. model-specific approach</h2>
<p>Some classes of models have been developed for a long period of time or have attracted a lot of interest with an intensive research as a result. Consequently, those classes of models are equipped with very good tools for model exploration or visualisation. For example:</p>
<ul>
<li>There are many tools for diagnostics and evaluation of linear models. Model assumptions are formally defined (normality, linear structure, homogenous variance) and can be checked by using normality tests or plots (normal qq-plot), diagnostic plots, tests for model structure, tools for identification of outliers, etc.</li>
<li>For many more advanced models with an additive structure, like the proportional hazards model, there also many tools that can be used for checking model assumptions.</li>
<li>Random-forest model is equipped with the out-of-bag method of evaluation of performance and several tools for measuring variable importance <span class="citation">(Breiman et al. <a href="#ref-R-randomForest">2018</a>)</span>. Methods have been developed to extract information from the model structure about possible interactions <span class="citation">(Paluszynska and Biecek <a href="#ref-R-randomForestExplainer">2017</a><a href="#ref-R-randomForestExplainer">b</a>)</span>. Similar tools have been developed for other ensembles of trees, like xgboost models <span class="citation">(Foster <a href="#ref-R-xgboostExplainer">2018</a>)</span>.</li>
<li>Neural networks enjoy a large collection of dedicated model-explanation tools that use, for instance, the layer-wise relevance propagation technique <span class="citation">(Bach et al. <a href="#ref-BachLWRP">2015</a>)</span>, or saliency maps technique <span class="citation">(Simonyan, Vedaldi, and Zisserman <a href="#ref-SaliencyMaps">2013</a>)</span>, or a mixed approach.</li>
</ul>
<p>Of course, the list of model classes with dedicated collections of model-explanation and/or diagnostics methods is much longer. This variety of model-specific approaches does lead to issues, though. For instance, one cannot easily compare explanations for two models with different structures. Also, every time when a new architecture or a new ensemble of models is proposed, one needs to look for new methods of model exploration. Finally, for brand-new models no tools for model explanation or diagnostics may be immedaitely available.</p>
<p>For these reasons, in our book we focus on model-agnostic techniques. In particular, we prefer not to assume anything about the model structure, as we may be dealing with a black-box model with an unclear structure. In that case, the only operation that we may be able to perform is evaluation of a model for a selected observation.</p>
<p>However, while we do not assume anything about the structure of the model, we will assume that the model operates on <span class="math inline">\(p\)</span>-dimensional vectors and, for a single vector, it returns a single value which is a real number. This assumption holds for a broad range of models for data such as tabular data, images, text data, videos, etc. It may not be suitable for, e.g., models with memory in which the model output does not depend only on the model input [TOMASZ: NOT SURE WHICH MODELS ARE MEANT HERE].</p>
<p>Note that the techniques considered in the book may not be sufficient to fully understand models in case <span class="math inline">\(p\)</span> is large.</p>
</div>
<div id="code-snippets" class="section level2">
<h2><span class="header-section-number">1.7</span> Code snippets</h2>
<p>TODO: Here we should tell why we present examples for DALEX.
And mention that there are also other functions that can be used.</p>
</div>
<div id="the-structure-of-the-book" class="section level2">
<h2><span class="header-section-number">1.8</span> The structure of the book</h2>
<p>Our book is split in two parts. In the part <em>Instance-level explainers</em>, we present techniques for exploration and explanation of model predictions for a single observation. On the other hand, in the part <em>Global explainers</em>, we present techniques for exploration and explanation of model’s performance for an entire dataset. In each part, every method is described in a separate section that has got the same structure:
* Subsection <em>Introduction</em> explains the goal of and the general idea behind the method.
* Subsection <em>The Algorithm</em> shows mathematical or computational details related to the method. This subsection can be skipped if you are not interested in the details.
* Subsection <em>Example</em> shows an exemplary application of the method with discussion of results.
* Subsection <em>Pros and Cons</em> summarizes the advantages and disadvantages of the method. It also provides some guideance regarding when to use the method.
* Subsection <em>Code snippets</em> shows the implementation of the method in R and Python. This subsection can be skipped if you are not interested in the implementation.</p>
<p>TO DO: A SHORT REVIEW OF THE CONTENTS OF VARIOUS CHAPTERS</p>
<p>Finally, we would like to signal that, <strong>in this book, we do show</strong></p>
<ul>
<li>how to determine features that affect model prediction for a single observation. In particular, we present the theory and examples of methods that can be used to explain prediction like break down plots, ceteris paribus profiles, local-model approximations, or Shapley values.</li>
<li>techniques to examine fully-trained machine-learning models as a whole. In particular, we review the theory and examples of methods that can be used to explain model performance globally, like partial-dependency plots, variable-importance plots, and others.</li>
<li>charts that can be used to present key information in a quick way.</li>
<li>tools and methods for model comparison.</li>
<li>code snippets for R and Python that explain how to use the described methods.</li>
</ul>
<p>On the other hand, <strong>in this book, we do not focus on</strong></p>
<ul>
<li>any specific model. The presented techniques are model agnostic and do not make any assumptions related to model structure.</li>
<li>data exploration. There are very good books on this topic, like R for Data Science <a href="http://r4ds.had.co.nz/" class="uri">http://r4ds.had.co.nz/</a> or TODO</li>
<li>the process of model building. There are also very good books on this topic, see An Introduction to Statistical Learning by Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani <a href="http://www-bcf.usc.edu/~gareth/ISL/" class="uri">http://www-bcf.usc.edu/~gareth/ISL/</a> or TODO</li>
<li>any particular tools for model building. These are discussed, for instance, in Applied Predictive Modeling By Max Kuhn and Kjell Johnson <a href="http://appliedpredictivemodeling.com/" class="uri">http://appliedpredictivemodeling.com/</a></li>
</ul>
</div>
<div id="thanksto" class="section level2">
<h2><span class="header-section-number">1.9</span> Acknowledgements</h2>
<p>Przemek’s work on interpretability has started during research trips within the RENOIR project (691152 - H2020/2016-2019). So he would like to thank prof. Janusz Holyst for the chance to take part in this project.</p>
<p>Przemek would also like thank prof. Chris Drake for her hospitality. This book would have never been created without perfect conditions that Przemek found at Chris’ house in Woodland.</p>
<p>This book has been prepared by using the <strong>bookdown</strong> package <span class="citation">(Xie <a href="#ref-R-bookdown">2018</a>)</span>, created thanks to the amazing work of Yihui Xie.</p>


</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ONeil">
<p>O’Neil, Cathy. 2016. <em>Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</em>. New York, NY, USA: Crown Publishing Group.</p>
</div>
<div id="ref-IBMWatson">
<p>Ross, Casey, and Ike Swetliz. 2018. “IBM’s Watson Supercomputer Recommended ‘Unsafe and Incorrect’ Cancer Treatments, Internal Documents Show.” <em>Statnews</em>. <a href="https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/">https://www.statnews.com/2018/07/25/ibm-watson-recommended-unsafe-incorrect-treatments/</a>.</p>
</div>
<div id="ref-AmazonAI">
<p>Dastin, Jeffrey. 2018. “Amazon Scraps Secret Ai Recruiting Tool That Showed Bias Against Women.” <em>Reuters</em>. <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazonscraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G</a>.</p>
</div>
<div id="ref-COMPAS">
<p>Larson, Jeff, Surya Mattu, Lauren Kirchner, and Julia Angwin. 2016. “How We Analyzed the Compas Recidivism Algorithm.” <em>ProPublica</em>. <a href="https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm">https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm</a>.</p>
</div>
<div id="ref-GoogleFLU">
<p>Salzberg, Steven. 2014. “Why Google Flu Is a Failure.” <em>Forbes</em>. <a href="https://www.forbes.com/sites/stevensalzberg/2014/03/23/why-google-flu-is-a-failure/">https://www.forbes.com/sites/stevensalzberg/2014/03/23/why-google-flu-is-a-failure/</a>.</p>
</div>
<div id="ref-EUGDPR">
<p>GDPR. 2018. “The Eu General Data Protection Regulation (Gdpr) Is the Most Important Change in Data Privacy Regulation in 20 Years.” <a href="https://eugdpr.org/">https://eugdpr.org/</a>.</p>
</div>
<div id="ref-RightToExpl">
<p>Goodman, Bryce, and Seth Flaxman. 2016. “European Union Regulations on Algorithmic Decision-Making and a &quot;Right to Explanation&quot;.” <em>Arxiv</em>. <a href="https://arxiv.org/abs/1606.08813">https://arxiv.org/abs/1606.08813</a>.</p>
</div>
<div id="ref-RightToExpl2">
<p>Casey, Bryan, Ashkon Farhangi, and Roland Vogl. 2018. “Rethinking Explainable Machines: The Gdpr’s ’Right to Explanation’ Debate and the Rise of Algorithmic Audits in Enterprise.” <em>Berkeley Technology Law Journal</em>. <a href="https://ssrn.com/abstract=3143325">https://ssrn.com/abstract=3143325</a>.</p>
</div>
<div id="ref-RightToExpl3">
<p>Ruiz, Javier. 2018. “Machine Learning and the Right to Explanation in Gdpr.” <a href="https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr">https://www.openrightsgroup.org/blog/2018/machine-learning-and-the-right-to-explanation-in-gdpr</a>.</p>
</div>
<div id="ref-R-randomForest">
<p>Breiman, Leo, Adele Cutler, Andy Liaw, and Matthew Wiener. 2018. <em>RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression</em>. <a href="https://CRAN.R-project.org/package=randomForest">https://CRAN.R-project.org/package=randomForest</a>.</p>
</div>
<div id="ref-R-randomForestExplainer">
<p>Paluszynska, Aleksandra, and Przemyslaw Biecek. 2017b. <em>RandomForestExplainer: Explaining and Visualizing Random Forests in Terms of Variable Importance</em>. <a href="https://CRAN.R-project.org/package=randomForestExplainer">https://CRAN.R-project.org/package=randomForestExplainer</a>.</p>
</div>
<div id="ref-R-xgboostExplainer">
<p>Foster, David. 2018. <em>XgboostExplainer: XGBoost Model Explainer</em>.</p>
</div>
<div id="ref-BachLWRP">
<p>Bach, Sebastian, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech Samek. 2015. “On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation.” Edited by Oscar Deniz Suarez. <em>PLOS ONE</em> 10 (7): e0130140. <a href="https://doi.org/10.1371/journal.pone.0130140">https://doi.org/10.1371/journal.pone.0130140</a>.</p>
</div>
<div id="ref-SaliencyMaps">
<p>Simonyan, Karen, Andrea Vedaldi, and Andrew Zisserman. 2013. “Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps.” <em>CoRR</em> abs/1312.6034. <a href="http://arxiv.org/abs/1312.6034">http://arxiv.org/abs/1312.6034</a>.</p>
</div>
<div id="ref-R-bookdown">
<p>Xie, Yihui. 2018. <em>Bookdown: Authoring Books and Technical Documents with R Markdown</em>. <a href="https://CRAN.R-project.org/package=bookdown">https://CRAN.R-project.org/package=bookdown</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="DataSetsIntro.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["PM_VEE.pdf", "PM_VEE.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
