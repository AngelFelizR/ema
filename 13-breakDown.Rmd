# Break Down {#breakDown}

The method approach for variable attribution presented in the Section \@ref(modelAgnosticAttribution) has the property of *local accuracy*, but variable contributions depends on the variable ordering.

The Break Down method solves this problem by using two-step procedure. In the first step variables are ordered and in the second step the consecutive conditioning is applied to ordered variables.


## The Break Down Algorithm

First step of this algorithm is to determine the order of variables for conditionaing. 
It seems to be resonable to include first variables that are likely to be most important, leaving the noise variables at the end.
This leads to order based on following scores

$$
score(f, x^*, i) = \left| E [f(X)] - E [f(X)|X_i = x^*_i] \right|
$$
Note, that the absolute value is needed as variable contributions can be both positive and negative. 

Once the ordering is determined in the second step variable contributions are calculated as

$$
v(f, x^*_i, i) = E [f(X) | X_{I \cup \{i\}} = x_{I \cup \{i\}}^*] - E [f(X) | X_{I} = x_{I}^*] 
$$
where $I$ is the set of variables that have scores smaller than score for variable $i$.

$$
I = \{j: score(f, x^*, j) < score(f, x^*, i)\}
$$

The time complexity of the first step id $O(p)$ where $p$ is the number of variables and the time complexity of the second step is also $O(p)$.


## HR dataset: Hire or Fire?

Let us consider a random forest model created for HR data. The average model response is $\bar f(x) = 0.385586$. For a selected observation $x^*$ the table below presents scores for particular variables.

|           |  Ei f(X)|    scorei|
|:----------|--------:|---------:|
|hours      | 0.616200|  0.230614|
|salary     | 0.225528|  0.160058|
|evaluation | 0.430994|  0.045408|
|age        | 0.364258|  0.021328|
|gender     | 0.391060|  0.005474|

Once we determine the order we can calculate sequential contributions

|variable         | cumulative| contribution|
|:----------------|-----------:|------------:|
|(Intercept)      |    0.385586|     0.385586|
|* hours = 42     |    0.616200|     0.230614|
|* salary = 2     |    0.400206|    -0.215994|
|* evaluation = 2 |    0.405776|     0.005570|
|* age = 58       |    0.497314|     0.091538|
|* gender = male  |    0.778000|     0.280686|
|final_prognosis  |    0.778000|     0.778000|

## The Break Down Plot

Once we calculated variable attributions we may plot them in an intuitive form.
This intuition behind Break Down Plots is described in Figure \@ref(BDPrice4). 

The variable ordering determined in the first step of Break Down Algorithm is reflected by the ordering of variables in consecutive rows of a plot. 

The last row of a plot shows the $baseline$, i.e. an average model prediction. The next row corresponds to average model prediction for observations with variable `surface` fixed to value `35`. The next for correspons to average model prediction with variables `surface` set to `35` and `floor` set to `1`, and so on. The first row corresponds to model response for $x^*$.

In panels A and B violines show distribution of model predictions for selected points, while red dots stands for averages. 

The most minimal form that shows all important information is presented in the panel C.
Positive values are presented with green bars while negative differences are marked with yellow bar. They sum up to final model prediction, which is denoted by a grey bar in this example.



```{r BDPrice4, echo=FALSE, fig.cap="(fig:BDPrice4) Break Down Plots show how variables move the model prediction from population average to the model prognosis for a single observation. A) The last row shows distribution of model predictions. Next rows show conditional distributions, every row a new variable is added to conditioning. The first row shows model prediction for a single point. Red dots stand for averages. B) Blue arrows shows how the average conditional response change, these values are variables contributions. C) Only variable contributions are presented. ", out.width = '70%', fig.align='center'}
knitr::include_graphics("figure/bd_price_4.png")
```




## Pros and cons

Break Down approach is model agnotic, can be applied to any predictive model that returns a single number. It leads to additive variable attribution. Below we summarize key strengths and weaknesses of this approach. 


**Pros**

- Break Down Plots are easy to understand and decipher.
- Break Down Plots are compact, many variables may be presented in a small space.
- Break Down Plots are model agnostic yet they reduce to intuitive interpretation for linear Gaussian and generalized models.
- Complexity of Break Down Algorithm is linear in respect to the number of variables.

**Cons**

- If the model is non-additive then showing only additive contributions may be misleading.
- Selection of the ordering based on scores is subjective. Different orderings may lead to different contributions.
- For large number of variables the Break Down Plot may be messy with many variables having small contributions.



## Code snippets for R

In this section we present key features of the `breakDown` package for R [@R-breakDown]. This package covers all features presented in this chapter. It is available on CRAN and GitHub. Find more examples at the website of this package `https://pbiecek.github.io/breakDown/`.

**Model preparation**

In this section we will present an example based on the `HR` dataset and Random Forest model [@R-randomForest]. See the Section \@ref(HRdataset) for more details.

```{r, warning=FALSE, message=FALSE}
library("DALEX")
library("randomForest")
model <- randomForest(status ~ gender + age + hours + evaluation + salary, data = HR)
model
```

Model exploration with the `breakDown` package is performed in three steps. 

**1. Create an explainer - wrapper around model and validation data.**

Since all other functions work in a model agnostic fashion, first we need to define a wrapper around the model. Here we are using the `explain()` function from `DALEX` package [@R-DALEX].

```{r, warning=FALSE, message=FALSE}
explainer_rf_fired <- explain(model,
                 data = HR,
                 y = HR$status == "fired",
                 predict_function = function(m,x) predict(m,x, type = "prob")[,1],
                 label = "fired")
```

**2. Select an observation of interest.** 

Break Down Plots decompose model prediction around a single observation. Let's construct a data frame with corresponding values.

```{r, warning=FALSE, message=FALSE}
new_observation <- data.frame(gender = factor("male", levels = c("male", "female")),
                      age = 57.7,
                      hours = 42.3,
                      evaluation = 2,
                      salary = 2)

predict(model, new_observation, type = "prob")
```

**3. Calculate Break Down decomposition**

The `break_down()` function calculates Break Down contributions for a selected model around a selected observation. 

The result from `break_down()` function is a data frame with variable attributions.

```{r, warning=FALSE, message=FALSE}
library("breakDown")
bd_rf <- break_down(explainer_rf_fired,
                 new_observation,
                 check_interactions = FALSE,
                 keep_distributions = TRUE)

bd_rf
```

The generic `plot()` function creates a Break Down plots. 
```{r, warning=FALSE, message=FALSE}
plot(bd_rf) 
```

Add the `plot_distributions = TRUE` argument to enrich model response with additional information.

```{r, warning=FALSE, message=FALSE}
plot(bd_rf, plot_distributions = TRUE) 
```




```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=FALSE}

bd_rf <- broken(rf_model, new_apartment, data = apartmentsTest, direction = "up", keep_distributions = TRUE)
bd_rf

plot(bd_rf) + theme_bw() + scale_y_continuous("price per square meter", expand = c(0,0), limits = c(0,6300)) + theme(legend.position = "none")

plot(bd_rf, plot_distributions = TRUE) + theme_bw() + scale_y_continuous("price per square meter", expand = c(0,0), limits = c(0,6300)) + theme(legend.position = "none")



plot(bd_rf) + theme_bw()+ scale_y_continuous("price per square meter", expand = c(0,0)) 
```



# Break Down for Interactions


Break Down decomposition shows how the expected model prediction changes when we move from general population to a particular observation.
Changes here means that values of variables are set to a value observed in a point of interest.
For non additive models the order of relaxations is important.
Therefore the construction of Break Down containes two phases.

A. Order of relaxations is determined.
B. Sequential relaxation is performed.

Let us present each phase in details based on an example. 

To determine the order we consider a series of one step relaxations. 

With the use of notation introduced in this section, we calculate expected valued for model predictions after a single variable $i$ is set to value observed in $x^*$.

$$
score_i = f^{\{i\}}(x^*)
$$

To determine the effect of this variable, we compare $score_i$ with the average model response $score_0$. The larger the difference, the larger is the effect of particular value.  

$$
diff_i = score_i - f^{\emptyset}(x^*)
$$

**Example**

Let us consider a HR dataset. The observation of interested is (TODO). 
The table below shows $score_i$ and $diff_i$ calculated for consecutive variables.

|           |    score|      diff|
|:----------|--------:|---------:|
|hours      | 0.616200|  0.230614|
|salary     | 0.225528| -0.160058|
|evaluation | 0.430994|  0.045408|
|age        | 0.364258| -0.021328|
|gender     | 0.391060|  0.005474|

Once we determine the order we can calculate sequential relaxations.

|variable         | cumulative| contribution|
|:----------------|-----------:|------------:|
|(Intercept)      |    0.385586|     0.385586|
|* hours = 42     |    0.616200|     0.230614|
|* salary = 2     |    0.400206|    -0.215994|
|* evaluation = 2 |    0.405776|     0.005570|
|* age = 58       |    0.497314|     0.091538|
|* gender = male  |    0.778000|     0.280686|
|final_prognosis  |    0.778000|     0.778000|


As we see contributions calculated in the sequential relaxations are different that these calculated in the first step.

Such situation suggests that the model under consideration is not additive.
What we can do with interactions?

Actually it turns out that we can use a very similar technique to identify interactions. We just need to extend bot steps intorduces in this section.

A. Order of relaxations is determined.
B. Sequential relaxation is performed.

For A. we need to calculate second order scores, i.e.

$$
score_{ij} = f^{\{i,j\}}(x^*)
$$

And calculate how much the second order score is different than sum of first order scores.

$$
diff_{ij} = score_{ij} - f^{\{i\}}(x^*) - f^{\{j\}}(x^*) + f^{\emptyset}(x^*) = score_{ij} - diff_i - diff_j - f^{\emptyset}(x^*) 
$$

Note, that for additive models $diff_{ij}$ shall be close to zero, so the larger is this value the larger deviation from additivness.

**Example**

Again, let us consider a HR dataset. The observation of interested is (TODO). 
The table below shows $score_i$ and $diff_i$ calculated for consecutive variables.

|                  | baseline|      diff| diff ij  |
|:-----------------|--------:|---------:|---------:|
|hours             | 0.616200|  0.230614|          |
|salary            | 0.225528| -0.160058|          |
|age:gender        | 0.516392|          |  0.146660|
|salary:age        | 0.266226|          |  0.062026|
|salary:hours      | 0.400206|          | -0.055936|
|evaluation        | 0.430994|  0.045408|          |
|hours:age         | 0.635662|          |  0.040790|
|salary:evaluation | 0.238126|          | -0.032810|
|age               | 0.364258| -0.021328|          |
|evaluation:hours  | 0.677798|          |  0.016190|
|salary:gender     | 0.223292|          | -0.007710|
|evaluation:age    | 0.415688|          |  0.006022|
|gender            | 0.391060|  0.005474|          |
|hours:gender      | 0.626478|          |  0.004804|
|evaluation:gender | 0.433814|          | -0.002654|

Again, once we determine the order we can calculate sequential relaxations.

|variable               | cummulative| contribution|
|:----------------------|-----------:|------------:|
|(Intercept)            |    0.385586|     0.385586|
|* hours = 42           |    0.616200|     0.230614|
|* salary = 2           |    0.400206|    -0.215994|
|* age:gender = 58:male |    0.796856|     0.396650|
|* evaluation = 2       |    0.778000|    -0.018856|
|final_prognosis        |    0.778000|     0.778000|




```{r bdInter1, echo=FALSE, fig.cap="(fig:bdInter1) Break Down plot with interactions ", out.width = '70%', fig.align='center'}
knitr::include_graphics("figure/bd_inter_1.png")
```

