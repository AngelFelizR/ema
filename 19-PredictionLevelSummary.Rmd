# Comparision of instance level explainers

TODO  compare pros and cons of different techniques

TODO: Sparse model approximation / variable selection / feature ranking

TODO comparison of difrerent approach for Johny D

TODO Champion-Challenger explainers


## When to use? 

There are several use-cases for such explainers. Think about following.

* Model improvement. If model works particular bad for a selected observation (the residual is very high) then investigation of model responses for miss fitted points may give some hints how to improve the model. For individual predictions it is easier to notice that selected variable should have different a effect.
* Additional domain specific validation. Understanding which factors are important for model predictions helps to be critical about model response. If model contributions are against domain knowledge then we may be more skeptical and willing to try another model. On the other hand, if the model response is aligned with domain knowledge we may trust more in these responses. Such trust is important in decisions that may lead to serious consequences like predictive models in medicine.
* Model selection. Having multiple candidate models one may select the final response based on model explanations. Even if one model is better in terms of global model performance it may happen that locally other model is better fitted. This moves us towards model consultations that identify different options and allow human to select one of them. 




Enslaving the Algorithm: From a ‘Right to an Explanation’ to a ‘Right to Better Decisions’?
[@Edwards_Veale_2018]



